[
  {
    "id": 24,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "chained-operators-python",
    "title": "Chained Comparison Operators in Python",
    "description": "In this essay, we find how chained comparison expressions are evaluated, understand how short-circuit evaluations happen internally, and alter Python's expression evaluation strategy.",
    "gif": "https://media.giphy.com/media/LpLd2NGvpaiys/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/116305344-47334080-a7c1-11eb-888a-a60b203ebe9d.png",
    "released_at": "2021-04-27",
    "total_views": 275,
    "body": "Python supports chaining of comparison operators, which means if we wanted to find out if `b` lies between `a` and `c` we can do `a < b < c`, making code super-intuitive. Python evaluates such expressions like how we do in mathematics. which means `a < b < c` is evaluated as `(a < b) and (b < c)`. C language on the other hand, evaluates `a < b < c` as `((a < b) < c)`.\n\nDepending on how we evaluate such expressions, the final evaluated changes. So, in python, if we evaluate `-3 < -2 < -1`, we get `True` and if evaluate `3 > 2 == 1` we get `False`.\n\n```python\n>>> -3 < -2 < -1\nTrue\n>>> 3 > 2 == 1\nFalse\n```\n\nBut on the other hand, if we evaluate this very expression in C language the output is `False`.\n\n```c\n#include <stdio.h>\n\nint main(int argc, char *argv[]) {\n    printf(\"%d\\n\", -3 < -2 < -1);\n    printf(\"%d\\n\", 3 > 2 == 1);\n    return 0;\n}\n\n$ gcc test.cpp\n$ ./a.out\n0\n1\n```\n\nIt does so because `(-3 < -2) = True = 1` and `1 < -1 is False`. Also, to get a better understanding of how such expressions evaluate, try playing around with different values and see if your predicted value matches the actual output.\n\nThis essay is going to be extra special; in this one, we find out\n\n- how Python evaluates chained comparison operators?\n- how Python implements short-circuiting?\n- how could you make Python-like evaluation a C-like evaluation? implying at the end of this essay we alter the CPython source code such that the expression `-3 < -2 < -1` will evaluate to `False`.\n\nI know this sounds tempting, so let's jump right into it.\n\n# Chaining comparison operators\n\nPython has a plethora of comparison operators like `<`, `>`, `<=`, `>=`, `==`, `!=`, `in`, and `is`. The output of the comparison operator is a boolean value - `True` or `False`. Python allows chaining of comparison operators which means, to check if `b` lies between `a` and `c`, we can simply do\n\n```python\n>>> a < b < c\n```\n\nThis is possible because internally Python evaluates this chained expression `a < b < c` as `(a < b) and (b < c)`. To make this efficient, the sub-expression `b` is evaluated only once and the evaluation also follows short-circuit evaluation; which means, if `(a < b)` is evaluated as `False` then Python would not evaluate further sub-expressions - `c` and `(b < c)`. Now that we have set the context, let's find out what happens under the hood.\n\n# Chaining under the hood\n\nDisassembling the expression would give out the set of Python instructions that will be executed on the runtime's execution stack. If we disassemble `a < b < c`, we get the following set of instructions. By the way, this is a great way to jump into the internals of anything in Python.\n\n```python\n>>> import dis\n>>> dis.dis('a < b < c')\n\n  1           0 LOAD_NAME                0 (a)\n              2 LOAD_NAME                1 (b)\n              4 DUP_TOP\n              6 ROT_THREE\n              8 COMPARE_OP               0 (<)\n             10 JUMP_IF_FALSE_OR_POP    18\n             12 LOAD_NAME                2 (c)\n             14 COMPARE_OP               0 (<)\n             16 RETURN_VALUE\n        >>   18 ROT_TWO\n             20 POP_TOP\n             22 RETURN_VALUE\n```\n\nHere is the summary of what each of the above instructions does; having this understanding will help us understand the entire execution process.\n\n- `LOAD_NAME`: Loads the variable on the top of the stack\n- `DUP_TOP`: Duplicates the top of the stack\n- `ROT_THREE`: Rotates the top 3 elements of the stack by 1, such that the second element becomes the top, the third becomes the second while the top becomes the third.\n- `COMPARE_OP`: Pops the top two elements from the stack, compare them (depending on the operator), compute the output, and puts it on the top of the stack.\n- `JUMP_IF_FALSE_OR_POP`: Checks if the top of the stack is `False` if it is false then jumps to provided offset, and if it is `True` it pops the value.\n- `RETURN_VALUE`: Pops the top of the stack and returns it\n- `ROT_TWO`: Rotates the top two elements of the stack such that the top elements become the second, while the second becomes the top.\n- `POP_TOP`: Pops the top element from the stack, kind of discarding it.\n\nYou can find details about these opcodes in the file [ceval.c](https://github.com/python/cpython/blob/master/Python/ceval.c). Now, let's do an instruction by instruction walkthrough for the expression `1 < 2 < 3` to see how it evaluates to `True`.\n\n## Evaluating `1 < 2 < 3`\n\nWhen we run disassembler on `1 < 2 < 3` we get a similar disassembled code. It starts with the loading of two constant values `1` and `2` on the stack. Then it duplicates the top which makes our stack `2, 2, 1`. Now upon `ROT_THREE` the `2` on the top of the stack goes at the third spot while the other moves up one place. at this instruction, our stack looks like `2, 1, 2`.\n\n![https://user-images.githubusercontent.com/4745789/116093465-508ab300-a6c4-11eb-8587-2922c4095eaa.png](https://user-images.githubusercontent.com/4745789/116093465-508ab300-a6c4-11eb-8587-2922c4095eaa.png)\n\nNow, the `COMPARE_OP` operation pops out two elements from the stack and performs the comparison. The first popped value becomes the right operand while the second popped becomes the left operand. Post comparison the evaluated value is put on top of the stack again. Since `1 < 2`, the expression is evaluated as `True` and this `True` is put on to of the stack. So, after the `COMPARE_OP` instruction, the stack would look like `True, 2`.\n\nThen comes the instruction `JUMP_IF_FALSE_OR_POP` which checks the top of the stack. Since the top of the stack is `True` (not `False`), it pops the value, making our stack `2`. Now `3` is loaded onto the stack making our stack `3, 2`.\n\nNow `COMPARE_OP` pops out two elements, compares them, and since `2 < 3` it evaluates to `True` and this `True` is stacked on top. After this operation, the stack has just one element `True`.\n\nThe next instruction is `RETURN_VALUE`, which pops out the top of the stack i.e. `True`, and returns it; and this is how the expression `1 < 2 < 3` is evaluated to `True`.\n\n## Short-circuit Evaluation\n\nA very interesting instruction is sitting right in the middle - `JUMP_IF_FALSE_OR_POP`. This instruction is the one that is doing short-circuiting. Once the runtime encounters this instruction it checks the top of the stack,\n\n- if top == `False` the flow jumps to the last few instructions, bypassing the loading and comparing other sub-expressions.\n- if top == `True` it does not jump, but rather continues its evaluation of the next instructions.\n\nTo get a better understanding, try doing an instruction by instruction walkthrough for the expression `6 > 7 > 8` and you will find out how it bypasses the evaluating next sub-expressions.\n\n![https://user-images.githubusercontent.com/4745789/116093532-60a29280-a6c4-11eb-9ad9-24a73dddb683.png](https://user-images.githubusercontent.com/4745789/116093532-60a29280-a6c4-11eb-9ad9-24a73dddb683.png)\n\nNow we know, why the [official documentation](https://docs.python.org/3/reference/expressions.html#comparisons) says,\n\n> Comparisons can be chained arbitrarily, e.g., x < y <= z is equivalent to x < y and y <= z, **except that y is evaluated only once (but in both cases z is not evaluated at all when x < y is found to be false)**.\n\n## How does it \"and\" sub-expressions?\n\nWe have established and also seen in action how Python evaluates chained comparison operators. We also understand that it evaluates `1 < 2 < 3` as `(1 < 2) and (2 < 3)` but exactly where is this very logic implemented? The magic happens with two instructions `DUP_TOP` and `ROT_THREE`.\n\nSo, if we keenly observe, to evaluate `1 < 2 < 3` as `(1 < 2) and (2 < 3)` we would need to repeat the middle operand and keep it ready as the first operand of the second comparison. Now, to \"repeat\" the middle operand, we call `DUP_TOP`.\n\nOnce the two operands are loaded on the stack we see that the right operand sits on the top and by invoking `DUP_TOP` we are copying the middle operand and putting it on the top of the stack. This copied top (middle operand) needs to be preserved to be used as the first operand in the next comparison, and to do this we call `ROT_THREE` that puts the stack top to the third from the top.\n\nAfter the first comparison is evaluated the stack contains - the copied middle operand and on top of it the evaluated value. The evaluated value is discarded or returned depending on if it is `True` or `False`, keeping the copied middle operand on the stack, making it the first operand of the next comparison.\n\n# Make chain evaluation C-like\n\nNow that we have understood how Chained Operators are evaluated and what how the evaluation is made \"mathematics\" like, let's manipulate the code to make the evaluation C-like; which means we have to evaluate operands left to right and use the evaluated value as the first operand for next comparison. To be honest, if you have understood the importance of `DUP_TOP` and `ROT_THREE` making evaluation C-like is fairly straightforward. \n\nThe code that generates instructions for comparison expressions is in file [Python/compile.c](https://github.com/python/cpython/blob/master/Python/compile.c#L4031). The snippet that interests us is the function `compiler_compare` which can be seen below\n\n```c\nstatic int\ncompiler_compare(struct compiler *c, expr_ty e)\n{\n    ...\n        for (i = 0; i < n; i++) {\n            VISIT(c, expr,\n                (expr_ty)asdl_seq_GET(e->v.Compare.comparators, i));\n            ADDOP(c, DUP_TOP);\n            ADDOP(c, ROT_THREE);\n            ADDOP_COMPARE(c, asdl_seq_GET(e->v.Compare.ops, i));\n            ADDOP_JUMP(c, JUMP_IF_FALSE_OR_POP, cleanup);\n            NEXT_BLOCK(c);\n        }\n    ...\n        ADDOP(c, ROT_TWO);\n        ADDOP(c, POP_TOP);\n    ...\n    }\n    return 1;\n}\n```\n\nTo make the evaluation C-like we\n\n- should not copy the middle operand\n- ensure that the evaluated value (output from the first compare) remains on top - so that it becomes the first operand of the next expression\n\nTo achieve this, all we have to do is comment out `3` lines that do exactly that. Post changes the snippet would look something like this.\n\n```c\nstatic int\ncompiler_compare(struct compiler *c, expr_ty e)\n{\n    ...\n        for (i = 0; i < n; i++) {\n            VISIT(c, expr,\n                (expr_ty)asdl_seq_GET(e->v.Compare.comparators, i));\n\n            // ADDOP(c, DUP_TOP);\n            // ADDOP(c, ROT_THREE);\n\n            ADDOP_COMPARE(c, asdl_seq_GET(e->v.Compare.ops, i));\n\n            // ADDOP_JUMP(c, JUMP_IF_FALSE_OR_POP, cleanup);\n\n            NEXT_BLOCK(c);\n        }\n    ...\n        ADDOP(c, ROT_TWO);\n        ADDOP(c, POP_TOP);\n    ...\n    }\n    return 1;\n}\n```\n\nRecall that the expression `-3 < -2 < -1` on a usual Python interpreter evaluates to `True` because `-2` is between `-3` and `-1`. But post these changes, if we build the binary and start the interpreter we would see the output of expression `-3 < -2 < -1` as `False`, just like C; as it evaluated the expression from left to right and kept reusing the output of the previous comparison as the first operand of the next one. \n\nHere is the disassembled code and an instruction by instruction execution post our changes.\n\n![https://user-images.githubusercontent.com/4745789/116272065-37eecb80-a79e-11eb-8345-cae342a8441c.png](https://user-images.githubusercontent.com/4745789/116272065-37eecb80-a79e-11eb-8345-cae342a8441c.png)\n\nThe engine first evaluated `-3 < -2`, and put the result `True` on top of the stack and then loaded `-1` to perform the comparison `True < -1`. Since `True == 1` the expression `True < -1` is evaluated as `False` and hence the output of the entire statement is `False`, just like in C. This also means that the expression `3 > 2 == 1` should evaluate to `True` and it actually does.\n\n![https://user-images.githubusercontent.com/4745789/116272093-3d4c1600-a79e-11eb-9981-655744c86348.png](https://user-images.githubusercontent.com/4745789/116272093-3d4c1600-a79e-11eb-9981-655744c86348.png)\n\n# References\n\n- [Under the Hood: Python Comparison Breakdown](https://pybit.es/guest-python-comparison-breakdown.html)\n- [How do chained comparisons in Python actually work?](https://stackoverflow.com/questions/28754726/how-do-chained-comparisons-in-python-actually-work)\n- [Comparisons: Python Language Reference](https://docs.python.org/3/reference/expressions.html#comparisons)\n",
    "similar": [
      "the-weird-walrus",
      "setting-up-graphite-grafana-using-nginx-on-ubuntu",
      "making-http-requests-using-netcat",
      "how-sleepsort-helped-me-understand-concurrency-in-golang"
    ]
  },
  {
    "id": 26,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "the-weird-walrus",
    "title": "The Weird Walrus",
    "description": "In this essay, we alter the Python Grammar and allow it run Assignment Expressions without any parenthesis.",
    "gif": "https://media.giphy.com/media/SbIJjAaist696ywQXx/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/112817071-ac4f2580-909f-11eb-8d56-f89536cfa065.png",
    "released_at": "2021-03-29",
    "total_views": 2377,
    "body": "Python in version 3.8 introduced [Assignment Expressions](https://realpython.com/lessons/assignment-expressions/) which can be used with the help of the Walrus Operator `:=`. This expression does assign and return in the same expression helping in writing a concise code.\n\nSay you are building your own shell in Python. It takes commands and input from the prompt, executes it on your shell, and renders the output. The shell should stop the execution as soon as it receives the `exit` command. This seemingly complicated problem can be built using just 4 lines of Python code.\n\n```python\ncommand = input(\">>> \")\nwhile command != \"exit\":\n    os.system(command)\n    command = input(\">>> \")\n```\n\nAlthough the above code runs perfectly fine, we can see that the `input` is taken twice, once outside the loop and once within the loop. This kind of use case is very common in Python.\n\nWalrus Operator fits perfectly here; now instead of initializing `command` with `input` outside and then checking if `command != 'exit'`, we can merge the two logic in one expression. The 4 lines of code above can be rewritten into the most intuitive 2 lines\n\n```python\nwhile (command := input(\">>> \")) != \"exit\":\n    os.system(command)\n```\n\n# What's weird with the Walrus operator?\n\nNow that we have established how useful the Walrus Operator could be for us, let's dive into the weird stuff. Since the Walrus operator has functioning similar to an assignment operator `=`, we would expect the following code to work fine, but it actually gives an error, not just any but a `SyntaxError`.\n\n```python\n>>> a := 10\n  File \"<stdin>\", line 1\n    a := 10\n      ^\nSyntaxError: invalid syntax\n```\n\nIf you thought, that was weird wait till we wrap the exact same statement with parenthesis and execute it.\n\n```python\n>>> (a := 10)\n10\n```\n\nWhat! it worked! How? What happened here? Just by wrapping the statement by parenthesis made an invalid Syntax valid? Isn't it weird? This behavior is pointed out in a Github repository called [wtf-python](https://github.com/satwikkansal/wtfpython#-first-things-first-). The theoretical explanation for this behavior is simple; Python disallows non-parenthesized Assignment Expressions but it allows non-parenthesized assignment statements.\n\nIn this essay, we dig deep into CPython and find out hows and the whys.\n\n# The hows and the whys\n\nFew points to note:\n\n- The Walrus Operator or Assignment Expressions are called Named Expressions in CPython.\n- The branch of the CPython we are referring to here is for version `3.8`\n\n## The Grammar\n\nIf `a := 10` is giving us a Syntax Error then it must be linked to the Grammar specification of the language. The grammar of Python can be found in the file [Grammar/Grammar](https://github.com/python/cpython/blob/3.8/Grammar/Grammar). So if we grep `namedexpr` in the Grammar file we get the following rules\n\n```\nnamedexpr_test: test [':=' test]\n\natom: ('(' [yield_expr|testlist_comp] ')' |\n       '[' [testlist_comp] ']' |\n       '{' [dictorsetmaker] '}' |\n       NAME | NUMBER | STRING+ | '...' | 'None' | 'True' | 'False')\n\ntestlist_comp: (namedexpr_test|star_expr) ( comp_for | (',' (namedexpr_test|star_expr))* [','] )\n\nif_stmt: 'if' namedexpr_test ':' suite ('elif' namedexpr_test ':' suite)* ['else' ':' suite]\n\nwhile_stmt: 'while' namedexpr_test ':' suite ['else' ':' suite]\n```\n\nThe above Grammar rules give us a good gist of how Named Expressions are supposed to be used. Here are some observations about it -\n\n- can be used in `while` statements\n- can be used along with `if` statements\n- named expressions are part of a rule called `testlist_comp`, which seems related to list comprehensions\n\nWe can see that the `atom` rules put in a hard check that `testlist_comp` should be either surrounded by `()` or `[]` and since `testlist_comp` can have `namedexpr_test` this puts in the check that Named Expressions should be surrounded by `()` or `[]`. \n\n```\n>>> (a := 1)\n1\n>>> [a := 1]\n[1]\n```\n\nSo when we run `a := 1`, none of the Grammar rules is satisfied and hence this results in a `SyntaxError`.\n\n## What about `if` and `while`?\n\nAccording to the rule `if_stmt` and `while_stmt` you can have named expressions right after `if` without needing any brackets surrounding it. This means the following statement is valid, but still chose to put parenthesis around `:=`, why?\n\n```python\nwhile command := input(\">>> \") != \"exit\":\n```\n\nThe answer is simple, [Operator Precedence](https://en.wikipedia.org/wiki/Order_of_operations); because of the configured precedence the above statement sets `command` as `bool` after evaluating `input(\">>> \") != \"exit\"` but we do not want this behaviour. Instead, we want `command` to be set as a command given as an input through `input` call and hence we wrap the expression with parenthesis for specifying explicit precedence.\n\n# Allowing `a := 10`\n\nTill now we saw how doing `a := 10` on a fresh Python prompt gives us a `SyntaxError`, so how about altering the CPython to allow `a := 10`? Sounds fun, isn't it?\n\n## Changing the Grammar\n\nTo achieve what we want to we will have to alter the Grammar rules. A good point to note here is that as a standalone statement, `:=` works and behaves very similar to a regular assignment statement having an `=`. So let's first find out, where have we allowed regular assignment statements \n\n```\nstmt: simple_stmt | compound_stmt\nsimple_stmt: small_stmt (';' small_stmt)* [';'] NEWLINE\nsmall_stmt: (expr_stmt | del_stmt | pass_stmt | flow_stmt |\n             import_stmt | global_stmt | nonlocal_stmt | assert_stmt)\nexpr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |\n                     [('=' (yield_expr|testlist_star_expr))+ [TYPE_COMMENT]] )\n```\n\nThe regular assignment statements are allowed as per `expr_stmt` rule which is, in turn, a `small_stmt`, `simple_stmt`, and `stmt`. Rules are self-explanatory and skimming them would help you understand what exactly is happening in there.\n\nIn order to mimic the behavior of `:=` to be the same as `=` how about adding a new rule in `expr_stmt` that suggests matching the same pattern as `=`. So we make the following change in `expr_stmt`.\n\n```\nexpr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |\n                     [('=' (yield_expr|testlist_star_expr))+ [TYPE_COMMENT]] |\n                     [(':=' (yield_expr|testlist_star_expr))+ [TYPE_COMMENT]] )\n```\n\nWhen we change anything in the `Grammar` file, we have to regenerate the parser code; and this can be done using the following command\n\n```\n$ make regen-grammar\n```\n\nOnce the above command is successful, we generate a fresh Python binary and see our changes in action.\n\n```\n$ make && ./python.exe\n```\n\nOn the fresh prompt that would have popped up try putting in `a := 10`, once you do this you will find out that this does not give any error and it executes seamlessly and it works just like a normal assignment statement, the behavior that we were seeking.\n\nSo with these changes, we have our Python interpreter that supports all three statements without any Error.\n\n```python\n>>> a = 10\n>>> (b := 10)\n10\n>>> c := 10\n```\n\nAll of these changes were made on my own [fork of CPython](https://github.com/arpitbbhayani/cpython) and the PR can be found [here](https://github.com/arpitbbhayani/cpython/pull/8).\n\n# References\n\n- [CPython Source Code Guide](https://realpython.com/cpython-source-code-guide/)\n- [Exploring CPython\u2019s Internals](https://devguide.python.org/exploring/)\n- [wtfpython - Github Repository](https://github.com/satwikkansal/wtfpython)\n- [Assignment Expressions: The Walrus Operator](https://realpython.com/lessons/assignment-expressions/)\n",
    "similar": [
      "setting-up-graphite-grafana-using-nginx-on-ubuntu",
      "super-long-integers",
      "making-http-requests-using-netcat",
      "how-sleepsort-helped-me-understand-concurrency-in-golang"
    ]
  },
  {
    "id": 29,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "constant-folding-python",
    "title": "Constant Folding in Python",
    "description": "Every programming language aims to be performant and Python is no exception. In this essay, we dive deep into Python internals and find out how Python makes its interpreter performant using a technique called Constant Folding.",
    "gif": "https://media.giphy.com/media/mMCXtwz1DM3xPKgkOB/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/104118331-23e9a000-534e-11eb-9ec8-8369cdae40b1.png",
    "released_at": "2021-01-10",
    "total_views": 3917,
    "body": "Every programming language aims to be performant in its niche and achieving superior performance requires a lot of compiler level optimizations. One famous optimization technique is [Constant Folding](https://en.wikipedia.org/wiki/Constant_folding) where during compile time the engine tries to recognize constant expressions, evaluate them, and replaces the expression with this newly evaluated value, making the runtime leaner.\n\nIn this essay, we dive deep and find what exactly is Constant Folding, understand the scope of it in the world of Python and finally go through Python's source code - [CPython](https://github.com/python/cpython/) - and find out how elegantly Python actually implements it.\n\n# Constant Folding\n\nIn [Constant Folding](https://en.wikipedia.org/wiki/Constant_folding), the engine finds and evaluates constant expressions at compile time rather than computing them at runtime, making the runtime leaner and faster.\n\n```python\n>>> day_sec = 24 * 60 * 60\n```\n\nWhen the compiler encounters a constant expression, like above, it evaluates the expression and replaces it with the evaluated value. The expression is usually replaced by the evaluated value in the [Abstract Syntax Tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree), but the implementation is totally up to the language. Hence the above expression is effectively executed as\n\n```python\n>>> day_sec = 86400\n```\n\n# Constant Folding in Python\n\nIn Python, we could use the [Disassembler module](https://docs.python.org/3/library/dis.html#module-dis) to get the CPython bytecode giving us a good peek at how things will be executed. When we disassemble the above constant expression using the `dis` module, we get the following bytecode\n\n```python\n>>> import dis\n>>> dis.dis(\"day_sec = 24 * 60 * 60\")\n\n        0 LOAD_CONST               0 (86400)\n        2 STORE_NAME               0 (day_sec)\n        4 LOAD_CONST               1 (None)\n        6 RETURN_VALUE\n```\n\nWe see that the bytecode, instead of having two binary multiply operations followed by one `LOAD_CONST`, is having just one `LOAD_CONST` with the already evaluated value of `86400`. This indicates that the CPython interpreter during parsing and building of Abstract Syntax Tree folded the constant expression, `24 * 60 * 60` and replaced it with the evaluated value `86400`.\n\n### Scope of Constant Folding\n\nPython tries to fold every single constant expression present but there are some cases where even though the expression is constant, but Python chooses not to fold it. For example, Python does not fold `x = 4 ** 64` while it does fold `x = 2 ** 64`. \n\nApart from the arithmetic expressions, Python also folds expressions involving Strings and Tuples, where constant string expressions till the length `4096` are folded.\n\n```python\n>>> a = \"-\" * 4096   # folded\n>>> a = \"-\" * 4097   # not folded\n>>> a = \"--\" * 4096  # not folded\n```\n\n# Internals of Constant Folding\n\nNow we shift our focus to the internals and find exactly where and how CPython implements Constant Folding. All AST optimizations, including Constant Folding, can be found in file [ast_opt.c](https://github.com/python/cpython/blob/master/Python/ast_opt.c). The base function starting it all is `astfold_expr` which folds any and every expression that Python source has. The function recursively goes through the AST and tries to fold every constant expression, as seen in the snippet below.\n\n![https://user-images.githubusercontent.com/4745789/103898628-38922200-511b-11eb-965f-fb4d46d3c45c.png](https://user-images.githubusercontent.com/4745789/103898628-38922200-511b-11eb-965f-fb4d46d3c45c.png)\n\nThe `astfold_expr` before folding the expression at hand, tries to fold its child expressions (operands) and then delegates the folding to the corresponding specific expression folding function. The operation-specific folding function evaluates the expression and returns the evaluated constant value, which is then put into the AST.\n\nFor example, whenever `astfold_expr` encounters a binary operation, it recursively folds the two child operands (expressions) before evaluating the expression at hand using `fold_binop`. The function `fold_binop` returns the evaluated constant value as seen in the snippet below.\n\n![https://user-images.githubusercontent.com/4745789/103898745-670ffd00-511b-11eb-88a9-f741157473b3.png](https://user-images.githubusercontent.com/4745789/103898745-670ffd00-511b-11eb-88a9-f741157473b3.png)\n\n`fold_binop` function folds the binary operation by checking the kind of operator at hand and then invoking the corresponding evaluation function on them. For example, if the operation at hand is an addition then, to evaluate the final value, it invokes `PyNumber_Add` on both its left and right operands.\n\n### What makes this elegant?\n\nInstead of writing special logic to handle certain patterns or types to fold constant expressions efficiently, CPython invokes the same general code. For example, it invokes the same usual `PyNumber_Add` function while folding that it does to perform the usual addition operation.\n\nCPython has thus eradicated the need to write special functions to handle constant folding by making sure its code and evaluation process is structured in such a way that the general-purpose code itself can handle the evaluation of constant expressions.\n\n# References\n\n- [Constant Folding](https://en.wikipedia.org/wiki/Constant_folding)\n- [CPython Optimizations](https://stummjr.org/post/cpython-optimizations/)\n- [Python dis module and constant folding](https://yasoob.me/2019/02/26/python-dis-module-and-constant-folding/)\n- [The simple way CPython does constant folding](https://utcc.utoronto.ca/~cks/space/blog/python/CPythonConstantFolding)\n- [A constant folding optimization pass for the AST](https://bugs.python.org/issue1346238)\n",
    "similar": [
      "python-prompts",
      "python-caches-integers",
      "python-iterable-integers",
      "fsm"
    ]
  },
  {
    "id": 30,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "string-interning",
    "title": "String Interning in Python",
    "description": "Every programming language aims to be performant and Python is no exception. In this essay, we dive deep into Python internals and find out how Python makes its interpreter performant using a technique called String Interning.",
    "gif": "https://media.giphy.com/media/KRNBl0iSS8gg0/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/102710262-1c971f80-42d7-11eb-9ee4-dcefd540e869.png",
    "released_at": "2020-12-20",
    "total_views": 1480,
    "body": "Every programming language aims to be performant in its niche and achieving superior performance requires a bunch of compiler and interpreter level optimizations. Since character Strings are an integral part of any programming language, having the ability to perform string operations quickly elevates the overall performance.\n\nIn this essay, we dive deep into Python internals and find out how Python makes its interpreter performant using a technique called [String Interning](https://en.wikipedia.org/wiki/String_interning). This essay not only aims to put forth Python internals but also aims to make the reader comfortable in navigating through Python's source code; so expect a lot of code snippets taken from [CPython](https://github.com/python/cpython/).\n\n# String Interning\n\nString Interning is a compiler/interpreter optimization method that makes common string processing tasks space and time efficient by [caching](https://en.wikipedia.org/wiki/Cache_(computing)) them. Instead of creating a new copy of string every time, this optimization method dictates to keep just one copy of string for every *appropriate* [immutable](https://en.wikipedia.org/wiki/Immutable_object) distinct value and use the pointer reference wherever referred.\n\nThe single copy of each string is called its ***intern*** and hence the name String Interning. The lookup of string intern, may or may not be exposed as a public interfaced method. Modern programming languages like Java, Python, PHP, Ruby, Julia, and many more, performs String Interning to make their compilers and interpreters performant.\n\n![https://user-images.githubusercontent.com/4745789/102705512-d1691680-42ae-11eb-825f-1e032a7c12c5.png](https://user-images.githubusercontent.com/4745789/102705512-d1691680-42ae-11eb-825f-1e032a7c12c5.png)\n\n## Why should Strings be interned?\n\n*String Interning speeds up string comparisons*. Without interning if we were to compare two strings for equality the complexity of it would shoot up to `O(n)` where we examine every character from both the strings to decide their equality. But if the strings are interned, instead of checking every character, equal strings will have the same object reference so just a pointer quality check would be sufficient to say if two string literals are equal. Since this is a very common operation, this is typically implemented as a pointer equality test, using just a single machine instruction with no memory reference at all.\n\n*String Interning reduces the memory footprint.* Instead of filling memory with redundant String objects, Python optimizes memory footprint by sharing and reusing already defined objects as dictated by the [flyweight design pattern](https://en.wikipedia.org/wiki/Flyweight_pattern).\n\n# String Interning in Python\nJust like most other modern programming languages, Python also does [String Interning](https://en.wikipedia.org/wiki/String_interning) to gain a performance boost. In Python, we can find if two objects are referring to the same in-memory object using the `is` operator. So if two string objects refer to the same in-memory object, the `is` operator yields `True` otherwise `False`.\n\n```bash\n>>> 'python' is 'python'\nTrue\n```\n\nWe can use this particular operator to test which all strings are interned and which are not. In CPython, String Interning is implemented through the following function, declared in [unicodeobject.h](https://github.com/python/cpython/blob/master/Include/unicodeobject.h) and defined in [unicodeobject.c](https://github.com/python/cpython/blob/master/Objects/unicodeobject.c).\n\n```cpp\nPyAPI_FUNC(void) PyUnicode_InternInPlace(PyObject **);\n```\n\nIn order to check if a String is interned, CPython implements a macro named `PyUnicode_CHECK_INTERNED`, again defined in [unicodeobject.h](https://github.com/python/cpython/blob/master/Include/unicodeobject.h). The macro suggests that the Python maintains a member named `interned` in `PyASCIIObject` structure whose value suggests if the corresponding String is interned or not.\n\n```cpp\n#define PyUnicode_CHECK_INTERNED(op) \\\n    (((PyASCIIObject *)(op))->state.interned)\n```\n\n## Internals of String Interning\n\nIn CPython, the String references are stored, accessed, and managed using a Python dictionary named `interned`. This dictionary is lazily initialized upon the first String Intern invocation and holds the reference to all the interned String objects.\n\n### Interning the String\n\nThe core function responsible for interning the String is named `PyUnicode_InternInPlace` defined in [unicodeobject.c](https://github.com/python/cpython/blob/master/Objects/unicodeobject.c) that upon invocation lazily builds the main dictionary `interned` to hold all interned strings and then registers the object into it with the key and the value both set as the same object reference. The following function snippet shows the String Interning process as implemented in Python.\n\n```cpp\nvoid\nPyUnicode_InternInPlace(PyObject **p)\n{\n    PyObject *s = *p;\n\n    .........\n\n    // Lazily build the dictionary to hold interned Strings\n    if (interned == NULL) {\n        interned = PyDict_New();\n        if (interned == NULL) {\n            PyErr_Clear();\n            return;\n        }\n    }\n\n    PyObject *t;\n\n    // Make an entry to the interned dictionary for the\n    // given object\n    t = PyDict_SetDefault(interned, s, s);\n\n    .........\n    \n    // The two references in interned dict (key and value) are\n    // not counted by refcnt.\n    // unicode_dealloc() and _PyUnicode_ClearInterned() take\n    // care of this.\n    Py_SET_REFCNT(s, Py_REFCNT(s) - 2);\n\n    // Set the state of the string to be INTERNED\n    _PyUnicode_STATE(s).interned = SSTATE_INTERNED_MORTAL;\n}\n```\n\n### Cleanup of Interned Strings\n\nThe cleanup function iterates over all the Strings held in the `interned` dictionary, adjusts the reference counts of the object, and marks them as `NOT_INTERNED` allowing them to be garbage collected. Once all the strings are marked as `NOT_INTERNED`, the `interned` dictionary is cleared and deleted. The cleanup function is defined in [unicodeobject.c](https://github.com/python/cpython/blob/master/Objects/unicodeobject.c) by the name `_PyUnicode_ClearInterned`.\n\n```cpp\nvoid\n_PyUnicode_ClearInterned(PyThreadState *tstate)\n{\n    .........\n\n    // Get all the keys to the interned dictionary\n    PyObject *keys = PyDict_Keys(interned);\n\n    .........\n\n    // Interned Unicode strings are not forcibly deallocated;\n    // rather, we give them their stolen references back\n    // and then clear and DECREF the interned dict.\n\n    for (Py_ssize_t i = 0; i < n; i++) {\n        PyObject *s = PyList_GET_ITEM(keys, i);\n\n        .........\n\n        switch (PyUnicode_CHECK_INTERNED(s)) {\n        case SSTATE_INTERNED_IMMORTAL:\n            Py_SET_REFCNT(s, Py_REFCNT(s) + 1);\n            break;\n        case SSTATE_INTERNED_MORTAL:\n            // Restore the two references (key and value) ignored\n            // by PyUnicode_InternInPlace().\n            Py_SET_REFCNT(s, Py_REFCNT(s) + 2);\n            break;\n        case SSTATE_NOT_INTERNED:\n            /* fall through */\n        default:\n            Py_UNREACHABLE();\n        }\n\n        // marking the string to be NOT_INTERNED\n        _PyUnicode_STATE(s).interned = SSTATE_NOT_INTERNED;\n    }\n\n    // decreasing the reference to the initialized and\n    // access keys object.\n    Py_DECREF(keys);\n\n    // clearing the dictionary\n    PyDict_Clear(interned);\n\n    // clearing the object interned\n    Py_CLEAR(interned);\n}\n```\n\n## String Interning in Action\n\nNow that we understand the internals of String Interning and Cleanup, we find out what all Strings are interned in Python. To discover the spots all we do is grep for the function invocation for `PyUnicode_InternInPlace` in the CPython source code and peek at the neighboring code. Here is a list of interesting spots where String Interning happens in Python.\n\n### Variables, Constants, and Function Names\n\nCPython performs String Interning on constants such as Function Names, Variable Names, String Literals, etc. Following is the snippet from [codeobject.c](https://github.com/python/cpython/blob/master/Objects/codeobject.c) that suggests that when a new `PyCode` object is created the interpreter is interning all the compile-time constants, names, and literals.\n\n```cpp\nPyCodeObject *\nPyCode_NewWithPosOnlyArgs(int argcount, int posonlyargcount, int kwonlyargcount,\n                          int nlocals, int stacksize, int flags,\n                          PyObject *code, PyObject *consts, PyObject *names,\n                          PyObject *varnames, PyObject *freevars, PyObject *cellvars,\n                          PyObject *filename, PyObject *name, int firstlineno,\n                          PyObject *linetable)\n{\n\n    ........\n\n    if (intern_strings(names) < 0) {\n        return NULL;\n    }\n\n    if (intern_strings(varnames) < 0) {\n        return NULL;\n    }\n\n    if (intern_strings(freevars) < 0) {\n        return NULL;\n    }\n\n    if (intern_strings(cellvars) < 0) {\n        return NULL;\n    }\n\n    if (intern_string_constants(consts, NULL) < 0) {\n        return NULL;\n    }\n\n    ........\n\n}\n```\n\n### Dictionary Keys\n\nCPython also interns thee Strings which keys of any dictionary object. Upon putting an item in the dictionary the interpreter String Interning on the key against which item is stored. The following code is taken from [dictobject.c](https://github.com/python/cpython/blob/master/Objects/dictobject.c) showcasing the exact behavior.\n\nFun Fact: There is a comment next to the `PyUnicode_InternInPlace` function call that suggests if we really need to intern all the keys in all the dictionaries.\n\n```cpp\nint\nPyDict_SetItemString(PyObject *v, const char *key, PyObject *item)\n{\n    PyObject *kv;\n    int err;\n    kv = PyUnicode_FromString(key);\n    if (kv == NULL)\n        return -1;\n\n    // Invoking String Interning on the key\n    PyUnicode_InternInPlace(&kv); /* XXX Should we really? */\n\n    err = PyDict_SetItem(v, kv, item);\n    Py_DECREF(kv);\n    return err;\n}\n```\n\n### Attributes of any Object\n\nObjects in Python can have attributes that can be explicitly set using `setattr` function or are implicitly set as part of Class members or as pre-defined functions on data types. CPython interns all these attribute names, so as to make lookup blazing fast. Following is the snippet of the function `PyObject_SetAttr` responsible for setting a new attribute to a Python object, as defined in the file [object.c](https://github.com/python/cpython/blob/master/Objects/object.c).\n\n```cpp\nint\nPyObject_SetAttr(PyObject *v, PyObject *name, PyObject *value)\n{\n\n    ........\n\n    PyUnicode_InternInPlace(&name);\n\n    ........\n}\n```\n\n### Explicit Interning\n\nPython also allows explicit String Interning through the function `intern` defined in `sys` module. When this function is invoked with any String object, the provided String is interned. Following is the code snippet from the file [sysmodule.c](https://github.com/python/cpython/blob/master/Python/sysmodule.c) that shows String Interning happening in `sys_intern_impl`.\n\n```cpp\nstatic PyObject *\nsys_intern_impl(PyObject *module, PyObject *s)\n{\n\n    ........\n\n    if (PyUnicode_CheckExact(s)) {\n        Py_INCREF(s);\n        PyUnicode_InternInPlace(&s);\n        return s;\n    }\n\n    ........\n}\n```\n\n## Extra nuggets on String Interning\n\n*Only compile-time strings are interned*. Strings that are specified during interpretation or compile-time are interned while dynamically created strings are not.\n\n*Strings having ASCII letters and underscores are interned*. During compile time when string literals are observed for interning, [CPython](https://github.com/python/cpython/blob/master/Objects/codeobject.c) ensures that it only interns the literals matching the regular expression `[a-zA-Z0-9_]*` as they closely resemble Python identifiers.\n\nComments on how CPython does String Interning internally (as discussed in the [Video](https://youtu.be/QpGK69LzfpY)) can be found in [this PR](https://github.com/arpitbbhayani/cpython/pull/9]).\n\n# References\n\n- [String Interning](https://en.wikipedia.org/wiki/String_interning)\n- [CPython Optimizations](https://stummjr.org/post/cpython-optimizations/)\n- [Python Objects Part III: String Interning](https://medium.com/@bdov_/https-medium-com-bdov-python-objects-part-iii-string-interning-625d3c7319de)\n- [The internals of Python string interning](http://guilload.com/python-string-interning/)\n",
    "similar": [
      "i-changed-my-python",
      "python-caches-integers",
      "python-iterable-integers",
      "super-long-integers"
    ]
  },
  {
    "id": 45,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "python-iterable-integers",
    "title": "Making Python Integers Iterable",
    "description": "In Python, Integers are not iterables but we can make them iterable by implementing __iter__ function. In this essay, we change Python's source code and implement iter function for integers.",
    "gif": "https://media.giphy.com/media/k4ta29T68xlfi/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/84585100-bf06af80-ae29-11ea-8797-16c70aee5cc4.png",
    "released_at": "2020-06-14",
    "total_views": 1790,
    "body": "Iterables in Python are objects and containers that could be stepped through one item at a time, usually using a `for ... in` loop. Not all objects can be iterated, for example - we cannot iterate an integer, it is a singular value. The best we can do here is iterate on a range of integers using the `range` type which helps us iterate through all integers in the range `[0, n)`.\n\nSince integers, individualistically, are not iterable, when we try to do a `for x in 7`, it raises an exception stating `TypeError: 'int' object is not iterable`. So what if, we change the Python's source code and make integers iterable, say every time we do a `for x in 7`, instead of raising an exception it actually iterates through the values `[0, 7)`. In this essay, we would be going through exactly that, and the entire agenda being:\n\n- What is a Python iterable?\n- What is an iterator protocol?\n- Changing Python's source code and make integers iterable, and\n- Why it might be a bad idea to do so?\n\n# Python Iterables\n\nAny object that could be iterated is an Iterable in Python. The list has to be the most popular iterable out there and it finds its usage in almost every single Python application - directly or indirectly. Even before the first user command is executed, the Python interpreter, while booting up, has already created `406` lists, for its internal usage.\n\nIn the example below, we see how a list `a` is iterated through using a `for ... in` loop and each element can be accessed via variable `x`. \n\n```python\n>>> a = [2, 3, 5, 7, 11, 13]\n>>> for x in a: print(x, end=\" \")\n2 3 5 7 11 13\n```\n\nSimilar to `list`, `range` is a python type that allows us to iterate on integer values starting with the value `start` and going till `end` while stepping over `step` values at each time. `range` is most commonly used for implementing a C-like `for` loop in Python. In the example below, the `for` loop iterates over a `range` that starts from `0`, goes till `7` with a step of  `1` - producing the sequence `[0, 7)`.\n\n```python\n# The range(0, 7, 1) will iterate through values 0 to 6 and every time\n# it will increment the current value by 1 i.e. the step.\n>>> for x in range(0, 7, 1): print(x, end=\" \")\n0 1 2 3 4 5 6\n```\n\nApart from `list` and `range` other [iterables](https://docs.python.org/3/library/stdtypes.html#sequence-types-list-tuple-range) are - `tuple`, `set`, `frozenset`, `str`, `bytes`, `bytearray`, `memoryview`, and `dict`. Python also allows us to create custom iterables by making objects and types follow the [Iterator Protocol](https://docs.python.org/3/c-api/iter.html).\n\n# Iterators and Iterator Protocol\n\nPython, keeping things simple, defines iterable as any object that follows the [Iterator Protocol](https://docs.python.org/3/c-api/iter.html); which means the object or a container implements the following functions\n\n- `__iter__` should return an iterator object having implemented the `__next__` method\n- `__next__` should return the next item of the iteration and if items are exhausted then raise a `StopIteration` exception.\n\nSo, in a gist, `__iter__` is something that makes any python object iterable; hence to make integers iterable we need to have `__iter__` function set for integers.\n\n# Iterable in CPython\n\nThe most famous and widely used implementation of Python is [CPython](https://github.com/python/cpython/) where the core is implemented in pure C. Since we need to make changes to one of the core datatypes of Python, we will be modifying CPython, add `__iter__` function to an Integer type, and rebuild the binary. But before jumping into the implementation, it is important to understand a few fundamentals.\n\n## The `PyTypeObject`\n\nEvery object in Python is associated with a type and each [type](https://docs.python.org/3/c-api/typeobj.html#type-objects) is an instance of a struct named [PyTypeObject](https://docs.python.org/3/c-api/typeobj.html). A new instance of this structure is effectively a new type in python. This structure holds a few meta information and a bunch of C function pointers - each implementing a small segment of the type's functionality. Most of these \"slots\" in the structure are optional which could be filled by putting appropriate function pointers and driving the corresponding functionality.\n\n## The `tp_iter` slot\n\nAmong all the slots available, the slot that interests us is the `tp_iter` slot which can hold a pointer to a function that returns an iterator object. This slot corresponds to the `__iter__` function which effectively makes the object iterable. A non `NULL` value of this slot indicates iterability. The `tp_iter` holds the function with the following signature\n\n```cpp\nPyObject * tp_iter(PyObject *);\n```\n\nIntegers in Python do not have a fixed size; rather the size of integer depends on the value it holds. [How Python implements super long integers](https://arpitbhayani.me/blogs/super-long-integers) is a story on its own but the core implementation can be found at [longobject.c](https://github.com/python/cpython/blob/master/Objects/longobject.c). The instance of `PyTypeObject` that defines integer/long type is `PyLong_Type` and has its `tp_iter` slot set to `0` i.e. `NULL` which asserts the fact that Integers in python are not iterable.\n\n```cpp\nPyTypeObject PyLong_Type = {\n    ...\n\n    \"int\",                                      /* tp_name */\n    offsetof(PyLongObject, ob_digit),           /* tp_basicsize */\n    sizeof(digit),                              /* tp_itemsize */\n    ...\n    0,                                          /* tp_iter */\n    ...\n};\n```\n\nThis `NULL` value for `tp_iter` makes `int` object not iterable and hence if this slot was occupied by an appropriate function pointer with the aforementioned signature, this could well make any integer iterable.\n\n# Implementing `long_iter`\n\nNow we implement the `tp_iter` function on integer type, naming it `long_iter`, that returns an iterator object, as required by the convention. The core functionality we are looking to implement here is - when an integer `n` is iterated, it should iterate through the sequence `[0, n)` with step `1`. This behavior is very close to the pre-defined `range` type, that iterates over a range of integer values, more specifically a `range` that starts at `0`, goes till `n` with a step of `1`.\n\nWe define a utility function in `rangeobject.c` that, given a python integer, returns an instance of `longrangeiterobject` as per our specifications. This utility function will instantiate the `longrangeiterobject` with start as `0`, ending at the long value given in the argument, and step as `1`. The utility function is as illustrated below.\n\n```cpp\n/*\n *  PyLongRangeIter_ZeroToN creates and returns a range iterator on long\n *  iterating on values in the range [0, n).\n *\n *  The function creates and returns a range iterator from 0 till the\n *  provided long value.\n */\nPyObject *\nPyLongRangeIter_ZeroToN(PyObject *long_obj)\n{\n    // creating a new instance of longrangeiterobject\n    longrangeiterobject *it;\n    it = PyObject_New(longrangeiterobject, &PyLongRangeIter_Type);\n\n    // if unable to allocate memoty to it, return NULL.\n    if (it == NULL)\n        return NULL;\n\n    // we set the start to 0\n    it->start = _PyLong_Zero;\n\n    // we set the step to 1\n    it->step = _PyLong_One;\n\n    // we set the index to 0, since we want to always start from the first\n    // element of the iteration\n    it->index = _PyLong_Zero;\n\n    // we set the total length of iteration to be equal to the provided value\n    it->len = long_obj;\n\n    // we increment the reference count for each of the values referenced\n    Py_INCREF(it->start);\n    Py_INCREF(it->step);\n    Py_INCREF(it->len);\n    Py_INCREF(it->index);\n\n    // downcast the iterator instance to PyObject and return\n    return (PyObject *)it;\n}\n```\n\nThe utility function `PyLongRangeIter_ZeroToN` is defined in `rangeobject.c` and will be declared in `rangeobject.h` so that it can be used across the CPython. Declaration of function in `rangeobject.h` using standard Python macros goes like this\n\n```cpp\nPyAPI_FUNC(PyObject *)   PyLongRangeIter_ZeroToN(PyObject *);\n```\n\nThe function occupying the `tp_iter` slot will receive the `self` object as the input argument and is expected to return the iterator instance. Hence, the `long_iter` function will receive the python integer object (self) that is being iterated as an input argument and it should return the iterator instance. Here we would use the utility function `PyLongRangeIter_ZeroToN`, we just defined, which is returning us an instance of range iterator. The entire `long_iter` function could be defined as\n\n```cpp\n/*\n *  long_iter creates an instance of range iterator using PyLongRangeIter_ZeroToN\n *  and returns the iterator instance.\n *\n *  The argument to the `tp_iter` is the `self` object and since we are trying to\n *  iterate an integer here, the input argument to `long_iter` will be the\n *  PyObject of type PyLong_Type, holding the integer value.\n */\nstatic PyObject * long_iter(PyObject *long_obj)\n{\n    return PyLongRangeIter_ZeroToN(long_obj);\n}\n```\n\nNow that we have `long_iter` defined, we can place the function on the `tp_iter` slot of `PyLong_Type` that enables the required iterability on integers.\n\n```cpp\nPyTypeObject PyLong_Type = {\n    ...\n\n    \"int\",                                      /* tp_name */\n    offsetof(PyLongObject, ob_digit),           /* tp_basicsize */\n    sizeof(digit),                              /* tp_itemsize */\n    ...\n    long_iter,                                  /* tp_iter */\n    ...\n};\n```\n\n## Consolidated flow\n\nOnce we have everything in place, the entire flow goes like this -\n\nEvery time an integer is iterated, using any iteration method - for example `for ... in`, it would check the `tp_iter` of the `PyLongType` and since now it holds the function pointer `long_iter`, the function will be invoked. This invocation will return an iterator object of type `longrangeiterobject` with a fixed start, index, and step values - which in pythonic terms is effectively a `range(0, n, 1)`.  Hence the `for x in 7` is inherently evaluated as `for x in range(0, 7, 1)` allowing us to iterate integers.\n\n> These changes are also hosted on a remote branch [cpython@02-long-iter](https://github.com/arpitbbhayani/cpython/tree/02-long-iter) and Pull Request holding the `diff` can be found [here](https://github.com/arpitbbhayani/cpython/pull/7).\n\n# Integer iteration in action\n\nOnce we build a new python binary with the aforementioned changes, we can see iterable integers in actions. Now when we do `for x in 7`, instead of raising an exception, it actually iterates through values `[0, 7)`.\n\n```cpp\n>>> for i in 7: print(i, end=\" \");\n0 1 2 3 4 5 6\n\n# Since integers are now iterable, we can create a list of [0, 7) using `list`\n# Internally `list` tries to iterate on the given object i.e. `7`\n# now that the iteration is defined as [0, 7) we get the list from\n# from iteration, instead of an exception\n>>> list(7)\n[0, 1, 2, 3, 4, 5, 6]\n```\n\n# Why it is not a good idea\n\nAlthough it seems fun, and somewhat useful, to have iterable integers, it is really not a great idea. The core reason for this is that it makes unpacking unpredictable. Unpacking is when you unpack an iterable and assign it to multiple variables. For example: `a, b = 3, 4` will assign 3 to a and 4 to b. So assigning `a, b = 7` should be an error because there is just one value on the right side and multiple on the left.\n\nUnpacking treats right-hand size as iterable and tries to iterate on it; and now since Integers are iterable the right-hand side, post iteration yields 7 values which the left-hand side has mere 2 variables; Hence it raises an exception `ValueError: too many values to unpack (expected 2)`.\n\nThings would work just fine if we do `a, b = 2` as now the right-hand side, post iteration, has two values, and the left-hand side has two variables. Thus two very similar statements result in two very different outcomes, making unpacking unpredictable.\n\n```python\n>>> a, b = 7\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: too many values to unpack (expected 2)\n\n>>> a, b = 2\n>>> a, b\n0, 1\n```\n\n# Conclusion\n\nIn this essay, we modified the Python's source code and made integers iterable. Even though it is not a good idea to do so, but it is fun to play around with the code and make changes in our favorite programming language. It helps us get a detailed idea about core python implementation and may pave the way for us to become a Python core developer. This is one of many articles in Python Internals series - [How python implements super long integers?](https://arpitbhayani.me/blogs/super-long-integers) and [Python Caches Integers](https://arpitbhayani.me/blogs/python-caches-integers).\n\n# References\n - [PyTypeObject](https://docs.python.org/3/c-api/type.html#c.PyTypeObject)\n - [Python Type Objects](https://docs.python.org/3/c-api/typeobj.html)\n - [Python Iterator Protocol](https://docs.python.org/3/c-api/iter.html)\n - [CPython with long_iter](https://github.com/arpitbbhayani/cpython/pull/7)\n",
    "similar": [
      "python-caches-integers",
      "python-prompts",
      "constant-folding-python",
      "i-changed-my-python"
    ]
  },
  {
    "id": 49,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "python-caches-integers",
    "title": "Integer Caching in Python",
    "description": "To gain a performance boost and avoid reallocation of frequently used integers, Python creates singleton instances of small integer values and uses them by reference.",
    "gif": "https://media.giphy.com/media/l378kmO7gdbXaesXS/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/82141979-a620d380-9856-11ea-9a4a-32399c0c01b8.png",
    "released_at": "2020-05-17",
    "total_views": 1824,
    "body": "An integer in Python is not a traditional 2, 4, or 8-byte implementation but rather it is implemented as an array of digits in base 2<sup>30</sup> which enables Python to support [super long integers](https://arpitbhayani.me/blogs/super-long-integers). Since there is no explicit limit on the size, working with integers in Python is extremely convenient as we can carry out operations on very long numbers without worrying about integer overflows. This convenience comes at a cost of allocation being expensive and trivial operations like addition, multiplication, division being inefficient.\n\nEach integer in python is implemented as a C structure illustrated below.\n\n```cpp\nstruct _longobject {\n    ...\n    Py_ssize_t    ob_refcnt;      // <--- holds reference count\n    ...\n    Py_ssize_t    ob_size;        // <--- holds number of digits\n    digit         ob_digit[1];    // <--- holds the digits in base 2^30\n};\n```\n\nIt is observed that smaller integers in the range -5 to 256, are used very frequently as compared to other longer integers and hence to gain performance benefit Python preallocates this range of integers during initialization and makes them singleton and hence every time a smaller integer value is referenced instead of allocating a new integer it passes the reference of the corresponding singleton.\n\nHere is what [Python's official documentation](https://docs.python.org/3/c-api/long.html#c.PyLong_FromLong) says about this preallocation\n\n> The current implementation keeps an array of integer objects for all integers between -5 and 256 when you create an int in that range you actually just get back a reference to the existing object.\n\nIn the CPython's [source code](https://github.com/python/cpython/) this optimization can be traced in the macro `IS_SMALL_INT` and the function [`get_small_int`](https://github.com/python/cpython/blob/master/Objects/longobject.c#L40) in [longobject.c](https://github.com/python/cpython/blob/master/Objects/longobject.c). This way python saves a lot of space and computation for commonly used integers.\n\n# Verifying smaller integers are indeed a singleton\nFor a CPython implementation, the in-built [`id` function](https://docs.python.org/3/library/functions.html#id) returns the address of the object in memory. This means if the smaller integers are indeed singleton then the `id` function should return the same memory address for two instances of the same value while multiple instances of larger values should return different ones, and this is indeed what we observe\n\n```py\n>>> x, y = 36, 36\n>>> id(x) == id(y)\nTrue\n\n\n>>> x, y = 257, 257\n>>> id(x) == id(y)\nFalse\n```\n\nThe singletons can also be seen in action during computations. In the example below, we reach the same target value `6` by performing two operations on three different numbers, 2, 4, and 10, and we see the `id` function returning the same memory reference in both the cases.\n\n```py\n>>> a, b, c = 2, 4, 10\n>>> x = a + b\n>>> y = c - b\n>>> id(x) == id(y)\nTrue\n```\n\n# Verifying if these integers are indeed referenced often\nWe have established that Python indeed is consuming smaller integers through their corresponding singleton instances, without reallocating them every time. Now we verify the hypothesis that Python indeed saves a bunch of allocations during its initialization through these singletons. We do this by checking the reference counts of each of the integer values.\n\n## Reference Counts\nReference count holds the number of different places there are that have a reference to the object. Every time an object is referenced the `ob_refcnt`, in its structure, is increased by `1`, and when dereferenced the count is decreased by `1`. When the reference count becomes `0` the object is garbage collected.\n\nIn order to get the current reference count of an object, we use the function `getrefcount` from the `sys` module.\n\n```py\n>>> ref_count = sys.getrefcount(50)\n11\n```\n\nWhen we do this for all the integers in range -5 to 300 we get the following distribution\n\n![Reference counts of interger values](https://user-images.githubusercontent.com/4745789/82141240-1e38ca80-9852-11ea-8133-fd8e1b26fc01.png)\n\nThe above graph suggests that the reference count of smaller integer values is high indicating heavy usage and it decreases as the value increases which asserts the fact that there are many objects referencing smaller integer values as compared to larger ones during python initialization.\n\nThe value `0` is referenced the most - `359` times while along the long tail we see spikes in reference counts at powers of 2 i.e. 32, 64, 128, and 256. Python during its initialization itself requires small integer values and hence by creating singletons it saves about `1993` allocations.\n\nThe reference counts were computed on a freshly spun python which means during initialization it requires some integers for computations and these are facilitated by creating singleton instances of smaller values.\n\nIn usual programming, the smaller integer values are accessed much more frequently than larger ones, having singleton instances of these saves python a bunch of computation and allocations.\n\n# References\n - [Python Object Types and Reference Counts](https://docs.python.org/3/c-api/intro.html#objects-types-and-reference-counts)\n - [How python implements super-long integers](https://arpitbhayani.me/blogs/super-long-integers)\n - [Why Python is Slow: Looking Under the Hood](http://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/)\n",
    "similar": [
      "python-prompts",
      "python-iterable-integers",
      "constant-folding-python",
      "i-changed-my-python"
    ]
  },
  {
    "id": 60,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "function-overloading",
    "title": "Function Overloading in Python",
    "description": "Python natively does not support function overloading - having multiple functions with the same name. Today we see how we can implement and add this functionality to Python by using common language constructs like decorators and dictionaries.",
    "gif": "https://media.giphy.com/media/WtCHRSPCuqS8E/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/73909201-04423000-48d2-11ea-8bd0-d7c25f6435c1.png",
    "released_at": "2020-02-07",
    "total_views": 12359,
    "body": "Function overloading is the ability to have multiple functions with the same name but with different signatures/implementations. When an overloaded function `fn` is called, the runtime first evaluates the arguments/parameters passed to the function call and judging by this invokes the corresponding implementation.\n\n```cpp\nint area(int length, int breadth) {\n  return length * breadth;\n}\n\nfloat area(int radius) {\n  return 3.14 * radius * radius;\n}\n```\n\nIn the above example (written in C++), the function `area` is overloaded with two implementations; one accepts two arguments (both integers) representing the length and the breadth of a rectangle and returns the area; while the other function accepts an integer radius of a circle. When we call the function `area` like `area(7)` it invokes the second function while `area(3, 4)` invokes the first.\n\n### Why no Function Overloading in Python?\nPython does not support function overloading. When we define multiple functions with the same name, the later one always overrides the prior and thus, in the namespace, there will always be a single entry against each function name. We see what exists in Python namespaces by invoking functions `locals()` and `globals()`, which returns local and global namespace respectively.\n\n```py\ndef area(radius):\n  return 3.14 * radius ** 2\n\n>>> locals()\n{\n  ...\n  'area': <function area at 0x10476a440>,\n  ...\n}\n```\n\nCalling the function `locals()` after defining a function we see that it returns a dictionary of all variables defined in the local namespace. The key of the dictionary is the name of the variable and value is the reference/value of that variable. When the runtime encounters another function with the same name it updates the entry in the local namespace and thus removes the possibility of two functions co-existing. Hence python does not support Function overloading. It was the design decision made while creating language but this does not stop us from implementing it, so let's overload some functions.\n\n# Implementing Function Overloading in Python\nWe know how Python manages namespaces and if we would want to implement function overloading, we would need to\n\n - manage the function definitions in a maintained virtual namespace\n - find a way to invoke the appropriate function as per the arguments passed to it\n\nTo keep things simple, we will implement function overloading where the functions with the same name are distinguished by the **number of arguments** it accepts.\n\n## Wrapping the function\nWe create a class called `Function` that wraps any function and makes it callable through an overridden `__call__` method and also exposes a method called `key` that returns a tuple which makes this function unique in entire codebase.\n\n```py\nfrom inspect import getfullargspec\n\nclass Function(object):\n  \"\"\"Function is a wrap over standard python function.\n  \"\"\"\n  def __init__(self, fn):\n    self.fn = fn\n\n  def __call__(self, *args, **kwargs):\n    \"\"\"when invoked like a function it internally invokes\n    the wrapped function and returns the returned value.\n    \"\"\"\n    return self.fn(*args, **kwargs)\n\n  def key(self, args=None):\n    \"\"\"Returns the key that will uniquely identify\n    a function (even when it is overloaded).\n    \"\"\"\n    # if args not specified, extract the arguments from the\n    # function definition\n    if args is None:\n      args = getfullargspec(self.fn).args\n\n    return tuple([\n      self.fn.__module__,\n      self.fn.__class__,\n      self.fn.__name__,\n      len(args or []),\n    ])\n```\n\nIn the snippet above, the `key` function returns a tuple that uniquely identifies the function in the codebase and holds\n\n - the module of the function\n - class to which the function belongs\n - name of the function\n - number of arguments the function accepts\n\nThe overridden `__call__` method invokes the wrapped function and returns the computed value (nothing fancy here right now). This makes the instance callable just like the function and it behaves exactly like the wrapped function.\n\n```py\ndef area(l, b):\n  return l * b\n\n>>> func = Function(area)\n>>> func.key()\n('__main__', <class 'function'>, 'area', 2)\n>>> func(3, 4)\n12\n```\n\nIn the example above, the function `area` is wrapped in `Function` instantiated in `func`. The `key()` returns the tuple whose first element is the module name `__main__`, second is the class `<class 'function'>`, the third is the function name `area` while the fourth is the number of arguments that function `area` accepts which is `2`.\n\nThe example also shows how we could just call the instance `func`, just like the usual `area` function, with arguments `3` and `4` and get the response `12`, which is exactly what we'd get is we would have called `area(3, 4)`. This behavior would come in handy in the later stage when we play with decorators.\n\n## Building the virtual Namespace\nVirtual Namespace, we build here, will store all the functions we gather during the definition phase. As there be only one namespace/registry we create a singleton class that holds the functions in a dictionary whose key will not be just a function name but the tuple we get from the `key` function, which contains elements that uniquely identify function in the entire codebase. Through this, we will be able to hold functions in the registry even if they have the same name (but different arguments) and thus facilitating function overloading.\n\n```py\nclass Namespace(object):\n  \"\"\"Namespace is the singleton class that is responsible\n  for holding all the functions.\n  \"\"\"\n  __instance = None\n\n  def __init__(self):\n    if self.__instance is None:\n      self.function_map = dict()\n      Namespace.__instance = self\n    else:\n      raise Exception(\"cannot instantiate a virtual Namespace again\")\n\n  @staticmethod\n  def get_instance():\n    if Namespace.__instance is None:\n      Namespace()\n    return Namespace.__instance\n\n  def register(self, fn):\n    \"\"\"registers the function in the virtual namespace and returns\n    an instance of callable Function that wraps the\n    function fn.\n    \"\"\"\n    func = Function(fn)\n    self.function_map[func.key()] = fn\n    return func\n```\n\nThe `Namespace` has a method `register` that takes function `fn` as an argument, creates a unique key for it, stores it in the dictionary and returns `fn` wrapped within an instance of `Function`. This means the return value from the `register` function is also callable and (till now) its behavior is exactly the same as the wrapped function `fn`.\n\n```py\ndef area(l, b):\n  return l * b\n\n>>> namespace = Namespace.get_instance()\n>>> func = namespace.register(area)\n>>> func(3, 4)\n12\n```\n\n## Using decorators as a hook\nNow that we have defined a virtual namespace with an ability to register a function, we need a hook that gets called during function definition; and here use Python decorators. In Python, a decorator wraps a function and allows us to add new functionality to an existing function without modifying its structure. A decorator accepts the wrapped function `fn` as an argument and returns another function that gets invoked instead. This function accepts `args` and `kwargs` passed during function invocation and returns the value.\n\nA sample decorator that times execution of a function is demonstrated below\n\n```py\nimport time\n\n\ndef my_decorator(fn):\n  \"\"\"my_decorator is a custom decorator that wraps any function\n  and prints on stdout the time for execution.\n  \"\"\"\n  def wrapper_function(*args, **kwargs):\n    start_time = time.time()\n\n    # invoking the wrapped function and getting the return value.\n    value = fn(*args, **kwargs)\n    print(\"the function execution took:\", time.time() - start_time, \"seconds\")\n\n    # returning the value got after invoking the wrapped function\n    return value\n\n  return wrapper_function\n\n\n@my_decorator\ndef area(l, b):\n  return l * b\n\n\n>>> area(3, 4)\nthe function execution took: 9.5367431640625e-07 seconds\n12\n```\n\nIn the example above we define a decorator named `my_decorator` that wraps function `area` and prints on `stdout` the time it took for the execution.\n\nThe decorator function `my_decorator` is called every time (so that it wraps the decorated function and store this new wrapper function in Python's local or global namespace) the interpreter encounters a function definition, and it is an ideal hook, for us, to register the function in our virtual namespace. Hence we create our decorator named `overload` which registers the function in virtual namespace and returns a callable to be invoked.\n\n```py\ndef overload(fn):\n  \"\"\"overload is the decorator that wraps the function\n  and returns a callable object of type Function.\n  \"\"\"\n  return Namespace.get_instance().register(fn)\n```\n\nThe `overload` decorator returns an instance of `Function`, as returned by `.register()` the function of the namespace. Now whenever the function (decorated by `overload`) is called, it invokes the function returned by the `.register()` function - an instance of `Function` and the `__call__` method gets executed with specified `args` and `kwargs` passed during invocation. Now what remains is implementing the `__call__` method in class `Function` such that it invokes the appropriate function given the arguments passed during invocation.\n\n## Finding the right function from the namespace\nThe scope of disambiguation, apart from the usuals module class and name, is the number of arguments the function accepts and hence we define a method called `get` in our virtual namespace that accepts the function from the python's namespace (will be the last definition for the same name - as we did not alter the default behavior of Python's namespace) and the arguments passed during invocation (our disambiguation factor) and returns the disambiguated function to be invoked.\n\nThe role of this `get` function is to decide which implementation of a function (if overloaded) is to be invoked. The process of getting the appropriate function is pretty simple - from the function and the arguments create the unique key using `key` function (as was done while registering) and see if it exists in the function registry; if it does then fetch the implementation stored against it.\n\n```py\ndef get(self, fn, *args):\n  \"\"\"get returns the matching function from the virtual namespace.\n\n  return None if it did not fund any matching function.\n  \"\"\"\n  func = Function(fn)\n  return self.function_map.get(func.key(args=args))\n```\n\nThe `get` function creates an instance of `Function` just so that it could use the `key` function to get a unique key and not replicate the logic. The key is then used to fetch the appropriate function from the function registry.\n\n## Invoking the function\nAs stated above, the `__call__` method within class `Function` is invoked every time a function decorated with an `overload` decorator is called. We use this function to fetch the appropriate function using the `get` function of namespace and invoke the required implementation of the overloaded function. The `__call__` method is implemented as follows\n\n```py\ndef __call__(self, *args, **kwargs):\n  \"\"\"Overriding the __call__ function which makes the\n  instance callable.\n  \"\"\"\n  # fetching the function to be invoked from the virtual namespace\n  # through the arguments.\n  fn = Namespace.get_instance().get(self.fn, *args)\n  if not fn:\n    raise Exception(\"no matching function found.\")\n\n  # invoking the wrapped function and returning the value.\n  return fn(*args, **kwargs)\n```\n\nThe method fetches the appropriate function from the virtual namespace and if it did not find any function it raises an `Exception` and if it does, it invokes that function and returns the value.\n\n## Function overloading in action\nOnce all the code is put into place we define two functions named `area`: one calculates the area of a rectangle and the other calculate the area of a circle. Both functions are defined below and decorated with an `overload` decorator.\n\n```py\n@overload\ndef area(l, b):\n  return l * b\n\n@overload\ndef area(r):\n  import math\n  return math.pi * r ** 2\n\n\n>>> area(3, 4)\n12\n>>> area(7)\n153.93804002589985\n```\n\nWhen we invoke `area` with one argument it returns the area of a circle and when we pass two arguments it invokes the function that computes the area of a rectangle thus overloading the function `area`. You can find the entire working demo [here](https://repl.it/@arpitbbhayani/Python-Function-Overloading).\n\n> Python supports function overloading using [functools.singledispatch](https://docs.python.org/3/library/functools.html#functools.singledispatch) since Python 3.4 and supports overloading on class and instance methods using [functools.singledispatchmethod](https://docs.python.org/3/library/functools.html#functools.singledispatchmethod) since Python 3.8. Thanks [Harry Percival](https://twitter.com/hjwp) for the correction.\n\n# Conclusion\nPython does not support function overloading but by using common language constructs we hacked a solution to it. We used decorators and a user-maintained namespace to overload functions and used the number of arguments as a disambiguation factor. We could also use data types (defined in decorator) of arguments for disambiguation - which allows functions with the same number of arguments but different types to overload. The granularity of overload is only limited by function `getfullargspec` and our imagination. A neater, cleaner and more efficient approach is also possible with the above constructs so feel free to implement one and tweet me [@arpit_bhayani](https://twitter.com/arpit_bhayani), I will be thrilled to learn what you have done with it.\n",
    "similar": [
      "python-iterable-integers",
      "recursion-visualizer",
      "fsm",
      "string-interning"
    ]
  },
  {
    "id": 63,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "super-long-integers",
    "title": "Super Long Integers in Python",
    "description": "Python must be doing something beautiful internally to support super long integers and today we find out what's under the hood. The article goes in-depth to explain design, storage, and operations on super long integers as implemented by Python.",
    "gif": "https://media.giphy.com/media/SKGo6OYe24EBG/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/72040055-55f49c00-32cd-11ea-9190-8f5a67c2f3d9.png",
    "released_at": "2020-01-10",
    "total_views": 3584,
    "body": "When you code in a low-level language like C, you worry about picking the right data type and qualifiers for your integers; at every step, you need to think if `int` would suffice or should you go for a `long` or even higher to a `long double`. But while coding in python, you need not worry about these \"trivial\" things because python supports integers of arbitrary size.\n\nIn C, when you try to compute 2<sup>20000</sup> using builtin `powl` function it gives you `inf` as the output.\n\n```c\n#include <stdio.h>\n#include <math.h>\n\nint main(void) {\n  printf(\"%Lf\\n\", powl(2, 20000));\n  return 0;\n}\n\n$ ./a.out\ninf\n```\n\nBut for python, it is a piece of cake \ud83c\udf82\n\n```\n>>> 2 ** 20000\n39802768403379665923543072061912024537047727804924259387134 ...\n...\n... 6021 digits long ...\n...\n6309376\n```\n\nPython must be doing something beautiful internally to support integers of arbitrary sizes and today we find out what's under the hood!\n\n# Representation and definition\nAn integer in Python is a C struct defined as following\n\n```c\nstruct _longobject {\n    PyObject_VAR_HEAD\n    digit ob_digit[1];\n};\n```\n\n`PyObject_VAR_HEAD` is a macro that expands into a `PyVarObject` that has the following structure\n\n```c\ntypedef struct {\n    PyObject ob_base;\n    Py_ssize_t ob_size; /* Number of items in variable part */\n} PyVarObject;\n```\n\nOther types that has `PyObject_VAR_HEAD` are\n - `PyBytesObject`\n - `PyTupleObject`\n - `PyListObject`\n\nThis indicates that an integer, just like a `tuple` or a `list`, is variable in length and this is our first insight into how it could support gigantically long integers. The `_longobject` after macro expansion could be roughly seen as\n\n```c\nstruct _longobject {\n    PyObject ob_base;\n    Py_ssize_t ob_size; /* Number of items in variable part */\n    digit ob_digit[1];\n};\n```\n\n> These are some meta fields in the `PyObject` struct, used for reference counting (garbage collection), but that we would require a separate article. The field that we will focus on is `ob_digit` and to some extent `ob_size`.\n\n### Decoding `ob_digit`\n\n`ob_digit` is an array of type `digit`, typedef'ed from `uint32_t`, statically allocated to length `1`. Since it is an array, `ob_digit` primarily is a `digit *`, pointer to `digit`, and hence if required could be malloced to any length. This makes it possible for python to represent and handle gigantically long integers.\n\nGenerally, In low-level languages like C, the precision of integers is limited to 64-bit, but Python implements [Arbitrary-precision integers](https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic). Since Python 3 all integers are represented as a bignum and these are limited only by the available memory of the host system.\n\n### Decoding `ob_size`\n`ob_size` holds the count of elements in `ob_digit`. To be more efficient while allocating the memory to array `ob_digit`, python over-provisions and then relies on the value of `ob_size` to determine the actual number of elements held int the array.\n\n# Storage\n\nA naive way to store an integer digit-wise is by actually storing a decimal digit in one item of the array and then operations like addition and subtraction could be performed just like grade school mathematics.\n\nWith this approach, a number `5238` will be stored as\n\n![representation of 5238 in a naive way](https://user-images.githubusercontent.com/4745789/71915727-5e03ed00-31a2-11ea-99c1-cdf28e74b595.png)\n\nThis approach is inefficient as we will be using up 32 bits of digit (`uint32_t`) to store a decimal digit that actually ranges only from 0 to 9 and could have been easily represented by mere 4 bits, and while writing something as versatile as python, a core developer has to be more resourceful than this.\n\nSo, can we do better? for sure, otherwise, this article should hold no place on the internet. Let's dive into how python stores a super long integer.\n\n## The pythonic way\n\nInstead of storing just one decimal digit in each item of the array `ob_digit`, python converts the number from base 10 to base 2<sup>30</sup> and calls each of element as `digit` which ranges from 0 to 2<sup>30</sup> - 1.\n\nIn the hexadecimal number system, the base is 16 ~ 2<sup>4</sup> this means each \"digit\" of a hexadecimal number ranges from 0 to 15 of the decimal system. Similarly for python, \"digit\" is in base 2<sup>30</sup> which means it will range from  0 to 2<sup>30</sup> - 1 = 1073741823 of the decimal system.\n\nThis way python efficiently uses almost all of the allocated space of 32 bits per digit and keeps itself resourceful and still performs operations such as addition and subtraction like grade school mathematics.\n\n> Depending on the platform, Python uses either 32-bit unsigned integer arrays with 30-bit digits or 16-bit unsigned integer arrays with 15-bit digits. It requires a couple of bits to perform operations that will be discussed in some future articles.\n\n### Example: 1152921504606846976\n\nAs mentioned, for Python a \"digit\" is base 2<sup>30</sup> hence if you convert `1152921504606846976` into base 2<sup>30</sup> you get `100`\n\n__1152921504606846976__ = __1__ * (2<sup>30</sup>)<sup>2</sup> + __0__ * (2<sup>30</sup>)<sup>1</sup> + __0__ * (2<sup>30</sup>)<sup>0</sup>\n\nSince `ob_digit` persists it least significant digit first, it gets stored as `001` in 3 different digits.\n\nThe `_longobject` struct for this value will hold\n\n - `ob_size` as `3`\n - `ob_digit` as `[0, 0, 1]`\n\n![representation of 1152921504606846976 in a pythonic way](https://user-images.githubusercontent.com/4745789/72000622-b5b95b80-3269-11ea-9e76-1755cd648f0d.png)\n\nI have created a [demo REPL](https://repl.it/@arpitbbhayani/super-long-int?language=python3) that will output the way python is storing integers internally and also has reference to struct members like `ob_size`, `ob_refcount`, etc.\n\n# Operations on super long integers\n\nNow that we have a fair idea on how python supports and implements arbitrary precision integers its time to understand how various mathematical operations happen on them.\n\n## Addition\n\nIntegers are persisted \"digit-wise\", this means the addition is as simple as what we learned in the grade school and python's source code shows us that this is exactly how it is implemented as well. The function named [x_add](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c#L3116) in file [longobject.c](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c) performs the addition of two numbers.\n\n```c\n...\n    for (i = 0; i < size_b; ++i) {\n        carry += a->ob_digit[i] + b->ob_digit[i];\n        z->ob_digit[i] = carry & PyLong_MASK;\n        carry >>= PyLong_SHIFT;\n    }\n    for (; i < size_a; ++i) {\n        carry += a->ob_digit[i];\n        z->ob_digit[i] = carry & PyLong_MASK;\n        carry >>= PyLong_SHIFT;\n    }\n    z->ob_digit[i] = carry;\n...\n```\n\nThe code snippet above is taken from `x_add` function and you could see that it iterates over the digits and performs addition digit-wise and computes and propagates carry.\n\n> Things become interesting when the result of the addition is a negative number. The sign of `ob_size` is the sign of the integer, which means, if you have a negative number then `ob_size` will be negative. The absolute value of `ob_size` will determine the number of digits in `ob_digit`.\n\n## Subtraction\n\nSimilar to how addition is implemented, subtraction also happens digit-wise. The function named [x_sub](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c#L3150) in file [longobject.c](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c) performs subtraction of two numbers.\n\n```c\n...\n    for (i = 0; i < size_b; ++i) {\n        borrow = a->ob_digit[i] - b->ob_digit[i] - borrow;\n        z->ob_digit[i] = borrow & PyLong_MASK;\n        borrow >>= PyLong_SHIFT;\n        borrow &= 1; /* Keep only one sign bit */\n    }\n    for (; i < size_a; ++i) {\n        borrow = a->ob_digit[i] - borrow;\n        z->ob_digit[i] = borrow & PyLong_MASK;\n        borrow >>= PyLong_SHIFT;\n        borrow &= 1; /* Keep only one sign bit */\n    }\n...\n```\n\nThe code snippet above is taken from `x_sub` function and you could see how it iterates over the digits and performs subtraction and computes and propagates burrow. Very similar to addition indeed.\n\n## Multiplication\n\nAgain a naive way to implement multiplication will be what we learned in grade school math but it won't be very efficient. Python, in order to keep things efficient implements the [Karatsuba algorithm](https://en.wikipedia.org/wiki/Karatsuba_algorithm) that multiplies two n-digit numbers in O( n<sup>log<sub>2</sub>3</sup>) elementary steps.\n\nThe algorithm is slightly complicated is out of the scope of this article  but you can find its implementation in [k_mul](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c#L3397) and\n[k_lopsided_mul](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c#L3618) functions in file [longobject.c](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c).\n\n## Division and other operations\n\nAll operations on integers are defined in the file [longobject.c](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c) and it is very simple to locate and trace each one. Warning: it will take some time to understand each one in detail so grab some popcorn before you start skimming.\n\n# Optimization of commonly-used integers\n\nPython [preallocates](https://docs.python.org/3/c-api/long.html#c.PyLong_FromLong) small integers in a range of -5 to 256. This allocation happens during initialization and since we cannot update integers (immutability) these preallocated integers are singletons and are directly referenced instead of reallocating. This means every time we use/creates a small integer, python instead of reallocating just returns the reference of preallocated one.\n\nThis optimization can be traced in the macro `IS_SMALL_INT` and the function [get_small_int](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c#L43) in [longobject.c](https://github.com/arpitbbhayani/cpython/blob/0-base/Objects/longobject.c#L35). This way python saves a lot of space and computation for commonly used integers.\n\n---\n\nThis essay is heavily inspired, and to some extent copied, from [Artem Golubin](https://rushter.com)'s post - [Python internals: Arbitrary-precision integer implementation](https://rushter.com/blog/python-integer-implementation/). In case you want a detailed deep dive on CPython Integers or CPython Internals in general, I recommend you checkout the [CPython Internal Series](https://rushter.com/blog/tags/cpython/) by Artem Golubin.\n\nThank you Artem Golubin for all the amazing CPython Internal articles.\nThis essay is heavily inspired, and to some extent copied, from [Artem Golubin](https://rushter.com)'s post - [Python internals: Arbitrary-precision integer implementation](https://rushter.com/blog/python-integer-implementation/). In case you want a detailed deep dive on CPython Integers or CPython Internals in general, I recommend you check out the [CPython Internal Series](https://rushter.com/blog/tags/cpython/) by Artem Golubin.\n\nThank you Artem Golubin for all the amazing CPython Internal articles.\n",
    "similar": [
      "i-changed-my-python",
      "the-weird-walrus",
      "python-caches-integers",
      "python-prompts"
    ]
  },
  {
    "id": 64,
    "topic": {
      "id": 0,
      "uid": "python-internals",
      "name": "Python Internals",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT12HU6v00VlcZ18ckWRGxXU"
    },
    "uid": "i-changed-my-python",
    "title": "Changing Python",
    "description": "I changed the Python's source code and made addition incorrect and unpredictable. The addition operation will internally perform either Subtraction. Multiplication, Floor Division or Power at random.",
    "gif": "https://media.giphy.com/media/aZ5wedD7Jtazm/giphy.gif",
    "image": "https://user-images.githubusercontent.com/4745789/71662123-60b3ac00-2d76-11ea-8018-f558cef93a59.png",
    "released_at": "2020-01-03",
    "total_views": 1121,
    "body": "Did you ever take a peek at Python's source code? I didn't and hence I decided to have some fun with it this week. After cloning the repository I realized how well written is the code that makes python what it is. In the process of exploring the codebase, I thought of making some changes, not big optimizations but some minor tweaks that will help me understand how Python is implemented in C and along the course learn some internals. To make things fun and interesting I thought of changing how addition work by making it incorrect and unpredictable which means `a + b` will internally do one of the following operations, at random\n\n - `a + b`\n - `a - b`\n - `a * b`\n - `a / b`\n - `a ** b`\n\nAfter forking and cloning the source code of [python](https://github.com/python/cpython), I broke down the task into following sub-tasks\n\n - find the entry point (the main function) of python\n - find where addition happens\n - find how to call other perform operations like subtraction, multiplication, etc on python objects.\n - write a function that picks one of the operators at random\n - write a function that applies an operator on the two operands\n\nBefore getting into how I did it, take a look below and see what it does\n\n![Random Math Operator in Python](https://user-images.githubusercontent.com/4745789/71643972-d96b2780-2ce6-11ea-894c-fd638dc95d7c.gif)\n\nYou would see how performing addition on numbers `4` and `6` evaluates to `0`, `10` and `24` depending on the operation it picked randomly.\n\n> Note, the change I made will only work when one of the operands is a variable. If the entire expression contains constants then it will be evaluated as regular infix expression.\n\n# Implementation\nOperations in python work on opcodes very similar to the one that a microprocessor has. Depending on opcodes that the code is translated to, the operation is performed using operands (if required). The addition operation of python requires two operands and opcode is named `BINARY_ADD` and has value `23`. When the executor encounters this opcode, it fetches the two operands from top of the stack, performs addition and then pushes back the result on the stack. The code snippet below will give you a good idea of what python does when it encounters `BINARY_ADD`.\n\n```c\ncase TARGET(BINARY_ADD): {\n    PyObject *right = POP();\n    PyObject *left = TOP();\n    PyObject *sum;\n    if (PyUnicode_CheckExact(left) &&\n             PyUnicode_CheckExact(right)) {\n        sum = unicode_concatenate(tstate, left, right, f, next_instr);\n    }\n    else {\n        sum = PyNumber_Add(left, right);\n    }\n    SET_TOP(sum);\n    ...\n}\n```\n\n> One thing to observe here is how it concatenates when both operands are unicode/string.\n\n### Checking if operands are numbers\n\nFor checking if both the operands for `BINARY_ADD` operation are numbers I used the predefined function named `PyNumber_Check` which checks if object referenced by `PyObject` is number or not.\n\n```c\nif (PyNumber_Check(left) && PyNumber_Check(right)) {\n        // Both the operands are numbers\n}\n```\n\n### Writing a random function\nFor generating random integer I used the current time in seconds from the system using `datetime.h` library and took modulus with the max value. The code snippet below picks a random number from `[0, max)`.\n\n```c\nint\nget_random_number(int max) {\n    return time(NULL) % max;\n}\n```\n\n### Functions to perform other operations\nSimilar to the function `PyNumber_Add` which adds two python objects (if possible), there are functions named `PyNumber_Subtract`, `PyNumber_Multiply`, `PyNumber_FloorDivide`, and `PyNumber_Power` which performs operations as suggested by their names. I wrote a util function that takes two operands and an operator and returns the resulting python object after performing the required operation.\n\n```c\nPyObject *\nbinary_operate(PyObject * left, PyObject * right, char operator) {\n    switch (operator) {\n        case '+':\n            return PyNumber_Add(left, right);\n        case '-':\n            return PyNumber_Subtract(left, right);\n        case '*':\n            return PyNumber_Multiply(left, right);\n        case '/':\n            return PyNumber_FloorDivide(left, right);\n        case '^':\n            return PyNumber_Power(left, right, Py_None);\n        default:\n            return NULL;\n    }\n}\n```\n\n### The new `BINARY_ADD` implementation\n\nNow as have everything required to make our `BINARY_ADD` unpredictable and following code snippet is very close to how it could be implemented.\n\n```c\ncase TARGET(BINARY_ADD): {\n    PyObject *right = POP();\n    PyObject *left = TOP();\n    PyObject *result;\n    if (PyUnicode_CheckExact(left) &&\n             PyUnicode_CheckExact(right)) {\n        result = unicode_concatenate(tstate, left, right, f, next_instr);\n    }\n    else {\n        // Do this operation only when both the operands are numbers and\n        // the evaluation was initiated from interactive interpreter (shell)\n        if (PyNumber_Check(left) && PyNumber_Check(right)) {\n            char operator = get_random_operator();\n            result = binary_operate(left, right, operator);\n            printf(\n                \"::::: %s + %s was evaluated as %s %c %s, hence to the value\\n\",\n                ReprStr(left), ReprStr(right),\n                ReprStr(left), operator, ReprStr(right)\n            );\n        } else {\n            result = PyNumber_Add(left, right);\n        }\n        ...\n    }\n    ...\n    SET_TOP(result);\n    ...\n}\n```\n\n# Challenges\nAfter making all the required changes I ran `make` to build my new python binary and to my surprise, the code wouldn't build. The reason was that the function where I made the changes was called during build and initialization phases and due to incorrectness induced in the `BINARY_ADD` the process ended in __Segmentation Faults__ as now it has a function that instead of adding two numbers was subtracting, multiplying, dividing and raising to power at random.\n\nTo fix this issue I had to ensure that this random picking of operator only happened when the operation is asked from the interactive shell and should continue its normal execution for others. The function that gets called during an interactive shell is `PyRun_InteractiveLoopFlags` and hence I started passing a flag named `source` to all the functions till my trail reaches the opcode evaluation flow. The value of this `source` is set to `1` when it is triggered from the interactive shell for others the default value passed is `0`. Once I had this `source` field in place with the proper value being passed from various initiations, everything worked like a charm.\n\nYou can find the detailed diff at [github.com/arpitbbhayani/cpython/pull/1/files](https://github.com/arpitbbhayani/cpython/pull/1/files).\n\n# Conclusion\n\nIt was fun to change the python's source code, I would recommend you to do this as well. It is always better if you know how things work internally and more importantly understand the complexities that are abstracted to make the application developers' experience seamless.\n\nYou can find the source code at [arpitbbhayani/cpython/tree/01-randomized-math-operators](https://github.com/arpitbbhayani/cpython/tree/01-randomized-math-operators). Feel free to fork it and make some changes of your own and share it with me. I will be thrilled to learn what you did with it.\n\nIf you want to dive deep into python's source I highly recommend you to read [realpython.com/cpython-source-code-guide/](https://realpython.com/cpython-source-code-guide/). It is an excellent guide to get you started and understand the language semantics and coding practices of a core python developer. Once you know the basics, navigating through the codebase is a walk in the park.\n",
    "similar": [
      "super-long-integers",
      "python-caches-integers",
      "python-iterable-integers",
      "python-prompts"
    ]
  }
]