 So to get the maximum performance out of our program, we tend to add threads to it, but is that it? Just adding threads obviously makes our program go faster, but is this the best that we can get out of our code? Is this the most efficient implementation that we can come up with? So in this video, what I would like to talk about is how to write good multi-thread programs? What does what do I mean when I say good multi-thread program? It means a program that uses multiple threads and is correct, which means that no matter what, there would not be race condition or there would not be any inconsistency data, which is, which typically happens when you have a shared-grower variable across multiple threads, and you're ensuring optimality, which means this is the best that you can do to get the performance out of your system. You are not wasting any CPU cycles, you are doing your best to get the most out of it. Okay, so let's go into it and we'll take actual code through, I'll walk you through the code. I'll give you an example of a sense of how to write good multi-thread program. Okay, so in order to ensure the correctness of our code, especially when we are writing multi-thread program, is by using locking, because it is very much possible that you have a globally shared variable across two threads both trying to update the value and both losing the correctness of it. For example, if my count value is 10, both thread might retain both updates to 11 and write there, and the final value should have been 12, but now it is 11, right? So that is wrong. So that is where you put locking, mutex and sima-fors, atomic instructions in order to ensure the correctness of your logic. Right? So that is what we'll not talk about that in depth, what we are more interested in talking about the fairness of our code, in order to ensure optimality. Because we don't want, let's say if my program runs on 10 threads, and if one of the threads is not doing a lot of work, while other thread is overburdened, it means that there is no fair allocation across my threads. I don't want that to happen, because if there is one thread sitting idle, but other thread is grinding it out, my overall execution time is lendened, then we don't want that, right? So to ensure optimality, we have to ensure fairness. We'll take an example of counting of prime numbers from 1 to 100 million. We'll just count the prime numbers, we don't want to print all of them. We'll count the prime numbers from 1 to 100, 1 to 100 million, and we see how three approaches would shape the execution, and how it would become better every time we go about it, right? Okay, so we'll start with the first one. We'll start with the sequential approach to do it, when I ran the last time, it took three minutes, 49 seconds, but when I run it, this time it might go a little beyond that, given that there is a lot of additional software running at this moment on my machine, right? Okay, so let me, while I explain, while I walk you through the code, let me quickly just run the program once, so that the execution keeps happening while I give you a walkthrough. So 0, 5 counting prime sequential 0, 5 not 4 counting prime sequential. Okay, so I've code by program to run. Now, I'll just give you a code walkthrough so that you understand where we are because this code remains fairly similar, the core logic of it, what changes is just the threading part of it, right? And this code is written in go line. I'll give you a quick walkthrough of it. There is nothing fancy in it, but this way you'll have an understanding of it. This, you can observe similar behavior using any multithreaded language like Java C++ holds true. I just use goaling for its simplicity and ease to create threads and go routines in that. Okay, so here I have a variable called accent, which is set to 100 million. Then I have total prime numbers, which is an integer, which would hold a total number of prime numbers from 1 to 100 million. I have a function called check prime whose job is to check if a number is prime or not. And if it is prime, then it would do count++, total prime number plus plus. That's it. In order to check if the number is prime or not, I'm iterating from 3 till the square root of that number. Let's say whatever number I want to check, let's say I want to check if 10001 is prime or not. So from 3 to square root of 10001, I check if it is divisible by that or not. If it is divisible by any one of that number until the square root, then the number is not prime or otherwise it is prime. A standard way to check if the number is prime or not. Pretty basic, still mildly optimal logic to check for the prime number. Okay, so we have this function, which does this and key thing to note that check prime does not return anything. It just increments the value of total prime number and at 10, what we do? We just print the value of that. Okay. Now in the main function, I just started my timer so that I count key in order to count the prime number sequentially. What is the total amount of time that it would take for me to find the total number of prime numbers? And what I'm doing is I'm starting from 3 because 2 is anywhere prime numbers I'll do plus 1, 3 to max it. Check if each number is prime or not. Check prime if it is prime, then good enough. It internally increments that counter. So total prime number becomes plus plus. And at the end, I'm just printing checking till 100 million, found these many prime numbers and the program took so much of time. Here we see programming is running. It is taking significant amount of time. We will not wait for that program to end. But from the previous one that I did, here's a quick snippet of what we should expect out of it. We see something out what something like this and it is already almost past 3 minutes. So it should be finishing any time soon, but we won't wait for that anyway. Checking till 100 million, found 5, 7, 6, 1, 4, 5, 5 prime numbers and it took 3 minutes 55 seconds. So this is what we see. We have already passed that. So which means the program is taking even longer given a lot of additional processes are running, especially this video recording software. But we see how CPU is limited and everyone is contending for it. Given that it is sequential execution, it just happening one after another. Now it's our job to make it faster. So now while this program is running, let me walk you through other approach where what we do is we add threads to the program. In order to understand what we are doing, let me give you a very basic walkthrough of what's happening. So what we will do is we'll add threads to it. A very basic way to multi thread or to parallelize the workload is instead of checking for one number every time. Let's say I am creating 10 threads. 10 threads that can execute in parallel. Now what I can do is I can split my range of 100 million into 10 ranges each holding 10 million numbers. And each thread taking care of that 10 million one. So I have 10 threads each taking care of 10 million eventually I'll cover 100 million there. So that's the most basic thing that we can do over here. So let me give you a walkthrough of what that code looks like. And when we run when the last time I ran the code, it took just 42 seconds. So from three minutes 55 seconds, it took 42 seconds. We might see some different time in this run and it's okay. The program is still running. It is going well beyond four minutes now, but that's okay. Okay, so I'll give you a quick walkthrough. It makes sense for us to stop this because it's taking way too longer to compute the total number of prime numbers over here. So I'm just interrupting it in between. I'll run the sixth one. This is the multi thread version of it, but not fair. It's unfair. While this is running, let me give you a code walkthrough. So the check prime function remains same, but instead of doing total prime number plus plus, we are doing an atomic increment of total prime number by one. Because now that there are multiple threads updating the same thing, executing this same function in parallel, what we would get is we would see a contention for this. We want correctness. That's why we did an atomic increment over here. We did not just do plus because plus plus is not thread safe. In order to make it thread safe, we have to use an atomic increment or a rapid in logs. So we did this. Right? Okay, so this ensures the correctness of our logic. And with respect to the execution logic, what changes is depending on the number of threads, the concurrency here at the top, we have defined concurrency to be 10, which means we want to create 10th. We have to compute this in with a concurrency factor of 10. So what we are doing is we'll create 10 threads. So for each one, apologies. What we are doing is for each of the 10, for the concurrency factor that we have, we would do, we would batch the range. The batch of the range is simple. The batch size is the maximum integer that we are iterating till divided by concurrency, which means this is my batch size. Now for me, what I have to do is each thread, I want to give one batch. So the first batch goes to this. So n start is the number that we are starting with n start plus batch size and n start plus equal to batches. So this way we are going one batch after another and creating n threads out of it, where n is the concurrency factor. So here what we are doing is through this logic, we are creating 10th threads, each taking care of one batch of my 100 million. So each taking care of 10 million. Right? Okay. And then we wait for it. So wg.ad is basically adding a counter wg.ad. Wait would wait for all of those go routines to terminate. Right? And then it would move on because I have to wait for all the threads to complete. And then I would print a total time taken over here. Right? Okay. Now each batch, when it is executing, what it would do? It would just for each number in that batch, it would check if it is prime or not. Straight power logic. Right? And once it is done, once it is done checking for all the numbers in that batch, it would print the time taken for this thread, handling this range, it completed in some time. Right? When I ran this here we see the time taken is one minute and almost zero seconds. So it's basically one minute. So from three minutes and 55 or other, it was much more than that because it ran more than four minutes. And if I go by my previous one, it was three minute, two to five seconds, reduced to 42 seconds. So roughly that much of a dip we would see or other that much of implemented performance we would see over here. But here we see a classic case of how we think the program is made much faster. And it is indeed faster. It is at least four X or five X faster. Right? And we very clearly see it in this demo. But now is this the best we can do? If we look closely in the output, we see something very interesting. The program ran really fast, it's good. But if we look, each thread is taking different amount of time to complete the execution of its batch. Because if you see thread zero just took 18 seconds, thread one took 30 seconds, thread two took 37 seconds, thread nine took one minute something. Right? So overall the time taken was one minute. But each thread completed its execution in not equal amount of time, which means thread zero had very less amount of work. Thread one had little more, thread two had little more, thread eight had more, and thread nine had the most amount of work to be done because it took that much of time to do it. Right? So although we made our code faster, but it is not fair. We want to, but which means which means we can do better than this. Because the execution was not fair, some threads executed, some threads completed faster, some threads took longer time. So overall execution time was limited. So if I would have gone with some other logic, I might. So there is still scope of me squeezing out performance out of my multi-threaded program. Right? Okay. But why is this happening? Let's first understand that. This is happening because what we did over here, just a minute. Let me change the screen. Okay. So this is happening because the number of prime numbers that we have are very dense at the lower range, but very few at the higher range. So there is an disproportionate distribution of prime numbers. So large prime numbers in smaller range, longer prime numbers or rather lesser prime numbers in larger range. That's fine. But more importantly, the way we are computing, the way we are checking the numbers is prime. We are editing from one till that number or the square root of that number. And we are checking if it is divisible by like each one of them we are checking for the divisibility. Right? Now given as the number would increase, we would be checking far more for that to be a prime number or not. So there is a square root relation. The amount of checks we are doing is equal to the square root of. So that's why you see a curve which is which would taper at the end. And it was very evident in the time that it took. So 18 seconds, 37 seconds and then it tapered off till 1 minute. Right? So this is a very standard square root curve that we also observed there. So this shows that each thread is doing disproportionate amount of work over there. So we have, so that is a scope of making it thin, which is where we come with the third approach. That hey, how do we add fairness? How do we ensure that my threads are doing like all of my threads are doing equal amount of work? So that I ensure that I am completing my complete execution in the bare minimum time. So now instead of I batching my thing and giving one batch to each thread, what if? What if I just keep my threads running? Whenever they are done processing, they pick the next number and check if it is prime or not. Other thread comes, picks an x number, check if it is prime or not. And they continuously do this until I exhaust my range. That means that each of the thread would be busy until I exhaust my complete range of 100 million. That's exactly what the logic is. So now let me give you a very quick code walkthrough and explain what is happening behind the scenes. So what I have over here is just a minute. So what I have over here is my approach third, which is 07. If I run it, the 07th one, which is the fair way to write the code, it would look something like this. So here what I have is max in concurrency factor 10, total prime number, but I have added one more thing called current number. So current number is the one is the current number that needs to be checked for prime. Right or it was just checked for the prime. So that's the logic basically. So what would happen is check prime function would check if x is prime or not pretty standard logic. It does atomic increment. Right. But now what my threads are doing. So what I'm doing first of all, I'm creating n threads over here, which would do do work. It is invoking do work over here. Right. I'm just waiting for all of them to complete. Now what do work does if I go to do work, what it does is it is literally an infinite loop, which runs until I exhaust the range. And what I'm doing is I'm just doing atomic count plus plus like it does basically current number plus one. Whatever the current number is does a plus one and checks if it is prime or not. Right. Every thread is repetitively doing this, which means one thread comes. It picks the current number, increments it and checks that number to be prime or not. Second thread comes, picks the number checks if it is prime or not. Third thread and once first thread is done, it would go and check the next number if it is prime or not. Because we are incrementing it atomically, every thread would atomically pick a number. Check if it is prime or not. If it is, it would do count plus plus and what not. This way all of my 10 threads are continuously running until I exhaust the entire range. Once the entire range is exhausted, then each thread would automatically start to exit from this for loop. And would print this. Right. Okay. Now when I run this code, now when I run this code, what happens is if you look carefully, the program just took 51 seconds from one minute that we saw in the previous run for the previous approach, it took 51 seconds. It is much faster, much faster than actually 10% faster than this. Right. So we saw that we saw how this is the optimal that we can reach because if you look carefully, the thread execution, the thread did not completed, it had 3rd, 0 completed, 10th, 3rd, 1 completed, it is then thread to completed. But it's seemingly random order, 6482150. Right. But each thread got completed and if you look at the time that it took to complete, is roughly the same. 51 seconds, 51.0, 51.0, 51.0, 51.0, 2 something. Right. You see how all of my threads were busy doing the work. It was not the fact that hey, one thread is done, one thread is done, sooner and that thread is just sitting idle or just done with its work. Why other thread is doing much more grinding work. Right. Every thread is continuously working, ensuring that I eventually count the total number of prime numbers from 1 to 100 million, not missing any. Right. So here we see how we ensure correctness by doing atomic increments of my total brand number. Plus plus and current number. How we ensure fairness by ensuring each thread does exactly nearly like almost equal amount of work. This way we minimize the time it would require for us to complete the execution of my program. And this is how we write good multi threaded code. Good writing good multi thread code is not just about adding threads and getting things done. It's more about extracting the maximum performance that you can get that you can out of your low level code. And this is what I wanted to talk about in this video. I really hope you found it interesting. I hope you now you see the impact of doing that performance improvement, impact of writing good multi threaded code, ensuring everyone does nearly the equal amount of work. Like in this use case it fits really well. In some practical use case, let's say if you're writing web servers and whatnot, just ensure that you are not unnecessarily waiting for someone to finish. See where you can parallelize, see where you can stream. And that would make your code much better. I will I will be covering those details in a lot of coming videos where we go in the depth of concurrency. But this is a static point. This is an excellent static point for you to understand why writing good concurrent code is different than writing just concurrent code. Right. But yeah, I hope you found it interesting. I hope you found it amusing. This is what I wanted to cover in this video. I will see you in the next one. Thanks a ton.