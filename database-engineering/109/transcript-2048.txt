so in this one we'll take an example of a very simple, uh, a, a very simple sequential serialization, like here, like what we typically see with sql databases, right?
so let's say we have a users table and it has five columns: id, name, h, bio and total blocks.
so every column or every attribute over here will take up some space onto the disk, which means that when that attribute or when this row needs to be serialized, every attribute gets its particular size or its particular set of bytes stored onto the disk, right?
let's say we put it as 128 bytes, and total number of blocks- as in how many blocks has this user published- would be an integer.
so here we saw: user table, five columns, 200 bytes to store one row onto the disk.
now let's say my table, my users table, has 100 rows like this.
so it would look something like this: let's say these are like dummy entries in my table: 1: name is a, age is 23, some bio, and then total number of blocks: 7.
right, so let's say we are playing with this: six entries, and there are many more entries like this, totaling up to 100 rows.
right now let's go through and understand how disk, how reads from the disk, actually happen.
uh, like, it is split into 600 byte blocks, right, and whenever, like, let's say, i have this as a space and it is split into four blocks for now.
so here, if i am requesting these bytes, what your disk io will do is it will go to the disk like it will hit the disk, read that particular block, load it in memory, read these bytes and then send it to the user right and basically send it for the further processing right.
so no matter how many bytes you would want to read, it's not that only those bytes are read, but the entire block is a brought into memory.
you read that many bytes and then you basically continue your processing right.
right now let's see how our users table that.
so we know that each record or each row of my users table is 200 bytes long.
we know that a block size for this example is 600 bytes, right?
which means that in each block- like if i am serializing this entire table, in each block i can contain three rows.
so my users table would look something like this on disk.
so the first three rows will go and sit in the first block, the second three rows will go and sit in the second block, and so on and so forth, because a block has, like, let's say a block has 600 bytes cup width, like that's the size of the block.
so to represent 100, no, rather to store hundred rows on the disk, how many blocks would you require?
we would require 100 by 3, it is 33.3, but we cannot, like the block is not divisible, so we need 34 blocks to store this entire table, this entire table onto the disk.
this entire table onto the disk, stored serially as a, as a series of blocks, which is total number of blocks required is 34 right now.
now let's say, if i am going through this table row by row, how much time would it require for us to read this entire table?
so to read this entire table, what would we require is we would have to iterate table row by row, request a particular row.
the, the, your disk engine, or your cpu in that case, will identify: hey, i want to read this particular block from the disk.
uh, sorry, it would say: i want to read this particular row from the disk.
it would find the byte offset, it would go on to the disk, read that block, keep in memory, extract the record and basically use it for further processing.
so the amount of time that we would require to go through the entire table will be equal to the amount of time required for us to read those many number of blocks.
so because, like hyper, that very hypothetical example- but let's say if i, if i like, when i do a disc, i o and i'm reading one block, let's say, hypothetically it takes one second for us to read one block from the disk.
so to read the entire table, or to i trade through the entire table because we are reading 34 blocks- how much time would it require for us to do it?
the query goes like this: that find all the users with age 23.
and then, after the iteration of the table is done, we would then written the output buffer as part of the response of my query, right?
we are rotating the entire table row by row, which means we'll be accessing all 34 blocks.
so time taken for us to answer this query is same as time taken to read all the blocks of my table.
so, because there are the d4 blocks, it would require us 34 seconds to answer this query.
now let's see how indexes make them make this particular flow faster.
index are very small referential tables that holds the row references against the indexed value, right?
so how does that index actually be stored onto the disk?
so somehow your index will also be serialized and be stored onto the disk as blocks.
right now let's see how much uh size, or what's the width of, like, how much size would it require?
how many bytes would it require for you to store one entry of this index, right?
our one disk block is 600 bytes.
in order to represent your index onto your disk, like if you are serializing your index and storing it onto the disk, it will only require you two disk blocks to store that.
now let us evaluate the same query with index and see how the flow would happen.
like i'll go through my complete index without any optimization, right?
the first thing that i'll do is i'll iterate through all the entries in my index, right, and find out who for which h is 23.
what i'll do is i'll go through this index, like, every entry, one by one, and i'll find all the entries whose age is equal to 23..
all of these ids are something just which, which i am interested in because for these ids age is equal to 23, right?
uh, so i'll iterate my index, uh, entry by entry, which means block by block.
how many disk blocks would i have to read to prepare this set of ids that i am interested in because i am going through the entire index?
two discretes and i'll be break and i'll be reading the entire index, uh, filtering out all the values, like also.
so i'll be collecting all the ids that i am interested in, which means whose age is equal to 23, and then i'll have this id and i'll have this buffer prepared.
right after i trading through the index, i'll have the list of ids that i am interested in.
so, first phase now, because i already have the ids that i'm interested in because of the index that i have, and now my next step would be to, because to user, i have to send the entire record.
so the next phase would be: for all the relevant ids that i have collected after i trading through my index, i would want to read the corresponding records from the main table, right?
so i would be reading the main the, the actual record from the main table of all the ids that i uh that i found to be relevant for h equal to 23, and i'm basically collecting it in the buffer and then sending it out to the user as an uh, as a response right now, here for the second phase of it, the amount of time that will require to fetch this, to fetch these records, uh, to fetch actual records from the id, would be equal to the number of disk blocks that we would have to read to answer this thing.
so first space, iterating through the index, finding out relevant ids, reading the entire index, two blocks required.
two blocks means two seconds per say, like our hypothetical use case.
so number of blocks read here to prepare that ide skull list is equal to two block reads right now, now that i have id.
second, three rows were stored in second block.
so if i want to read this one block, one record.
as i told at the beginning of this that, even if you want to read one byte from it, your disk will always perform a block read.
it would read that entire block in memory, extract that byte and then discard the block, like it is basically catching it, but let's say basically discarding the block.
so if i am reading this particular, i want to read this particular record, which means i have to read this entire block.
so i will read the first three entries, i'll read the block here, which means it would load these three records.
okay, for this age is equal to 23, because i have the offset, i can directly go and read that record and add it to my buffer.
so i'm reading the second block from the disk in memory, finding out that record uh, adding it to the buffer and then discarding it.
so to answer this query: how many disk blocks to get the actual record from the reference id?
so to read the actual record, two disk blocks to read the index to find the relevant id is two disk blocks.
so total number of, so total number of uh disk clocks that we read to answer this query with index, is equal to four blocks, right, and we know that, approximately hypothetically, we took that one disk block uh reading is equal to one second.
so the total number of time that we would require to answer this query would be equal to 4 seconds, right, so 2 for index, 2 for record.
so now, if we compare the time, the time taken without, so time taken to answer the query without the index, was equal to 32 seconds, because we had to read 32 blocks, iterating through the tables step by step, while with index, with index, we only had to read four blocks: two blocks for the index and two blocks for the actual data right now.
if we see, only with this, with this example, we were able to gain 8x performance out of like just by creating an index, we were able to get 8x performance out of my system, right.
if that is not index it, in worst case, it may lead to i, it may lead to sequential iteration across like a full table scan, to be honest, in worst case, worst case, right.
like, for example, a few optimization that you can do with index scanning is: you may not need to read entire index every time if you can create a multi-level indexing.
that you are like here right now you are iterating on the complete index.
like here you are iterating on the complete index to find out the relevant ids.
otherwise, in this simple example only, you can just stop iterating once you cross 23, like you requested, for aging is equal to 23.
you can start reading block by block and, as you know that, hey, you br, you crossed age equal to 23 here.
what's the idea behind it, how disk reads happen in block center, right, okay, that's it from me.