 So we all know most databases store the data in B plus trees. But how in this video, we answer this very question and go through the evolution of storage from a knife implementation to an optimized B plus tree. We will talk about why there was a need to use B plus trees, how table data is actually stored in B plus trees and how is this tree serialized and stored on the disk. But before we move forward, I'd like to talk to you about a course on system design that I've been running for over a year and a half now. The course is a covered base course, which means I won't be rambling a solution and it will not be a monologue at all. Instead, a small focused group of 50 to 16 engineers will be brainstorming the systems and designing it together. This way, we build a very solid system and learn from each other's experiences. The course is enrolled by 800 plus engineers spanning 12 cohorts and 12 countries. Engineers from companies like Google, Microsoft, GitHub, Slack, Facebook, Tesla, Yelp, Flipkart, Dream 11 and many many many more have taken this course and have some wonderful things to say. The course is focused on building systems the way they are built in their world. We will be focusing heavily on building the right intuition so that you are ready to build any and every system out there. We will be discussing the trade-offs of every single decision we make just like how you do in your team. We covered topics ranging from real-time text communication for Slack to designing our own toil-out balancer to create buses live text commentary to doing impressions counting at scale. In all, we would be covering roughly 20-8 systems and the detailed curriculum split week by week can be found in the course page linked in the description down below. So, if you are looking to learn system design from the first principles, you will love this course. I have two offerings for you. The first one is the live cohort base course and the second one is the recorded offering. The live cohort base course happens once every two months and will go on for eight weeks while the recorded course contains the recordings from one of the past cohorts as is. If you are in a hurry and want to learn and want to binge-line system design, I would recommend going you for the recorded one. Otherwise, the live cohort is where you can participate and discuss the systems and its design life with me and the entire cohort. The decision is totally up to you. The course details prerequisite testimonials can be found on the course page Arpithbanny.me slash masterclass. I repeat, Arpithbanny.me slash masterclass and I would highly recommend you to check that out. I have also put the link of this course page in the description down below and I am looking forward to see you in my next cohort. So, we all know SQL databases are known to store data in B plus trees, right? But it is true that even non-relational databases, they leverage B plus trees to store the data. For example, MongoDB does that. MongoDB stores the collection data on this serialized in terms of B plus tree. So, their storage engine called wired tiger does that. Now, in this one, what I would like to do is to build an intuition around why there was a need to introduce a data structure like B plus tree and how it is actually serialized and stored, like the data serialized and stored on the disk. Now, in order to do this, let's start with something really simple and then we see why is there even a need to do that. Now, let's say, the most simplistic way to store data. Let's say I have a table, I have bunch of rows in that table. The most simplistic way to store the data is to store it in a single file, one row after another. Dead simple, right? Now, when you have something like this, when we store data in a file, sequentially, one row after another, literally one after another in a file, let's see how insert works. Now, here, just a thing that when I say row, it does not just imply row, but I will document anything, any entity that we are storing in the table could be placed over here. So, SQL tables typically call it rows, not relational databases, typically call it documents and whatnot, but idea holds true across the database spectrum, right? So, here, what I would want you all to do is to focus on the need and the intuition rather than the specifics, then everything would make sense, right? Okay, so let's start with that. Let's say I have a bunch of rows over here and I would want to insert a new row. Now, given that all the rows that I have is placed in that file sequentially, which means one after another, inserting a new row, inserting this new row at the end of the file is really easy, you open the file independently mode and add the row at the end, right? But now, for example, we know that relational database or most databases store the data ordered by primary key, which means that let's say I have defined a particular column ID as my primary key and I'm inserting row 1, 2, then 5, then 4 and then 3. Now, I'll have row 1, 2 and 5 inserted, then I would want to insert the row in between because our table is ordered by that. For me to insert the row in the between, what would I have to do? Given that, I cannot just insert a line in middle of a file. I just cannot do that because when I would write something and between the offset, the line does not automatically, the rows automatically would not move down the file, right? That's not a classic problem on a disk-based solution is, right? It's not in memory, but for the actually scene code editor, where we just hit enter and it adds a new line, it's on disk storage. So, when I would want to write something in between, it is definitely trying to override the existing content, right? That I cannot do, which means adding a new line in a file in between rows is not an efficient solution because now what we'd have to do is every time the insert happens, I would have to first locate the position at which I would want to insert, then copy all the lines, all the rows before that in a new file, add this new line, then copy the remaining file on this new, or basically copy the remaining lines in this new file, right? This way my insert becomes order and because every time I'm inserting something, I would have to create a new file. That's the only way to do it because if whenever you write at a particular location, whatever is written at that location in the file gets over it, right? You cannot just insert in between in one file on any disk, right? So, that's the limitation number one and that's why insert becomes order n. Okay, now let's take a look at how update looks like. Now, let's add one to update row three, right? Now, in order for me to do that, I would have to look for the row with ID3, right? So, then worst case, I would have to do linear scan across the entire file and find the rows that and find the row that I'm interested in. Then, once I discovered that row, I would start writing at that specific location and overriding the content. Now, here are the challenges. Given my other rows are already occupying some space, when I'm writing something from this location, starting from this location, I would have to write the number of bytes equal to the width of this row. I cannot go beyond that because as soon as I go beyond that, I would be infringing in the location, in the storage location of the next row, I'd be overriding this content. It cannot move automatically forward, just like in ID. In ID, it can move out because it is RAM. You're storing that file in, you're loading that file in RAM and then making the update. When you press controls S, then it gets saved on the disk, right? Here you cannot do that. So, if let's say this number of bytes were 100 and if I would want to write 120 bytes, so 100 bytes would be written over here and 20 bytes would be written over here, infringing in the space of the row ID for. Now, for you to do an update, you first have to locate and then assuming that you would be updating the exact same width, you can start over writing over here. But if you want to do more than this width, you cannot do that. You'd have to create a new file and copy the rows, a similar to insert. Copy the rows, write this new row and then update. And then, just copy the rest of the rows. That's why file IO is so interesting because it you just cannot do it intuitively. You'd need to know the constraints that you're playing with. Let's say I would want to find a new row because even in insert, you wanted to hunt for location, even in order to want to hunt for location. Let's see how hunting for a location looks like. How do you find one in the file? For you to do that, the only way to do it, given, because basically given right now, there is no indexes, even in case of indexes, you cannot do it efficiently if you go with this structure. But now, here, what you would have to do is you literally go through file row by row and see the and find the row that you're interested in. There is no way for you to optimize it. By the research, you can do it, but when you have right set of indexes, but how will it take a look, which is where B plus 3 comes in, right? But a nine implementation linear scan is the only way to do it. Okay. Now, another common operation that you've seen databases is range queries. Now, range queries are quite popular. Like, give me all the rows, which are present in this range. Like, let's say, one, two, one hundred, right? Now, for you to do it, range queries, you can do it only, you can do it efficiently in this case. Why? Because first of all, let's add one to find rows between two and five, right? So I start from here, I'd find a row with ID2, I found this, then I'll continue to iterate one after another until I find row five. And then I would just club the results and send it out to the user, right? So range queries are efficient, but in order to find the first row itself, the worst case is order N, you'd have to do a linear scan, right? So range queries, once you find the first row, then the range query becomes like a linear scan. But before that, that complexity to find a first row itself is order N because it's a find of an operation, right? So even find of an operation is order N. You would like not getting enough performance out of your database, not the final operation, delete, right? Delete as you might have guessed already, when you're deleting a particular row, it's you'd have to create a new file every time you delete, given this naive implementation. Because what you do is you'd create a new file, copy all the rows until you click. First of all, you'd have to find a row that you'd want to delete, find one operation order N, worst case, then you copy the rows up until that location into a new file, right? And then you skip that row and then you copy rest of the rows over here. That's how you delete the row because it's pile-out, you cannot just delete something without and not reclaim the space because then you are effectively occupying that row, right? So you'd have to do it. So all the operations that we discussed are order N. Insert, update, find, delete, everyone is order N. So how does B plus 3 solve this problem? So given that order N insert, update, delete, cannot work well with in a transactional database, it's not perform enough, we have to find another solution, which is where B plus 3 comes into the picture. Now, what is a B plus? Now we'll not go into the data structure B plus 3. We'll understand how B plus 3 is leverage. So in case you don't know what B plus 3 is, just google search away. But let me talk about how B plus 3s are leverage over here. So in a table, there are bunch of rows, right? A table consists of rows, a collection consists of documents. Now, when you have all of these rows, you club these rows in 1B plus 3 node. So for example, if 1B plus 3 node that I have, if it is 4KB big, which means I can store 4 kilobytes of data in this 1B plus 3 node, then in that case, if my average row size or average row document length, average length of the row is let's say 40 bytes. In a SQL table, if I may call it, the schema that you have, you define fixed width for every single column, you exactly know the length of the row, right? That I'm talking about. If the length of the row is equal to 40 bytes, and if my B plus 3 node is 4KB big, each node will contain 4KB divided by 40 roughly 100 rows, which means that in this B plus 3 node, the number of rows that I can put in is 100 rows. So this is row 1, row 2, row 3, row 4 and so on and so forth, right? So this is exactly what B plus 3 stores when it says that I'm, my table is storing the data in B plus 3. This is the leaf node of B plus 3, where you are actually storing the rows of the table, right? Okay. So now, typically, typically, the why did I pick 4KB as the size of this B plus 3 node? In most typical configuration, the size of a disk block is 4KB. Now, what is this disk block? When you do a disk I, you read, write, a delete, do something on the disk. The most granular width in which it is done is 4KB. It is basically called as a disk block size. So even if you want to read one byte from the disk, you cannot just read one byte. You have to read the entire disk block, and then pick the byte that you're interested in and then like the operating system does this for you, but in reality, because your operating system is reading that entire block, that is the most granular width that you operate on, that entire one, that entire 4KB block is read. It picks one byte and discards everything else. Now, given this, given that the most granular operation that you are doing is on 4KB, you keep the size of a B plus 3 node equal to 4KB, which means whenever you are reading, you are reading that one B plus 3 node as it is. Which means your effect when you are reading roughly 100 rows over here. I am not going to need to read exactly exactly 100 rows, or it is slightly lesser than that, but you get the idea. So given this is how my rows are structured in B plus 3 nodes. Now, my table can be represented as a set of B plus 3 nodes, which are connected to each other. Now, how are you connecting it? For example, for example, I have, we know that one B plus 3 node as per our assumption, 4KB disk block size equal to 4KB size of B plus 3 node, each row is 40 bytes, so I can store 100 rows. So given that I know that each node can store 100 rows, I will have, let's say, 400 rows. So first node will contain 1 to 100, second row will contain 100 to 1 to 200, third row, third block, third node would contain 200 and 1 to 300, and then the final node would contain 311 to 400. Now, these nodes can be present in any location on the disk. Now, what your data is does internally, it does not just allocate a random disk block on it, it has a proper structure in a file where it knows from this is this particular block is there, from this offset to this offset disk particular block is there. I am drawing it in a randomish way so that you understand it might not be sequentially arranged. You cannot assume that they are arranged one after another. That's why I am just drawing it like this so that you don't fall into that trap and ginking that all of my rows are stored one after another. They are not, they might be but need not be. Now, each node contains a small pointer exactly a disk offset, like a disk offset in this file, this is where my this B plus 3 node is present. Now, this might not be individual files, this may be part of the same file itself, but in that file you split a file into different regions each of the same size, this is same as 4kb and you just node down the offset of that. And storing that offset becomes a pointer to that node. As similar to see where pointer is exactly the address of the memory location, here the pointer is the offset in that specific, this specific file. Now, this is exactly how your data is stored or your table data or your document data is stored serialized on the disk. These nodes become the leaf node of a big plus 3. You would have, you would remember that the leaf node of the B plus 3 also stores the data. This is exactly what they are talking about. These are the leaf nodes of my B of my B plus 3 which is actually storing the row data that you have. But is this even making your insert update delete efficient? Now, B plus 3 does not just contain leaf node. It contains other nodes. So, what is stored in other nodes? Let us go through that. A simple table when visualized as a B plus 3, a very simplistic visualization for you to understand a concept is this. So, B plus 3 may contain n levels. I am taking example of 3 that becomes easier to understand. Now, here this is the root of the B plus 3 node. Then you have first level and then you have the actual leaf nodes where the actual table data is stored. Here you can see how a table data is stored in B plus 3 row or rather ID 1 to 100, 100 to 100, 200 to 100 to 100, 200 to 300 and so on and so forth are stored over here. Now, let us see what each node holds in B plus 3. Now, again each of this, this is a very nice visual way to see it on this. They might be spread anyhow in the table file. It depends. So, depending on the database, what storage is in there using? For example, mySQL, DB has mySM, NODB and whatnot. They may choose a different way to store this or different way to allocate this B plus 3 node on the disk in that region. We do not have to worry about it. That is the implementation specific. But in a nice visual representation, this is how we can visualize it very easily. Now, every B plus 3 node is serialized and stored on the disk. So, all of these nodes that you are seeing, they are not stored in memory. They are all on disk. They may be brought into memory for performance gain, but the worst cases they are all stored on disk. Okay. Non-leaf nodes, they hold the routing information. When I say routing information, it is not something nodes routing. What I am talking about is it tells that in the child node, which node holds what range of data. For example, here this node, non-leaf node stores 1 and 101, which means that the left node starts with 1 ID and the right node starts with ID 101. Here, the left node starts with 201 and right node starts with 301. So, from 211 to 301, you can find it over this and so on and so forth. This is the offset or the routing, not offset, but the routing information that the range information might be the better word. Range information of what the lead B plus 3 node holds and white versus as level increases, they keep holding the range information of their child. Now, for you to make any insert update delete, you can very clearly see and sorry before that, before we go into the operation side of things. As always, in B plus 3 node, all the leaves are interlinked. They are connected linearly like each leaf is connected like this, they are linearly connected. So, the first node, second node or not, they are linearly connected and they are also part of the B plus 3. Now, we will see how beautiful this solves a problem. Okay, leaf node, as I we discussed, holds the actual rows. These are row ID, 5 0 and 5 0 to 5, but this is actual row data and leaf nodes are connected linearly. Now, let us take a look at operations, how this makes sense. Let us start with find 1 by ID operation, find 1, like given an ID, find me the row. Now, for you to do that, in order to find a particular row with a particular ID, what would you need to do? Let us say I would want to find row with ID 4, what will I do? I will start with the root node. Now, this node is present on disk. So, first thing what I will do is I will go to the disk, read this particular block. I will read this particular block, interpret the routing information and I would know that ID 4 is present in this range. I would go over here and how would I know that? I would just store the left and the right, like the least and the most value over then through which I am routing, like here 1 and 1 0 1 is what I am storing. I am not going to store every single rows information, right, because it is range is what I am operating on. Correct. So, now here I would have information which is let me just be very specific on that. I would store 1, 2, 0, 1 and 4, 0, 1, kind of like this information would be stored. So, this means that 1, 2, 2, 0, 1, if I am requesting for this ID, I have to go over here. If I am requesting something for 2, 0 between 2, 0, 1, 2, 4, 0, 1, I would have to go over here, 4, 0, 1 greater than 4, 0, and I have to go over here, right, that is typically what we store in pre-president, right. Okay. So, now what do we do? Let us say we are requesting for row ID 3, right. So, now what I will do? 3 lies between 1 and 2, 0, 1. So, it would first read this block, understand, hey, I am looking for 3, it is present in between 1 and 2, 0, 1. So, it would go to the first node. Here it would say 3, 1 and 1, 0, 1. So, over here, it would come over here and read, so read this block, come over here, then read this block from the disk, read all these 100 rows. Again, it is a discrete, it would read all these 100 rows and find which one is row ID 3, get that and return it. So, now what your linear scan was, is now just wall down to 1, 2 and 3 discreet, that is it. Where you are doing this multiple discreet at first, now it just boils down to 3 discreet and you get the row that you are interested in. Dead simple, right. Now here you beautifully see, no matter which row you request, you would get it in this specification in exactly 3 discreet, not one extra. One for this block, one for this block, one for this block, extract this row and return it to the user, right. This is how your reads would work, right. Find one by ID. Now let us take a look at next operation which is insert. Now how would insert? Insert, what we would first have to do is let us out want to insert row 4. What I will do, read this block, understand where the 4 while would lie in the leaf node, I would come over here, insert find row 4, where 4 would lie, I would find this, I would read this entire block, find the place where I can place the row 4, it would be after 3 and because I am loading it in memory, I can do that arrangement, add something in between and move other forward, right. I can do that at a moment, right. You can do that if you are storing it in arrays. You put it in between and then flush the entire thing on the disk, which means you read this, you read this, you read this, you read this, you put your row 4 and then you put it and you flush this B plus T node on the disk. So, one disc read, two disc read, three disc read, update in memory and one disk flush, right. So, this way, you are insert can happen in between, you do not have to rewrite the entire file, in linear sequential way that we were storing, we would have to rewrite the entire file, here we do not have to, here what we are getting is we are getting this benefit that without touching any other disk block, any other B plus T node, I am just reading the blocks I am interested in, updating them and flushing it down, right. And obviously, the B plus T rebalancing and all comes into the picture. So, that is specifications of B plus T as a data structure, go through that, that is out of this scope, I am talking about how data is actually stores the data, right. Okay, that is about insert. Similarly, you can envision updates, you read, read, read, update the row, let us add one to update row 202, right. Let me take a different example, update row 202, I would read this, I would know you come over here, read this, I would now have to come over here, read this, in memory now I have the entire disk, the entire B plus T node in memory, I would update whatever I want to flush it down on the disk, right. If I want to do arrange and move it and whatnot, I can do all of that. But without altering any other block, I am just doing the updates that I mentioned, I may have to split and rebalance the B plus T, that is a different problem, but it makes my operation so simple. And similarly, when you are deleting it, what you do, let us add one to delete row 401, I read this, read this, read this, end memory, delete this block, I literally, if it is, I am storing it in an array, I would just delete that part, in memory and then flush it onto the disk. The way I do it, when I flush it, the row is gone, and that is my hard deletion, then I may have to rebalance the tree in order to maintain the ambient factor that you will know, like standard rebless rebless practices. But now here you see how beautiful your operation gets, right. So simple, so efficient without touching anything else, you get the raw power of the disk, right. The final operation I want to talk about is range query. Let us say I want to find all the rows whose ID line the range 100 to 600. Now for you to do this, see how beautifully that leaves that are connected, that solves this problem so beautifully. Now let us add one to read rows whose ID is in range 100 to 600, right. Okay, what I will do, I will want to read 100, right. So I will start from here, where does 100 lie here, I will come over here, where does 100 lie over here. So I will start from here, from 101, I will read this block, I would say did I read 600? No, so then I will have to read this block. But now instead of coming from here, here, until here, because these nodes are connected, like this, you can linearly traverse through this. So I read this, I read this, with this part I read this until I reach 600. As soon as I reach 600, I stop. So now what we are doing with this leaves directly connected with each other, what you get is you don't have to iterate through this from top to bottom again and again. Once you reach at the leaf, you can just linearly traverse like this. That's the beauty of this data structure. Now the number of discreet is 1, 2, 3, 4, 5, 6, 7, the bare minimum that you have to do, log n to reach to the first point and then linearly depending on the number of rows that you are reaching. Such a beautiful implementation, that's why data structures, this B-blast trace, so so so powerful because of this very reason. Why B-blast trace, forces you to store data in the leaf node, now you get it. B-trees allow you to store data in the middle in the in the non-leaf node also, but B-blast trace forces you to store data in the leaf node. This is precisely where because it makes your range queries super efficient. It gives you predictable times to read any row from your database. This is the power of B-plus-3 and this is why most databases out there, they use B-plus-3 to store and hold their actual data. It's not just specific to SQL, no SQL databases like MongoDB, in their wired tiger storage engine, they do this. This is the beauty of B-plus-3 and how database and why database stores the data in B-plus-3. This is what I wanted to cover. I really hope you found it interesting. Now I think most of your questions around why database use B-plus-3s to hold the data would be solved. But once again, explore on this bit more detail, understand B-plus-3 in case you are unaware. But this is precisely why database use B-plus-3 to store the data. Again, I hope you found it interesting. I hope you found it interesting. I'm using, sorry, and that's it for this one. I'll see you in the next one. Thanks a ton.