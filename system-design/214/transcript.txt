so almost all Engineers start working on a feature thinking it is a simple and a no-brainer but when we start thinking of the implementation details we realize how complicated things actually are in this video we go deep into the email classification service at slack whose sole job was to classify an email into an internal or an external one the feature seems like a cakewalk but when we start jotting down the implementation specifics things turn out to be a little more complicated than we anticipated but before we move forward I'd like to talk to you about a course on system design that I've been running for over a year and a half now the course is a code based course which means I won't be rambling a solution and it will not be a monologue at all instead a small focused group of 50 to 16 genus will be brainstorming the systems and designing it together this way we build a very solid system and learn from each other's experiences the course is enrolled by 800 plus ingenious spanning 12 codes and 12 countries ingenious from companies like Google Microsoft GitHub slack Facebook Tesla Yelp Flipkart dream11 and many many many more have taken this course and have some wonderful things to say the course is focused on Building Systems the way they are built in the real world we will be focusing heavily on building the right intuition so that you are ready to build any and every system out there we will be discussing the trade-offs of every single decision we make just like how you do in your team we cover topics ranging from Real Time text communication for slack to designing our own toilet balancer to cricbuzzes live text commentary to doing impressions counting at scale in all we would be covering roughly 28 systems and the detailed curriculum split week by week can be found in the course page linked in the description down below so if you are looking to learn system design from the first principles you will love this course I have two offerings for you the first one is the live cohort best course and the second one is the recorded offering the Live code base course happens once every two months and will go on for eight weeks while the recorded course contains the recordings from one of the past cohorts as is if you are in a hurry and want to learn and want to binge learn system design I would recommend going you for the recorded one otherwise the Live code is where you can participate and discuss the systems and its design life with me and the entire code the decision is totally up to you the course details prerequisites testimonials can be found on the course page arpitbani.me masterclass I repeat ad with many dot me slash masterclass and I would highly recommend you to check that out I've also put the link of this course page in the description down below and I'm looking forward to see you in my next cohort so on slack we can invite people by email there are two kinds of people whom we can invite first as internal second is external the difference is that internal people when you are inviting they are directly added to the workspace while external are just added to a few set of channels now depending on whom we are inviting we would want to trigger an internal onboarding floor and external onboarding floor which could be as simple as just showing a different dialogue but with this this seems like a very simple statement but hey can we not just show them a check box when they invite someone won't we just show a checkbox that hey is this your internal employer or an external person but you would not want to do that that would ruin the user experience like the onboarding flow plus what if someone just wants to uh uh what if an organization wants to invite multiple folks in which there are internal folks also external folks also you can't just do that right so this is where from a product perspective it is very essential for you to classify every single email into an internal or an external so that you can show them or take them through that through that specific dialog boxes through which you can make onboarding as smooth as possible now this is where we start looking into things and see that such a simple problem statement of inviting people leads us to think from a product perspective and see oh my God we didn't think of this case oh my God we didn't think of other case right but you would still say that hey if it's an organization then isn't it obvious that all people of that organization would have the same email domain so if I get in uh if I get and so if I have to invite a person with a different email then that person would be classified as external isn't there's a no-brainer it is not it is not because there are organizations in which emails are maybe per region let's say I have let's say I'm operating an MNC called bar.com and I would give bar dot in to all the folks who are based out of India and bar dot us to all the folks made out ways out of us now these would become their email domains right there would be a possibility of that second is an organization might also want to classify their uh their interns they are basically contractual employees their vendors with different email domains so that they could restrict accesses on other set of their internal tools private infrastructure and whatnot so now here we see that this is not as simple as we thought right now given this we would want to make this process as simple of an onboarding process as possible which is why we would need an email classification service right so how do we go about it now here we go the way we would want to approach this is through heuristics like because heuristics would always work you may very clearly think that hey why why do we want to over complicate things with machine learning AIS and whatnot can we not just can we not just apply simple heuristics so what here what you are trying to do is given an email let's say person a wants to invite person B whenever an invitation is whenever a person a types a person B's email address or email classification service kicks in and it classifies it open internal and external so depending on which you would have you would trigger the corresponding dialogue boxes and the onboarding flow so here we take look at three specific cases the first one is like first two cases are no braider where it's mostly driven by configuration while in another case we would have to derive the answer so first is the settings context because it is very possible that an employee that uh in a workspace the administrator has has configured that these are the domains that are internal While others are external or it they might have just basically uh shut down uh basically external invites right it's very much possible so if you have configuration that would help you that that would help you do a shortcut evaluation right or a short circuit evaluation of the part that hey is it an internal or an Excel One you go about that second is where you go with the inviters context so for example if I would want to invite someone and if my domain is let's say a bar dot external then and I'm inviting someone with bar dot external so which means that we both have same domain so whatever my classification is same thing would apply to that person as well now this is another simple heuristic that we can apply that would be like almost a surety that hey this person also belongs to the same class as the other person right so these two are fairly simple and would cover at least 50 percent of the cases but there might still be a chance where there are emails that you are seeing for the first time you cannot just mark them as external mark them as internal and you cannot also probe every time when you see a new email domain hey do you want to add it to this list or not right you just want to make the process as seamless as possible so that because the more adoption you get the more Revenue make the company makes money and we keep our jobs right okay now comes the third case where you cannot derive something out of simple configuration like through settings or through inviter's context the third one comes as a teams context now here what happens is so now here the challenges that a workspace can have millions of employees so slack does not put any restrictions so long as we give them money or we are on that paid tier they don't put they they typically don't put any restrictions on the maximum number of people we can invite so workspace may have millions of people so now given a query which is which you sent today given this email ID give me the classification if it is internal or an external given this if you have millions of people how quickly can you identify if this is an internal or an external right now this is where the challenge starts to creep in right so now the now basically we have to find a solution to that now the solution to this is you all might have guessed and it's pretty straightforward it's like literally peeking into our eye is we keep track of all the domains that are part of my workspace and have an aggregated count against which and we use that to classify right for example if I have let's say four domains part of my workspace in which I have people whose email ends with bar.com some people who whose email ends with bar dot in and there are few whose end with gmail.com now these are all part of my they are part of my workspace right I as an admin have not gone and and basically and basically allowed these sort of emails to be there you just keep on inviting people seamlessly and that system would need to keep track of all the count like like the overall aggregation of the number of people against each email so what slack does behind the scene is it keeps track of domains in their email classification service they keep track of domains and the domains that they keep track of is look like the the table looks something like this for a particular workspace or a theme they specify or they keep a track of domains that they have the count against them the date at which they'll it was last updated and the role of that particular group basically what they're doing is that it says that for team a bar.com has two people with role admin team a bar.com has 68 people with role member right now why roles are segregated here we will we will go to it's a it's a very nice hack it's a very nice heuristic that they derive through this so the idea is in this table for every team that they have they would keep track of all of these things right so all of these aggregated statistics now so with this why do they have to like can they not just do it at domain level why do they need to add role level information here they are adding row level information because if the admin is having at the red bar.com it's a bigger indication that it is an internal domain and because admin typically would have the internal domain so that is why they are just keeping the aggregated count which is grouped by domain and role for a particular team now these kind of heuristics you can apply when you are building an image classification service so here the idea is pretty simple given an email you just see that for a particular like you extract the domain out of that email and see where it holds right and when you see it you see what percentage of people and role combination are they have the same domain right if it is more than 10 percent you consider it as an internal if it is less than that you consider it as an external so 10 percent is a threshold that slack internally maintains like obviously it's a tunable parameter so which means that given this as my distribution bar.com admin 2 bar.com member 68 people bar dot in member 30 people and gmail.com member three people so I can see that if I am want to classify for one directbar.com it would be an internal classification because there are 68 people right with bar.com with bar dot in there are 30 so 30 out of almost 100 uh still more than 10 percent then food or few three gmail.com is will be classified as external because there are only three people out of 100 almost 100 uh which are having this particular thing so you can you would you are tempted to classify it as external right so this is a simple heuristic that they went with a simple high level architecture for this would look something like this a user never wants to invite someone named classification service is triggered it refers to the domain stable in order to identify or in order to classify where this particular email or basically where this email particular where this particular email sits sorry so it's internal or external now how would this domains table be populated you might say hey it's a no-brainer right whenever a user is created or updated I keep updating this particular table so which is what we exactly do we consume it we consume all the events being flushed onto Kafka we consume it through the workers and keep this table updated now this drawing boxes is easy but think about it imagine how are you actually updating the table that is also very important design decision because if you just do count plus plus would that work what if that row does not exist you'd want to make it as simple as possible so which is where how we go about it is we use absurds in order to add or remove something from this table or rather increment or decrement something into this table because absurd statement seamlessly works so in what upsets are is it either inserts or updates if the entry exists it updates if entry does not exist it inserts now this absurd statement if you would not have written upsert statement then you would have to first get if the entry exists then update if it doesn't exist then you would be inserting onto that so instead of having that if else in your code wrapped around a transaction you typically just fire an observed statement right so what you do is whenever a user is created your file an observed statement like this upset count equal to count plus 1 where team might equal to 7 and domain equal to bar.com and roll equal to member this wave entry doesn't exist it would create that entry if it exists it would update the entry to count equal to count plus one right now here the key advantage of using absurd is absurd takes row level locks and the operations are very relative so it basically solves both the problem in one shot so even if there are multiple absurd statements firing at the same time because row level locks exist it ensures that the data always remains consistent now when you are updating a particular user a movement might happen is a user is elevated to become an admin so in this case what you would have to do is you would have to read when a role changes of a particular person you would have to have fired two absurd statements first is where you do count equal to count minus one for that same thing where role equal to member because now member count is is minus minus while admin count becomes plus plus right now there are multiple such statements fired but no matter how many queries are fired because upset is taking a row level lock it is ensuring that the system is eventually consistent because you are not missing out on anything right and this is very important plus you are not wrapping multiple statements in a transaction which might lower the throughput so you're still getting enough throughput out of the system but is it still done is it still done how how about this like is like are we missing out on something there is a very interesting challenge that is coming out of this particular thing and that challenge is a broker that we use that is consuming the events that would be consumed by the workers and updating the database these broker offer you different kinds of guarantee no one gives you exactly one semantics because what they give you is at least once semantic which means that a message that you are receiving it is possible that you receive the same message again because broker thought that it message was not delivered so it recued it and almost all Brokers operate with at least one semantics with this what is a possibility is that the numbers that you have can drift now this becomes a problem because now let's say if a particular user got created you updated the entry in the database but your broker thought that a message was not consumed or before the message was deleted you re or the message got recued again so then you are doing count plus plus not once but twice so your numbers there is a very high chance that they would drift over time so how do you solve it which is where what slack did is they had or they built a Healer service whose job is to periodically heal the numbers and bring it back and bring it back to a consistent state but when you do that an interesting challenge crops up now this challenge is what so first of all when you trigger a Healer service the Healer service is triggered whenever we see it but how do we know that there is a drift so you again you apply heuristics here first you may think hey let me just do it periodically let's say every one day or sorry every day where one job I run for every team that would heal the system second is when you when a user upgrades a let's say workspace was a free tier and then they changed their plan to a pay tier you might just want to Recons the numbers and ensure that everything is in place because their licenses that billing depends on this right third is when an email is added for the forces when an email a new email is seen you may would want to just trigger a healing process now given the frequency of this healing process you would want to ensure that it's lightweight it's consistent and it does not make your data go inconsistent now let me walk through you through that and again it's not it's easy to draw box around healer and hey this would heal the system but how do you actually implement it now a naive approach that you may think to heal is that hey let's say whenever A Healer runs I would just recompute the count and update it in the DB so which means that whenever my healer is running I am simply going through all of the users that I have I'm extracting their email domains and then I'm doing the count in memory and I'm updating it in the database which means I'm replacing the domains DB for that particular team The Edge case the edge case here is while so the point when you started your healer then you computed the numbers then you crunch the numbers you got that aggregation and then you're replacing now let's say this healer took five minutes to compute it because there were far too many users now in this five minutes the new users that came in or the new updations that happened what about them you would be losing out on that because then when you replace it the updates that happen in between are lost because you are doing a complete replacement so that's not good right so there has to be a better approach so what do you do so in that case the answer here is again the upsets operation play a very important role so what you do is when your healer starts at that point in time you keep track of the date time this is the date time at which your healer started now it in the table in the domains table that we had we had a column called Date Update now this is what is with this is what would tell us that it up until this time this was the state of my database right now you keep track of this right so what you do the idea is pretty simple you when you your healer starts you keep track of the date time when you have the date time you start Computing so you first read your domain stable you know that this was the count that was there in my domains table you go through all the events of the users again up until this daytime so who's updated ad is up until the noted date time you compute the numbers you see the drift and you know that hey this is what I want to do plus n minus and what I would want to do again absurd operations you will not do replacement you will trigger upsets right now with this what happens is up until this point the time at which healer started you knew what the state of your domain stable was that is a snapshot that you have second you went through all the events of user creation updation deletion up until that modified time because you would have updated ad field in your users table or somewhere like that you would go through that and Recons the numbers find the drift and you create an absurd operation of plus and minus and whatever your operations are you would start pushing those things through that same route now what happens with this is the new events that are there are anywhere being upserted the existing one the drip that you computed will also be applied so with healer with this approach you are ensuring that you are not replacing something so you are always upserting this way you do not lose any events or you do not lose any updates that you have made on your on the database so now the architecture of this looks something like this everything else Remains the Same and you just plug a Healer who job is exactly what I just described right so from the events that are flowing in a Healer consumes it and it it sees it basically queries the DB gets the drift it triggers the corresponding absurd happens which happens on the DB and system eventually heals so this entire system is eventually consistent it's not strongly consistent it's eventually consistent but it would definitely converge in some time not you may not be sure by when but you would definitely be sure that it would eventually be converging to the correct state and this is where I always say the Devils lie in the details and this is where we see we could have just drawn boxes and said hey this is the system that we designed but in reality when you start thinking of the implementation you start realizing that it's not as simple as it seems we could have very easily drawn A Healer box and say okay this would just heal it but that's not where the fun lies of fun lies in the intricate granular minute details of implementation and yeah this is how slack does it all of this is taken from slacks engineering block which I've Linked In the description down below I would highly highly highly highly recommend you to check that out I know this is what I wanted to cover today I hope you found it interesting I hope you found it amusing just keep an eye on the details of any system that you are learning go through that integrate intricate details of implementation and which is and that's how you become a better engineer I would highly highly highly recommend you to do that for every single thing that you are studying right so yeah that is it that is it from me for this one I'll see in the next excellent thanks letter [Music]