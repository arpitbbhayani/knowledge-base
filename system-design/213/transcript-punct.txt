a truly scalable system is one that can be scaled horizontally. a database is typically scaled by splitting the data across multiple shards, but what happens when a particular shot becomes hot due to excessive load hitting It, While others remain underutilized? a classic way to address this is by moving a fragment of data from one Shard to another. but how? in this video, we look at how Shopify rebalances the chart by moving a fragment of data from one database to another without incurring a downtime. but before we move forward, I'd like to talk to you about a course on system design that I've been running for over a year and a half now. the course is a cohort based course, which means I won't be rambling a solution and it will not be a monologue at all. instead, a small, focused group of 50 to 16 genus will be brainstorming the systems and designing it together. this way, we build a very solid system and learn from each other's experiences. the course is enrolled by 800 plus Engineers spanning 12 codes and 12 countries. ingenious from companies like Google, Microsoft, GitHub, slack, Facebook, Tesla, Yelp, Flipkart, dream11 and many, many, many more have taken this course and have some wonderful things to say. the course is focused on Building Systems, the way they are built in the real world. they will be focusing heavily on building the right intuition so that you are ready to build any and every system out there. we will be discussing the trade-offs of every single decision we make, just like how you do in your team. we cover topics ranging from Real Time text communication for slack to designing our own toilet balance, live text commentary to doing impressions counting at scale. in all, we would be covering roughly 28 systems, and the detailed curriculum, split week by week, can be found in the course page linked in the description down below. so if you are looking to learn system design from the first principles, you will love this course. I have two offerings for you. the first one is the live cohort based course and the second one is the recorded offering. the Live code base course happens once every two months and will go on for eight weeks, while the recorded course contains the recordings from one of the past cohorts, as is. if you are in a hurry and want to learn and want to binge line system design, I would recommend going you for the recorded one. otherwise, the Live code is where you can participate and discuss the systems and its design life with me and the entire cohort. the decision is totally up to you. the course details, prerequisites, testimonials can be found on the course page. arpitbani dot me slash masterclass. I repeat, ad with many dot me slash masterclass and I would highly recommend you to check that out. I've also put the link of this course page in the description down below and I'm looking forward to see you in my next cohort. so people can host their shops on Shopify, and Shopify uses MySQL lizard primary database and this is what their current architecture looks like. with respect to that, whenever a request comes in, the request hits their front-end proxy, which is typically nginx. from here, in this nginx layer, they have written their routing modules, which routes the request to the corresponding pod. now this pod- please don't confuse it with the kubernetes, but Paul- is just a logical grouping of shops which share a common database. so in this diagram you can see shop one and Shop 2, part of part 1, which share the same database, for shop3 and Shop would share the other database. right now, here these two databases, they do not have any data in common. these are shards, right? so these are MySQL shards which are running now. given this, when the request comes from the front end to the nginx. nginx, through its routing module, decides where to forward the request to requests, goes to the corresponding part and serves from that corresponding database. right now, within this database, each table would have a column called shop ID which help us identify that this row belongs to this shop. like if you have an orders table in that order stable, there will be in in that order stepper, there will be a column called shop ID which tells that, hey, this order belongs to this particular table. now, when A Shard becomes hot, which means, let's say, there's a huge amount of load coming on shop one, which makes this pod one hot. because of this, the database which was shared between shop one and Shop 2 is now really hot. right, because a lot of reads and writes are going to this database. so how do you handle this? now, this one shop becoming hot might make this entire pod effect, which means that there are hundreds of shops hosted on the same part. they are all getting affected because of workload on one. so what do they do? they would have to move the shops from one pod to another. so moving API service is pretty easy. you just shut down server over here and you add over that because it's stateless. but what's stateful is the data. so how do you move data from one database to another without having a downtime, which is what makes it extremely challenging but fun at the same time. so a normal approach to think about it is: hey, let me just iterate through all the tables of my database, pick the rows with a specific shop ID and I move this rows from one database to another database. what's the problem? the problem is downtime, because a shop can have huge number of rows. while it is having huge number of rows and let's say, the migration is going to take one hour, you can't just say, hey, my site would be down for one hour. that's not gonna happen, right. so which is where, without incurring any downtime, you have to move data from one database to another, which is what makes it really interesting problem to solve. so next, like: why do we need to move? first reason that what happens when a Shard becomes hot, like this is like if, if, nothing could happen, if rather, nothing would happen when there is an excessive load, you can just say, hey, why do we even need to get? but two critical reasons why you would want to move data or you would want to move shop from one pot to another. first reason is that the risk of failure due to over utilization. here we clearly see that if there is a huge number of requests coming on one shop, it would make this database piping hard, which means that there is a chance, there is an increase in probability of this fragment of infrastructure failing, which you should not let happen, because one shop spacing this excessive load takes down other shops with it- is unacceptable, right? second is inconsistent database utilization across charts. primarily, you see that while one shot is operating at 100 capacity, While others are just serving a 10 percent, 5 percent, two percent. you don't want that to happen. you want near equal distribution of load across our infrastructure. so, which is why we think of: hey, let's do rebalancing of shards such that the load across all of my pods is fairly equal, right, okay? so the first problem comes: how do we decide which shop lives in which Shard? now, this is where it becomes interesting, or rather interesting per se, but more about what all factors can you consider while you are making this decision? so this is typically done by the data science team, because their job is to Crunch data, to apply those models which tell you that, hey, this shop, this should move to this chart, this shop should move to another shot, right? so the factors that you might consider that, the first normal factor that you might come to a conclusion that, hey, let's just move it with respect to the number of shops in a database. isn't that a straightforward way to think about it? that, hey, let me just split. every database handles 100 shops, but that's not good, because when you do that, it's very much possible that there might be a pod which is handling three, or like many, hot shops, which means shops which are very resource intensive. they are being hosted on one shot. you don't want that to happen, right so, which is why you apply heuristics to see, hey, where which shot can move to which shot. few things that you can consider: you can consider historical database utilization, which would tell you, hey, this is where this shop should lie, this is where this shop should lie, this is the basic, this is the pattern of utilization of this particular shop. so this is the best place for the shop to be. otherwise, you can look at historical traffic that you see and, more importantly, you can use forecasting, because, let's say, there is a shop which calls you and tells you: hey, uh, we are having a big, big flash sale, so we would want- uh, so we are expecting this much of traffic. given that you already know that these folks are going to have a flash sale, it's better to be prepared. so you would just move their shop to a isolated place so that that cell can go really well, right? so there are lots of factors. you cannot just converge to one, so it's heuristics of all of them. it just basically playing around with weights and see how do you move here and there, which is what makes it really interesting: that, given that you might be doing it frequently- frequently does not mean every minute, but frequently. it definitely means once every few weeks, given that you might want to uh, redistribute your load across pods, which means that your process needs, the process of movement needs to be automated. so, second, without having any downtime, right, okay? so now let's come to the elephant of the room. uh, how do you move the shops? so few critical constraints that we have to definitely be be very off that we cannot break. first, that the shop must be entirely available, which means that there should not be any, any perceivable downtime in the shops, right? so no matter what happens, no matter where you are moving data, no matter how good you are making that infrastructure or their performance, downtime is not expected, because it would impact not only your Revenue but your customers revenue, and that's more important. second, there should not be any data loss or corruption, because you cannot just say, hey, because I move the data from One DB to another and then, like, I just missed few rows, that cannot happen. every single row is critically important. you would want to keep it as is right. you have to ensure that there is no data loss, no matter what. third is that your movement should be seamless enough that your movement should not be. it should not be expensive enough that it puts burden in your own database or on your own infrastructure, right? so these are three critical constraints that we would have to operate on. so, then, this entire problem statement of moving shop from one to another- can be broken into three phases. the first one is we do batch copy and tailing of Bin luck. we'll go through it, each one of them in depth. second is to be prepared for a cutover. and third is updating the routing table. right? so do it step by step, and, in general, almost all systems are built step by step. so we'll go with the first step and see how these sort of baby steps help us achieve what we would want to do. so phase one: batch copy and tailing bin log. so here let's go one by one. so what Shopify does. so Shopify is built a tool called ghostferry- uh, it's open source. you can find it on GitHub. source code is predicable. it's written in golang, so it was very easy to skim through. but I would highly recommend you to check that out. and now, yeah, by the way, all of this thing, whatever I'm discussing, is taken from shopify's engineering blog, which I've Linked In the description down below. highly recommend you to check that out. right, okay, first step, the most or the most basic one, but really important one. so first step is: you do batch copy. you do batch copy of data from One DB to another DB. we know that every Row in the table has a shop ID as one of its column. you iterate through all the tables, pick the rows that has a specific shop ID and you write them into another database in a transaction. this way you ensure that there is a bulk copy happening from 1 DB to another. you might create like you might just have a process or a machine that is just basically editing through the tables and copying and pasting the rows over here, right while this batch copy is happening. you like this batch copy? obviously, while this batch copy is happening, there are new updates which are flowing in the main DB. it's like you have not stopped the incoming traffic through this DB. the new requests are still hitting the DB. so from DB1, when you're copying the data to db2, your DB1 is still live. it is still handling a lot of incoming requests that are coming in. so, which means that when you start copying, you also have to keep track of whatever new changes are coming in into this DB. how do you do that? which is where CDC comes in, which is where uh Bin log comes in. so, given that they are using uh MySQL, MySQL, the write ahead log file of Pi SQL uh is called bin log. you can keep track of coordinates within the bin log on. how do you do uh? on which point did you start copying? and these are the new updates. so all the updates that happen on the DB, they go to this bin log and it's really easy to write a parser for that, or there are tools available as well, which you can go through, which contains events that happened on the database. so, for example, if there was an event on order stable in the DB, so you would have something like this: insert order and the and the values of the columns, then update orders and the value of the column. so these are right ahead log files which dumps, which are dumped on every commit of a transaction in this right-hand log file. so from there, this would ensure that the first step is ensuring that your you are batch copying the data from One DB to another while you are keeping track of changes that are happening live on the database. now, where do you put this stuff? now here? there are two ways to do it. either you use CDC and put all of these events stream, all of this events in a queue. that is one way to do it. second way to do it is just make a note of Bin log coordinates. if you have a higher bin log uh retention, just keep a track of Bin lock coordinates from at the time at which you started your bad job. that, hey, this was the point when I started my bad job. so these are the bin law coordinates up until which, when my bad job completes, I would have data till this stage. after that, I would read and apply it there, right? so this is what you would have to do then. here, obviously, performance optimization: you just don't need to have just one thread which is copying the data from the batch copy. you can just have multiple threads to do it. okay, now, second step: once you say you have made note of that, either that bin log coordinate, that hey, up until this 10, or, in case you are using Q, in either case, you would know that you have completed your batch copy till that point. right, you know that because you will keep track, hey, from this point, I am anyway capturing all the live events that were happening. so before this, whatever I got, I need to just do batch copy up until that, but otherwise you would be copying it forever. you don't want that to happen. so you cop it till that, state you, you apply your for Loop until that particular bin log coordinate is hit. when you do that, which means that now your batch copy is done, which means that by enter time, when the batch copy started from your first DB, all of the data is present in your second DB. right now, what Remains, the things that remain is that you have to copy the new things, like from the time that you started a batch copy. whatever new rights have happened onto the DB, you have to take and apply it over there. right. but here a critical thing- that you don't just have to apply all the updates, but only the updates that are for your shop, right? so, which is what we do- we capture, filter and apply the changes into db2. right, so we start consuming the newer rides that are happening in the DB. so here what happens is that, because the batch copy would be very fast, you are bulk copying the data of the shop that you are interested in another DB. then you are, you have kept track of from this point, I did it right- and then you're starting from that new point and just filtering the events that you are interested in and applying the changes into another DB. so this way there will be some lag, some lag between the new rights happening in the main DB and being- and that right being- updated in another DB. there would be some gap between the two. that is the replication lag. you may call it replication lag, right, but in general just a lag that is happening with you then. so you measure this lack that hey, how old are my entries there. you would keep a track of how old are these entries and if, once they hit near real time, maybe few seconds, one or two or three seconds difference, which is when you know that, hey, now this is small enough for my db2 to catch up. so, given this, what do you do? you stop the right on your main DB as soon as you stop the right on the main DB. this is where your small, small downtime would might come in. might come in. you can handle it on the application side so that your end users don't see it as a downtime, have retries and what not, to handle it, right, but it should be very small enough, hardly two seconds, three seconds at Max. but you would have those retries in your application, like that, in case your right field should just retrying it. this way, your users would not see any perceivable downtime, but you would still have this small cutover phase where your DB is not accepting the rights because you are switching the database, right, so you just have to be aware of this fact that you might need to have retrace there, right? okay, so when? so here, what happened is here. we have two things that we did. we first did batch copy up until a certain stage. from there, we started capturing the Live Events. we started applying those Live Events onto another DB. right, once the difference was few seconds, one or two seconds, you stop the incoming traffic onto your database or onto your, onto your API site and you waited for everything to be going down, right. so, once all the changes that you know- because you are not accepting any new new rights- once you have consumed everything, you would know that, hey, everything is caught up. right, once you know everything is caught up. so at this stage, what is this stage? at this stage, there are no new rights coming onto the source DB and your Source DB is equal to Target DB because the data on both the databases is exactly the same. there are no new rights coming in. this is the time when you make that switch, where you enter the third phase and you update the routing table. and what would this routing table do? this is that that nginx layer in which you have defined, or you have defined, a custom routing module which says that, hey, for this shop, you go to pod one, but now it changes to go to pod 2.. so when this happens what you would have- and here we are just talking about database side, because API server speed up is pretty trivial, because it's entirely stateless. we spoke only about a database side of things. so here, what did you do? you change the routing layer and updated that. hey, shop one that used to go to pod one now goes to pod 2.. then the new request that comes in, all the new requests- will come to nginx. nginx would say hey, it's part two, and it would forward that request to pod 2 instead of Pod 1. and this is how you do this migration from one port to another without having any downtime. once that change is done in the routing table, you start accepting the request and all of the requests for shop one that used to go to pod one will now go to part two without having any downtime, because the database as is basically caught up, right. so there is no problem there. and this is exactly what you do step by step, right? so first space is to do batch copy. second phase is you enter the cut over. you apply all the updates coming in from the bin log. third, once the replication lag is less, you wait until all the changes are caught up, because you stop the rights onto the DB and then you are making the change in the routing layer right. once all of this is done, you start accepting the rights because you can't wait. you can't wait, I'll validate and then I'll start accepting the rights, because the problem is that you cannot have a longer downtime, because it should not be perceivable by your- by your- customer. so, on application logic, you would have retries. but, more importantly, once your shop moves from Pod 1 to pod 2, sure what you do, your next steps is you have to validate that the data that you have done is proper and then you delete the data from the role DB. so now your shop one has now been successfully moved to part one, and this is almost automated. just, obviously, you might just need a few Engineers keeping an eye when, whenever, this is happening, but this is almost an automatable process, not not really? uh, like something which becomes extremely complex over time, but you would still need a pair of human eyes to keep an eye on in case something goes wrong. right, but this is how, overall, the flow happens. or, and this is how you actually solve the hot node problem, or hot partition problem, when you would want to move data from one node to another without having any downtime, right? the steps vary depending on the technology that you are using, but overall, the flow would look exactly like this, no matter what you are using, right? just few, just few cosmetic changes here and there, right, and yeah, that is our and that is exactly how Shopify does it. all of this, again, is taken from shopify's engineering blog. I have linked that blog in the description down below. there are few links that that I would recommend you to go through which would cover this entire concept really well, but I hope you found it interesting. you found it amazing. that is it for me for this one. I'll see you in the next one. thanks, [Music]. [Music]. thank you. [Music].