so when a product is catering to a large audience providing contextual information becomes important and at the scale of Airbnb it becomes non-optional hence the engineering team at Airbnb they collated all the data and structured it into a knowledge graph that today Powers their search Discovery and trip planner services in this video we take a detailed look into how Airbnb designed its Knowledge Graph some key components of it and some key design decisions it took while architecting it but before we move forward I'd like to talk to you about a course on system design that I've been running for over a year and a half now the course is a code based course which means I won't be rambling a solution and it will not be a monologue at all instead a small focused group of 50 to 60 Engineers will be brainstorming the systems and designing it together this way we build a very solid system and learn from each other's experiences the course is enrolled by 800 plus engineer spanning 12 cores and 12 countries ingenious from is like Google Microsoft GitHub slack Facebook Tesla Yelp Flipkart dream11 and many many more have taken this course and have some wonderful things to say the course is focused on Building Systems the way they are built in the real world we will be focusing heavily on building the right intuition so that you are ready to build any and every system out there we will be discussing the trade-offs of every single decision we make just like how you do in your team we cover topics ranging from real-time text communication for slack to designing our own toilet balancer to cricbuzzes live text commentary to doing impressions counting at scale in all we would be covering roughly 28 systems and the detailed curriculum split week by week can be found in the course page linked in the description down below so if you are looking to learn system design from the first principles you will love this course I have two offerings for you the first one is the live covert best course and the second one is the recorded offering the Live code base course happens once every two months and will go on for eight weeks while the recorded course contains the recordings from one of the past cohorts as is if you are in a hurry and want to learn and want to binge learn system design I would recommend going you for the recorded one otherwise the Live code is where you can participate and discuss the systems and its design life with me and the entire cohort the decision is totally up to you the course details prerequisites testimonials can be found on the course page arpitbani dot me slash masterclass I repeat arpitbenny dot me slash masterclass and I would highly recommend you to check that out I've also put the link of this course page in the description down below and I'm looking forward to see you in my next cohort so Airbnb holds experiences places hotels events restaurants markets homes and much much much much more so while planning for a trip it is important to show all of this critical information to the user so that user can make an informed decision while making the booking now to have all of this information obviously all of this information is present there on each of their own respective databases but to have them collated helping users make the best decision you have to have this information at one place making them easily accessible this is where Knowledge Graph come in it is not a new thing Google you basically Google has been using it for a very long time Facebook also has their own Knowledge Graph and whatnot so here we would take a look at how Airbnb does that right okay so Airbnb a very traditional architecture they have most of their data like most of the transactional data present in the relational databases but why they cannot use that information to power this functionality because like with relational databases you typically know that it's a most common way to store stuff you have for each type of entity you have a table right and every single row of the table represents one entity for example you might have a table for hotels you might have table for events a table for experiences and what not and then what you would have is you would have foreign key references connecting to all of them so relational databases are meant to work very well with the transactional information for example payments the way we do it affordable users post even for this for the transactional thing where I'm getting something putting something that sort of stuff on an individual entity level it works really really well but when uh when a traveler wants to book something for N B and B the requirements are not very straightforward they might for example what if we would want to take the user on this journey of finding a city that hosts a type of experience in July and August for example the user is trying to book a uh to basically book a trip in the month of July and August right but he or she is looking for a very specific type of experience and you and he or she is open for multiple cities so you'd want to list down top five cities where this type of experience is there in the month of July and August now this is not something that you can write a SQL verified because there could be a lot of types of information and the way you have you might have a micro service it's not so easy to do that other query would be find neighborhoods in Los Angeles where there are huts or Islands available so here you are going for a state type in a particular City in sorry in the neighborhood of a particular City so answering such queries with traditional relational databases is a big pain so that is where like here if you look at this we would want users to have enriched exploration uh experience it's like basically surfing through the data this is where knowledge graphs come in so now how is Knowledge Graph structured at Airbnb so the key component the key infrastructure components are specific highlighted first is the graph storage where they would be actually storing the knowledge graph second is graph query apis through which your search service planner service and whatnot will be using or will be querying this graph storage tools Rel to surface and element information and then a storage mutator so that this information can be updated by some by some peripheral services right we'll start with the first one graph storage so how is graph stored you might think hey graph needs to be stored let me just use a graph database no graph database is very like they are very operation intensive they are not very easy to use but grab database obviously they are meant for very specialized use cases but we do not have very specialized use case you might just work very well with the normal relational DB as well but no one's denying that you cannot use a graphdb you can use Airbnb did not use it because they didn't have expertise in using them right so what they do is Airbnb stores their entire Knowledge Graph in a relational database the idea is where in the in the in a normal graph also you have nodes and edges in the relational database also within split across multiple table they store this very information nodes and edges but the way the way any graph you if you are designing anything anything related to graph typical three things that you might have to think of it's subject verb and object for example New York is in USA so subject verb and object basically two nodes connected VI and Edge right so this is this triplet is what most graph databases use to store this information which we can very well mimic in a normal relational database within a table with three columns so each node type in the graph has a different schema for example a location might have name and a GPS coordinate while an event might have name date and venue so there is a way in this in their own Knowledge Graph to specify that hey this is my node type for this node type this is the schema so that when they're making an entry of this in the database they can have that particular type of schema like they would be able to ingest that particular type of value then similar to nodes they have edges types for example landmark in city is an edge type that hey Taj Mahal is a landmark in the city of Agra right so this is how your relation is your relationship is defined and each Edge type would have that what kind of nodes Can it can connect to for example Landmark inner city can connect a landmark node to a city node because you just can't do random connections you need to have that strict constraints that landmark in a city can connect only Landmark from like a landmark to a city right and they didn't go for graph DB again just to emphasize on that that keeping things simple is the heart and solid scale is to make it operations because operations overhead is there and they do not have enough expertise to like at that time they didn't have expertise to manage a graph DB they were very familiar with additional DB it's of them really well so they use relational DB to build it right and and the knowledge graph that they have needs to be periodically dumped for offline consumption for example I don't have to always query the graph my knowledge graph to get some information for example let's say if I want to do some search engine ranking or if I'd want to run some recommendation so instead of every for everything firing query to Knowledge Graph will be too expensive because it would put unnecessary load onto your knowledge graph so that's why periodically the data from the knowledge graph this particular database is dumped into a format that other service other services can consume from and they typically do it for offline ranking processing recommendations and whatnot right now we covered graph storage now let's talk about graph query API so how a normal service let's say search wants to use this knowledge graph how would they query it so a graph typically is meant to be traversed because you don't know what kind of query you'll get but you would have to Traverse the graph and find the most relevant information out of it so for example you might want to find all the places like all Place nodes connected via with a particular City node Los Angeles with h type contains location where listings are more than 5000 and they are Scenic category which means that I want to find out all famous places in Los Angeles where number of listing is more than 5000 and they have a scenic view in them this way if I want to do this I would want to Traverse a graph so there has to be a way through which I should be able to provide a query now this could be a simple Json format in which they are expressing this query and this query layer understands it understands that particular Json and then goes to the knowledge graph converts this type of query into an into your relational database understandable SQL query fires on the relational database gets the output and sends the response back to the user the idea is this graph query layer it takes an input a Json which is a very sophisticated nested query converts it into SQL fires it onto the database gets the response and sends it back to the client right this is the role of graph query API layer and this totally depends on how they would want to build it they typically did it with simple Json you can have your own custom format no one stopping you from doing that but the idea is keep it simple Json everyone understands user that right then the third part which is the most interesting part of this is the storage mutator now here and the key thing here is so say we have some information in our knowledge graph but obviously let's say I have listings now that listing changed right so the description of the listing chain now how will this change the information because your listing would have its own service for example let me use a simpler word let's say you have a City information so City will have its own micro service or have its or is its in its own database now you would want something change in that and now this chain needs to be propagated to this knowledge graph so that whenever someone fires to this knowledge graph it gets the latest data now to do this what would happen is from this database how would the change propagate over here you might say hey when something changes over here let me invoke a Knowledge Graph API to update the information so this is a synchronous update but just imagine at a scale of Airbnb so many updates across so many entities would be happening in so like so frequently now all of them making synchronous updates to this knowledge graph is catastrophic so synchronous updates would make everything slow expensive and time consuming so can we do it in an async way this is where what storage mutator does is it exposes like it takes input from Kafka now anyone who wants to update something in a specific format can put a message into Kafka this mutation this storage mutation accepts those message and updates the knowledge graph this way the mutation layer exposes like or rather it allows us to do bulk updates in our knowledge graph and this is such a beautiful design because in most cases people think hey Knowledge Graph is a service let me update it through an API but if you do that you are putting unnecessary pressure onto this knowledge graph while you are making things slower to do bulk updates and you might also want to expose a bulk and pot and whatnot keep it extremely simple let it happen over Kafka because in Kafka message would remain persisted they would ingest the data slowly it would be consumed and the knowledge graph would be updated a simple high level architecture is what you can see over here I'll explain it in a very verbose way so what you have is your simple graph has a storage your relational DB is the storage right now your graph query layer your end user which is maybe your search service your client search service planner service product listing page all of them they use graph query layer to fire a synchronous query to this graph so graph query instead of directly talking to the relational database they are talking to a storage abstraction it's purely your implementation if you don't want to do that don't implement it let directly your API Handler invoke uh the like basically convert it into SQL query and fire it but this storage abstractions job would be to primarily take the Json input convert it into the SQL query and fire it onto the relational database get the response send it back to the user done second is this is what your normal flow would look like then periodically your relational database is dumped into a data warehouse maybe a redshift may be S3 somewhere relational database periodically dumped uh onto your data warehouse so that it can be consumed by search or recommendation service for offline processing right now you would have a normal ingestion flow where through the mutation a like a batch or a streaming ingestion job would be run whose job would be to take in regular updates that are happening from different sources through mutation pass it and update it in your relational database right this is what your regular flow would look like and then for bulk mutation that comes in some external mutation something that you would want to do except those events through Kafka and those updates from other sources can happen both ways asynchronously through Kafka or synchronously through graph API both ways are fine and this is a very simple extremely simple high level architecture of airbnb's uh of airbnb's Knowledge Graph extremely simple but see how beautifully they made those design decisions where are they using it synchronous versus asynchronous these are the trade-offs that are extremely important when you are designing scalable system right and that is it that is it from this one I hope you learned something interesting you saw the beauty of simple system simple systems always scale keep that in mind so yeah that's it for this one if you guys like this video give this video a thumbs up if you guys like the channel give this channel a sub I post three in-depth engineering videos every week and I'll see in the next one thanks [Music] thank you