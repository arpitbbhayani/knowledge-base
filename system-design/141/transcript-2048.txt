putting such code into production can take down your entire infrastructure and could cause a massive outage.
in order to handle such situations gracefully and provide us with an early warning about some things wrong, we have something called as a canary deployment.
in this video, we take an in-depth look into canary deployments.
it's a very interesting story- understand how they are actually implemented, talk about the pros and the cons of this deployment pattern and conclude with one really solid use case where you absolutely need canary deployment.
but before we move forward, i'd want to talk to you about a code based course, or system design, that i have been running since march 2021.
right, if you're looking to learn system design from the first principles, this course is for you.
right, i have also attached a video, verbatim, as is, from my first code where we designed and scaled instagram notifications.
canada deployment is a pattern that allows us to roll out our code, features, changes, whatever you want to ship to an initial subset of users before we roll it out to 100 of them.
so the idea here is that when we are rolling out our things, or when we are rolling out our changes to 100 of the users, we have to be 100 sure that this would not cause an outage, right?
for example, if we have seven servers in production, out of that, seven servers on one server, you will deploy this new code or the new change that you have right, and then you will monitor this server.
are there any bugs in the latest code that that you have just shipped right?
is you deployed your code right?
if that is well you are, you are pretty confident that, hey, this is exactly how my code used to should work.
your canary deployment pattern acts as your early warning indicator, which which warns you pretty early if something's wrong in your code, right.
this is how we avoid a massive outage, because if we already detected on that one server that, hey, something's wrong, you would not go and proceed to 100 of deployment, right.
so then you would be immediately rolling back your changes from that one server.
so overall flow when you have a canary deployment would look something like this: you would deploy the new version of your code or the new changes that you have to one server, right, and then you would monitor the vitals of that server- cpu, ram error rates, pick your favorite vitals, or pick the vitals which is specific to your use case, and monitor them.
and also you may need to optionally test your business logic changes, if any, on this one server.
if all's good, then you roll it out to remaining- uh, you, you roll it out to remaining servers that you have right, and then, if something's wrong, that you are not okay with the changes that have been just shipped onto the server.
you would be rolling back from that, from that particular server, right?
in 1920s, uh, during coal mining, the miners, like what happens in a coal mine: there are a lot of basically toxic gases which release.
so in our canary deployment, that one server that we picked up is acting as that canary, which would tell us if everything's good or everything's not, something's bad, so that we can we can take those preventive measures and not roll it out and not go into a catastrophic situation.
so there are like the true deployment of canary or, sorry, the true implementation of canary deployment- depends on your use case.
but in a generic sense, if you are doing a server based rollout, what it would look like is you need to add a few bits and pieces in your infrastructure to get that thing done.
so what we do is we create a small parallel infrastructure, just like how we have for our existing, for our existing service.
let's say you are building an auth service and for that you want to ship out the new version of your code.
so you will create a parallel set of api servers with the similar conflict curve, with the similar configuration as your old one, but there would be only one or two servers that you would put there right, and then you will create a parallel infrastructure.
you'll put a load balancer in front of it, configure the rules such that five percent of the traffic goes to this new setup, 95 of the traffic goes to this old setup.
the idea is to route five percent of traffic to new setup, 95 of traffic to old setup.
right, pick your favorite infrastructure component, but you need to put that in front.
once that that proxy layer that is sitting in front it gets the request, it will transfer 95 of the request to the old setup, five percent of the request to the new setup and now that you are already monitoring the vitals on the new setup, you would know that if it's going good or not going good, or what's wrong and what's not, and then you can take a call on what to do next, right, okay, so now let's talk about the advantages or the pros of using of doing a canary deployment.
although the word testing and production in one sentence does not good is not good, but still it allows you to test the changes in production with real use, with real users, with real traffic, and that is pretty solid, because not all cases might be covered during a unit test, integration test or qa if that's an idle situation.
but then it is always better that you know exactly how your code is performing when it hits production.
you monitor that thing, but it gives you that power to test your changes on the actual users, on the actual traffic that you get.
so now what you have is you have your users making your request, coming to your proxy layer, proxier, transferring five percent to new infra- sorry, basic five percent to new infra, 95 percent to old infra.
roll backs are so simple that on your proxy layer, just configure instead of 595 000, this way, zero percent traffic would go to a new infra, 100 traffic would go to old infra.
this way, as soon as you detected something's wrong, you immediately rolled back and it was just a simple configuration change, right, and this is how you get click.
although some users were, some users were affected when that bad code was pushed on canary, but it did not impact 95 percent of the users.
this is what we talked about, that if a new version of our code has bugs or it crashes, has memory leaks, anything, when it is deployed on canary and when you roll it back, it is only affecting the request that goes to that canary machine.
zero downtime deployments, right.
five percent of traffic goes to old uh.
five percent of traffic goes to the new fleet.
ninety five percent traffic goes to the old fleet.
now i want ten percent traffic to go to new, then 25, then 50 and then 100 percent.
so then, basically, what you are doing is you are slowly cutting off the traffic from your old version of your code and slowly moving it to the newer version of it.
this way, from 0 to 100, you are slowly doing this roll out of your new codes, new features, new changes, so your deployments become zero downtime.
one thing to note that when the traffic would increase, always make sure that your canary- uh, your, your, your, oh, your, basically your canary fleet has enough machines to handle that load.
but the overall idea is you get zero downtime deployment okay.
you do a canary deployment right.
you just take each other, let's just push the code into the production.
okay, next advantage: we can use canary setup to do a b testing.
a b testing is extremely important in order to not make abrupt changes like, for example.
you applied some machine learning, change some algorithm and new.
for that, in order to be very sure that moving from v1 to v2 would definitely improve the relevance of your search result, you need to do a b testing.
you use canary deployment to do this.
the new version of your code with all the machine learning and all the fancy stuff.
and when you are very definite that you definitely see an improvement with search v2 in overall key metrics of your search, like ctr and whatnot, then you basically roll it out and then you are pretty sure that, hey, search v2 is definitely better than v1.
right, so av testing is pretty solid, it's pretty simple, it's pretty straightforward with canada setup.
for example you might want to start with, let's say, only users in india gets this feature, no one else.
so when they rolled out this feature, this new apk having upi payment feature should only be good going to people in india, no one else.
other use cases would be user cohorts, for example, all users older than 25 years of age but younger than 30 years of age working in an it company.
uh is your cohort, so roll out the feature to those specific users.
so when a new version of an app is released, you have an option to release it to the beta users who signed up for that.
it's more about a b testing kind of- but the idea of canary deployment still remains the same- which are rolling out the changes to a particular set of users right.
right, and that is a random selection of users.
so whenever a new version of a facebook app is released, it is first released internally where their internal employees use it.
okay now cons of doing a canary deployment.
we have canary deployment to test those things in production.
so although it's good for exceptional use cases, but doing it often will lower your overall engineering practices that you would want to have in your org right.
next, architecting a canary deployment is complex, as you saw.
you need extra infra components like load balancer, api gateway, proxy router, what not- or at least one of them to put to sit in front of it.
the next is parallel monitoring setup, because we need to know how our traffic is performing or how our servers are performing on or harvesting.
how is code performing on the old setup and on the new setup?
so what you definitely need to have is you need to have a parallel monitoring setup so that you know that the cpu coming from canary machines is this and cpu coming from normal machine is this, so that you can do side by side comparison.
old is floating around five percent, new is floating around forty percent.
you can only definitely tell when you have this exact side-by-side comparison of the same metric coming in from your normal fleet or from the old version and from the canary version of it.
now the final thing: when do you absolutely need canary deployment?
hey, golang is the new, the, the, the next big thing, the most performant framework or the most performant language out there.
entire business logic needs to be changed from java to golang.
you need to have a parallel setup where you are incrementally rolling out changes from java to golang and just to check if everything's working fine or not.
once your confidence- hundred percent confident- about it, then you make the hundred percent change to go like right, and this is where you would absolutely need canary setup right.