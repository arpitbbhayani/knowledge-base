search is one of the most used features in any e-commerce and to give a better user experience, it is almost customary to provide type by head search suggestions.
in this video, we will talk about how Flipkart made that type ahead, search hyper personalized and dive deep into their high level architecture and key design decisions.
Engineers from companies like Google, Microsoft, GitHub, slack, Facebook, Tesla, Yelp, Flipkart, dream11 and many, many more have taken this course and have some wonderful things to say.
the first one is the live cohort based course and the second one is the recorded offering.
so when a user is typing a query, we have to suggest some Search terms, because this gives user a better experience, because now user does not have to think twice on what needs to be typed, what's the spilling of it.
now the problem is: how can we make this type of headset suggestions hyper personalized?
so, for example, if your past history suggests that you have bought a lot of shoes and if you type sh, like your shoes should come at the top, and if you have purchased- let's say, always purchase- Shoes less than 2000, then shoes under 2000 should be the hyper personalized search suggestion that it should give.
that is hyper personalized for the user who is making that search.
so now, when we are thrown at this problem statement, or rather when Flipkart was trying to solve this particular problem statement, the first thing that they thought is: hey, what are the parameters to rank it?
because this entire problem statement boils down to how we are defining, or how we are defining, the ranking function, because we might have thousands of terms that matches sh, but out of which, picking the top five that suits the user, the best is what we want.
the first parameter for ranking would be the quality of the suggestion.
for example, if a search phrase is not at all popular, why should you even consider it in your search suggestions, even if it is hyper personally?
second is performance, which means that does this search term when click?
because if you are recommending a search term, the user is very likely to tap on it, which means that if a person Taps on it, there has to be enough items in the search result.
otherwise the performance is not good, which means the user is tapping on it and, let's say you say no results found.
so that should be your the another factor that you would be considering when you're thinking that, hey, I want to surface quality result.
this three parameters would Define a good quality search suggestion: first thing.
second is prefix like: should you only consider, let's say, person typed in sh?
should you only be considering the terms that starts with SH or sh can also be a prefix or s message can be a word within the phrase that starts with SH, something like that, right?
and the third one is: this is where the user personalization comes in.
that, hey, given that I know which user is firing the query, I would know the past action that the user has taken.
for example, if a user has made last three searches of shoes, the next search is very likely to be of shoes category, right?
similarly, if I know that historically user has purchased a particular item having a particular property, let's say, user has always purchased items which are under 2000 rupees- this makes it very simple for us to have that filter in the search query where you would, in the suggestion itself, you would show shoes under 2000, for example, right?
so now, one very naive way to build this- if I'm talking about non-personalized way- is to get all possible Search terms that user fired on your platform.
let's, on, flip cut everything that the user fired and you just rank them by popularity or by frequency and you show them and you just order it by them.
just imagine if three different types of users come in and all of them search for sh and the first user sees sport shoes, and on the second it's, he or she sees shirts.
so depending on which user is searching, what if this search suggestions can become hyper personalized.
so, first of all, a nice way to think about this is: hey, let me just create cohorts of user, let me just create groups, like, let me just create small groups of people having similar purchases to a similar interest, and then to all of them, let me show the same set of suggestions.
that's a nice way of thinking it, because what that would mean is that even if, like, there would be a chance where a user would be misclassified into a particular code- very high chance, right?
because every user search journey is going to be unique, the needs are going to be unique or the context is going to be extremely recent, which means that user has made last five searches belonging to a particular type of thing.
then the next one is highly likely to be belonging to the same category.
so that is where the first thing that we have to do is to understand the user intent that, hey, if user search for something, what does that user actually mean?
this is the taxonomy that I am talking about now, depending on the search term.
every search term that user is firing could belong, or rather could come, would belong, to one of these categories.
given that it would belong to one of these categories, we can leverage this information to create that context so that the next time the request comes in for search suggestions, we are able to use this or leverage this particular taxonomy to suggest the right item to the user.
now if my query is classified to shoes and sandals, like one query classified to shoe, second query classified to sandal, which means the entire context remains around Footwear.
so the next query or the next search query that is coming in, very likely it would be a footwear based query, right.
second is where your past searches, browsing history, purchase history- can be clubbed and mapped onto this exact same taxonomy and you can group them and then use some sort of AI, ml- not really AI, but basically machine learning model- to do Predictive Analytics and see, hey, what suits the best, right?
this would become the core and the Crux of making a better personalized uh, or rather hyper personalized, uh query suggestion, right.
so, for example, if I'm firing a bunch of queries, then for my, for the current query that I am grabbing, the suggestion, we should take a look at last n queries.
so for each query that the user has fired you would see which category it belonged to.
so this query belongs to this particular category.
so if last n queries belong to the same category, so the current query highly likely will belong to the exact same category again, right?
first is we evaluate the category similarity, which means that a probability that the current query that the user is firing is similar in category to T minus X.
for example, if I am searching for computer monitor and then if I'm typing c o, very high chances that I'm looking for computer mouse, because that starts with a C, right, so because they should belong to the same category.
second is evaluating reformulation, which means that, for example, if user is reformulating the query- which is typically what we do- for example we are looking for shoes.
I have a red shoe, but then I like the bunch of Nike things.
second query was red shoes.
so, leveraging this, you build a predictive model that tells: okay, hey, what are the chances?
if a person is typing this, you would want to build a predictive model that it belongs to this particular category.
then comes the part of personalizing the search.
now that we have the data, we have mapped it, now we understand what we would want to leverage now if we think about personalizing the suggestions.
the idea is pretty simple: the model that you will be building.
this model needs to be built on how user interacted with your system.
so, which means that that un like the one that the user clicked on gets a higher score, while it gets a negative score for the other nine items.
this way, you would want to rank it.
you would want to start ranking and assigning score to each of the suggestion that you are giving, and that's how your model would need to learn over and over and over and over again.
XG boost would work just fine, and Flipkart actually uses XG boost with 100- with 100 plus threes in their production environment to do this, to do this analysis, I right.
so here the idea is very simple: when your user, when your end customer, fires a query, that- hey, I am the user- typed in sh.
now the query or the request, the API request, would come to our Auto suggest service.
uh sorry, auto suggest service would first check: hey, is there a scope of personalization or not?
so if you cannot personalize the output to a particular user, you would want to serve it from the cache, because that would not change for anyone, because it is not personalized at all.
solar is a search engine through which they power this part.
so LTR is basically learning to rank, in which you can inject machine learning, more models on top of solar elasticsearch.
sorry, LTR ranking is what you can use, and then you would want to, you would have to provide your machine learning model to that.
so, which means that solar- uh, as in your search engine, because the query would be firewire, given this prefix- match all of them.
this would be firing on solar, because it's very efficient to do so right now.
how would your search engine rank it?
the way it would rank It Is by using a machine learning model.
but how to use a machine learning model with solar?
right, but now, first of all, with this solar, how would it get the machine learning model?
so that is where every search in, like solar elastic search, if I talk about they.
you can like, with LTR ranking model, you can provide a Json in an HTTP request.
so now XG boost model would be learning, let's say, every day, using your events and data platform to get that event, that which item was clicked, or which search is recommendation or sorry, which source suggestion was clicked, which was not clicked, and it would build the model.
so solar will then use this thing, like the Json that you provided- and this is not for every request you're providing- you'd just be ingesting this entire model solar bit, keep it with itself and it would use it for ranking.
now, how would solar get the search suggestions?
there would be gigantic big data pipelines around all the search queries that has fired on the system.
you would want to do that, that particular grammatical check, quality check, popularity check and then then you would want to ingest it into solar.
so Auto suggestion feature would have a cache, a solar, a big data pipeline, a machine learning model, training and explicit server to do that.
once the training is done, the Json, the model, would be exported, as in Json, inserted into solar so that it can use it for ranking, right?
and this is how Flipkart made their search suggestions hyper personalized, and that is it.