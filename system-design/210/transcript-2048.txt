so search is one of the most important Services, specially for food aggregators like zomato.
an interesting challenge comes when a search query is not homogeneous.
this query contains a restaurant, a dish and a location.
getting relevant information from your search engine, like, let's say, elasticsearch with this kind of query, is a very interesting problem to solve.
in this video, we dive deep into how zomato identifies the intent of the search query to better its search experience and make it more conversational using national language processing.
Engineers from companies like Google, Microsoft, GitHub, slack, Facebook, Tesla, Yelp, Flipkart, dream11 and many, many, many more have taken this course and have some wonderful things to say.
now, one of the main medium for people to discover food and dishes and restaurants is through the search bar.
now, zomato allows people to search for three typical entities.
second, a restaurant, like, for example, if I'm searching for Domino's Pizza, hot or any favorite chain of yours.
let's say: I know I want to eat Chinese today, so I'll search for Chinese, and it should list the restaurant that serves Chinese food, right, fine.
but given that the search bar is an open text box, people can pass in any query that they want, right.
so what they can do is they can basically combine multiple of such entities and pass inquiry like: hey, Pizza space, Dominos, which means I want pizza from Domino's restaurant.
by the way, this entire a piece of content is taken from zomato's engineering blog, which I've Linked In the description down below.
for example, title gets a weight of 10 while description gets a weight of one, so that when you're firing the query, if the query matches in the title, so if I'm passing in query, let's say dominoes, and if Dominos is present in the title, that document ranks higher as compared to when it is present in the description.
let's say, let's say someone fires a query, best coffee near me.
if this is a query that I bluntly fire on an elastic search, now what would happen now if I pass this?
I may configure that, hey, search for best coffee near me with title weightage of 10, description weightage of one.
now, but what when this query is fired on elasticsearch or a solar, with the configuration, what it would spit out is any restaurant that has best in their name, or coffee in their name or near in their name for some reason, or me in their name, would be ranked higher.
for example, best coffee cafe may be name of a particular Cafe, but that would be ranked first given that it matches the most of the word matches in the title.
I'm just basic making this up, but you understand the problem with this, right, given that best coffee near me is not about a restaurant, but about a food item- coffee- that you are looking for, and you are looking for restaurants that serve you best coffee, right?
this query content, this query contains all types of entities and we need to understand what are we actually looking for.
this is where natural language understanding comes in, and so that, given a query, we try to understand the intent of the user.
because voice search makes people speak like here.
now, when a human is speaking, when we are speaking or we are providing input to this search engine, we tend to be more verbose when we speak, when we type, we are lazy, we type fewer words.
then let's say, veg restaurant, koramangala- this is I'm looking for a category of restaurant which serves vegetarian food in location which is koramangala.
and third, maybe let's say chai and Samosa restaurant that serves chayan Samosa- both I would want rank them to to on the top.
right now, single intent queries are easy to answer.
but here, in this type of queries, when people are allowed to be verbos there, we need to understand the intent, right.
so, given a query, we need to understand what user is seeking.
it should automatically, like we have to write a service that understands the intent, which means from the search query, Domino's Outlet near me.
I need to understand that intent is to find the nearest outlet, an entity which is the restaurant.
it's zomato classifies search query into three categories.
the first is dish plus dish, in which, like, people are typing multiple dish name in the search query, like, for example, or uh, let's say pizza with cheese dip, right, dish plus dish is one type of query.
second type of queries: restaurant plus dish.
let's say MCD Burger, right, they that people are telling that I want a burger, but specifically from McDonald's.
third is, let's say, restaurant dish Plus near me, best at some irrelevant takes.
let's say: best pizza near me, right, so near me is an is an irrelevant text.
uh, what you're looking for is a pizza, uh, and you want best of that right now.
like, for example, if you would want to apply, uh, machine learning or, let's say, data science or NLP, nlu, something around it, you need label data.
for example, let's say, given that you are allowed to do voice search, you may pass in uh, right, that's a typical Hindi phrase, and which means you want Dal makhni with none together like.
but here, if you look carefully, the sentence or the query is not very verbose that you have to understand the entire language.
these are junk words, right, you can omit to them.
so somehow your intent identification needs to work such that you understand the context.
third, or another queries, let's say pizza.
a very clear indication which means, like you need very good pizza, a very clear indication that you are looking for pizza.
what to work is one of the most famous way through which- uh like it's a most famous way- to create word embeddings.
sorry, a number represent a word, but it's hard to just say a, let's say, Burger is one, pizza is two.
so, which is where what we are doing is what what to work basically does is it converts a word to a vector.
for example, let's say we are training this model on zomato's data set.
it means that we are providing it, restaurants, entire food menu and all the location names that you have.
you are training your word to work model on this data set.
so what it would do is, for every word in the vocabulary that it discovers, it would create a vector so you may pass in the size of the vector that you would want to Output.
so if you do vector algebra on King minus man plus woman, it would give you a vector which would be very close to Queen's Vector right, and it's a very common example that you will see almost at every single block about word to back.
now, this is the core rangia, that the way this neural network defines the weight, depending on the Corpus, is such that you can operate, you can perform any operations on this vector and it would be like performing operations on the word right.
you can use this along with a bunch of other algorithms to do, uh, identification of synonyms, because two vectors that are close to each other, their words might have very similar meaning.
this would be literal representation of words in an n-dimensional space such that it holds its semantics, it holds the meaning of it right, and this is the beauty of word to work, and in most cases you just do inputs, or you just do inputs I Pi, or let's say, import gen Sim and then train the word to work model to to drive it, but to know the internals of it.
you use it along with something else, right, okay, that is first word to it.
we saw how there are filler words when we pass in the search DK Burgers K does not hold any info or any any information there.
if let's say this is your uh string, you would want to tokenize it such that the basic way is the: let me.
it might be present as, like when speech to text is happening, the way it would come out.
let's say, I have a dish name called fried rice, with no space f-r-i-e-d-r-i-z-e, but every other restaurant, the Corpus, uses fried space rice.
right now, this is exactly how, where sub word tokenization comes in and what.
highly recommend you to check that out- and this is byte pair encoding, so they use these two to create or to train.
but as an output of this, when you train the entire neural network on all of this thing, it becomes very elegantly used to do named entity recognition or something called as a sequence tagging.
so, for example, if someone types in mixed veg, sub G or Roti, so you have to tokenize it and then identify what is a dish, what is a restaurant, what is a location, something around that right.
so, for example, mix with sub G, this three words together is a dish, is what we have to answer.
for example, if I am searching for Jack's Aloo Tiki Burger, so then Jax is the restaurant, Aloo Tiki Burger is a dish right.
so the keywords for you to explore- in case you are, you would want to rebuild this- is word to back: uh, byte pair encoding bi-directional lstm and CRF.
if you are familiar with python, you will find a bunch of examples where all of these things are put together and you just have to copy paste and run and train it on your data set.
right now, this is what would help us fire better queries on our search engine, which is what we were discussing at the first.
for example, if I am looking for Domino's Pizza, what I would do if I identify that Domino's is the name of the restaurant, I would search Dominos in the restore collection and Pizza in the food menu.
right, so that I get better search results.
similarly, if I'm searching for, let's say, Jax alotiki Burger- I know I want restaurant having named Jack and then Aloo Tiki Burger is the name of a dish- I can refine my search query so that elastics are just not spit out stupid answers.
right, because it's not its fault, but because we just cannot fire the query as is to the search engine and expect the best result out of it.
search fires a query through this model and identifies the intent.
so what we do is we train the model on restaurant food menu and location.
so search Service First fires an API which talks to the model given the search query, tells you the named entities out of it.
it uses that and creates us very specialized queries, depending on what it got out of this as an uh, from this model as an output, and fires a very relevant elastic search query looking for those corresponding things in those corresponding indexes.
right, and otherwise it would have given some random answer, like any restaurant having name Jacks might be on top and so it would be very hard to identify because query contained a lot of terms, a query contained a lot of entities that it was looking for.
like they make their search experience better by identifying query, and almost all companies operating at scale have this, have this intent identification, something trained on their own data set.
this is how zomato improves the search query, right, and all of this, all of this is taken from zomato's engineering block, which I've Linked In the description down below.