so search is one of the most important Services specially for food aggregators like zomato an interesting challenge comes when a search query is not homogeneous instead it contains multiple entities for example best Domino's Pizza near me this query contains a restaurant a dish and a location getting relevant information from your search engine like let's say elasticsearch with this kind of query is a very interesting problem to solve in this video we dive deep into how zomato identifies the intent of the search query to better its search experience and make it more conversational using national language processing but before we move forward I'd like to talk to you about a course on system design that I've been running for over a year and a half now the course is a code based course which means I won't be rambling a solution and it will not be a monologue at all instead a small focused group of 50 to 60 genus will be brainstorming the systems and designing it together this way we build a very solid system and learn from each other's experiences the course is enrolled by 800 plus Engineers spanning 12 codes and 12 countries Engineers from companies like Google Microsoft GitHub slack Facebook Tesla Yelp Flipkart dream11 and many many many more have taken this course and have some wonderful things to say the course is focused on Building Systems the way they are built in the real world we will be focusing heavily on building the right intuition so that you are ready to build any and every system out there we will be discussing the trade-offs of every single decision we make just like how you do in your team we cover topics ranging from real-time text communication for slack to designing our own toilet balance live text commentary to doing impressions counting at scale in all we would be covering roughly 28 systems and the detailed curriculum split week by week can be found in the course page linked in the description down below so if you are looking to learn system design from the first principles you will love this course I have two offerings for you the first one is the live cohort based course and the second one is the recorded offering the Live code base course happens once every two months and will go on for eight weeks while the recorded course contains the recordings from one of the past cohorts as is if you are in a hurry and want to learn and want to binge line system design I would recommend going you for the recorded one otherwise the Live code is where you can participate and discuss the systems and its design life with me and the entire cohort the decision is totally up to you the course details prerequisites testimonials can be found on the course page arpitbani dot me slash masterclass I repeat arpitbani dot me slash masterclass and I would highly recommend you to check that out I've also put the link of this course page in the description down below and I'm looking forward to see you in my next cohort so zomato is a restaurant aggregator which means it allows restaurant to list themselves on the platform while it also allows people to place order from their favorite restaurant now one of the main medium for people to discover food and dishes and restaurants is through the search bar now zomato allows people to search for three typical entities the first is a dish let's say pizza burger a paneer butter masala something around that second a restaurant like for example if I'm searching for Domino's Pizza hot or any favorite chain of yours a third is a Cuisine let's say I know I want to eat Chinese today so I'll search for Chinese and it should list the restaurant that serves Chinese food right fine but given that the search bar is an open text box people can pass in any query that they want right so what they can do is they can basically combine multiple of such entities and pass inquiry like hey Pizza space Dominos which means I want pizza from Domino's restaurant now solving for such an input is a very interesting problem now zomato might be using something like an elasticsearch or or a solar in the back end I don't know that extract but that's my speculation that they might be using something like this by the way this entire block is taken by the way this entire a piece of content is taken from zomato's engineering blog which I've Linked In the description down below I would highly recommend you to check that out right but because I don't know that extract it's my speculation that they might be using something around that uh to power their search engine now when you are configuring a search engine it's an elastic search or a solar what you typically have is you have indexes they might be having one index on a restaurant one indexes or one index on food and when you are searching within that the documents are retrieved now each document in a restaurant might contain a title a description menu detail something around that while on a food you might have the name of the food description or its ingredient and plus so on and so forth some information around that now now when you're searching when you fire a search query you would typically provide weights to this field for example title gets a weight of 10 while description gets a weight of one so that when you're firing the query if the query matches in the title so if I'm passing in query let's say dominoes and if Dominos is present in the title that document ranks higher as compared to when it is present in the description this is the most common configuration that almost all search engine in the world are configured now this is where interesting things come out let's say let's say someone fires a query best coffee near me if this is a query that I bluntly fire on an elastic search now what would happen now if I pass this I may configure that hey search for best coffee near me with title weightage of 10 description weightage of one now what would happen here best coffee near me is not telling you to find the restaurant with the name best coffee near me it's not telling you anything and this is a very generic query now but what when this query is fired on elasticsearch or a solar with the configuration what it would spit out is any restaurant that has best in their name or coffee in their name or near in their name for some reason or me in their name would be ranked higher for example best coffee cafe may be name of a particular Cafe but that would be ranked first given that it matches the most of the word matches in the title then best Bliss might be another restaurant bar best maybe another one like I'm just basic making this up but you understand the problem with this right given that best coffee near me is not about a restaurant but about a food item coffee that you are looking for and you are looking for restaurants that serve you best coffee right so this is where this is this type of query is not a homogeneous query this query content this query contains all types of entities and we need to understand what are we actually looking for this is where natural language understanding comes in and so that given a query we try to understand the intent of the user this is what makes this problem statement really interesting now here zomato also launched voice search now this is another interesting problem why because voice search makes people speak like here we are not typing we are we are saying what we would want to search and then basically speech to text kicks in and it basically converts it into text and then this is fired in the button now when a human is speaking when we are speaking or we are providing input to this search engine we tend to be more verbose when we speak when we type we are lazy we type fewer words so let's say if I am if if I would want to search for I'd say basically let's say garlic bread with cheese dip it's neither a restaurant it's their dish but there are two DISH garlic bread and cheese dip now where do I search this what do I search right this is where these are very weird kind of queries then let's say veg restaurant koramangala this is I'm looking for a category of restaurant which serves vegetarian food in location which is koramangala now if there is some restaurant whose name contains that would be ranked higher instead of location so here the problem starts to creep in and third maybe let's say chai and Samosa restaurant that serves chayan Samosa both I would want rank them to to on the top right now single intent queries are easy to answer where I am looking I am exactly know what I'm looking for and which is exactly a small piece of information small piece of query that I am providing which is going there searching for that information title description body whatever it is and giving me the search result that is the easiest one but here in this type of queries when people are allowed to be verbos there we need to understand the intent right so given a query we need to understand what user is seeking for example dominance Outlet near me it should automatically like we have to write a service that understands the intent which means from the search query Domino's Outlet near me I need to understand that intent is to find the nearest outlet an entity which is the restaurant is Dominos right so Domino's is a restaurant near me is the location intent is to find nearest outlet now here what zomato does it's zomato classifies search query into three categories right which is the most common pattern that that they have observed they classify search queries into three categories the first is dish plus dish in which like people are typing multiple dish name in the search query like for example or uh let's say pizza with cheese dip right dish plus dish is one type of query second type of queries restaurant plus dish let's say MCD Burger right they that people are telling that I want a burger but specifically from McDonald's third is let's say restaurant dish Plus near me best at some irrelevant takes let's say best pizza near me right so near me is an is an irrelevant text uh what you're looking for is a pizza uh and you want best of that right now it becomes really easy to understand query when you have narrowed down the scope so that is where intent identification comes in so now let us take a look at what are the challenges in this in in this particular system so when zomato was building this the first set of challenges that there is a lack of availability of label data like for example if you would want to apply uh machine learning or let's say data science or NLP nlu something around it you need label data we don't have labeled data so which means supervised approaches are kind of fuzzy over here like you may have to go for most most of the unsupervised approaches second is the queries that are being fired over here they involve more than one language for example let's say given that you are allowed to do voice search you may pass in uh right that's a typical Hindi phrase and which means you want Dal makhni with none together like so you need to support multiple languages but here if you look carefully the sentence or the query is not very verbose that you have to understand the entire language here there are still keywords that you want Dal makhni and you want none these are junk words right you can omit to them so somehow your intent identification needs to work such that you understand the context you I'm sorry you understand the core keywords which is Dish Restaurant more more importantly so Dish Restaurant Cuisine that is what you have to identify very well everything is junk you may just ignore if it is very diluted right third or another queries let's say pizza a very clear indication which means like you need very good pizza a very clear indication that you are looking for pizza and substitution is something which is very nice you may ignore it or you may make it more smarter to understand the language and convert it but no but not really needed because you get an idea that you know you need pizza that is what your intent identification needs to do third is phrase that mean the same for example MCD burger mcdike burger both mean the exact same thing that you are looking for burger from McDonald's so here you may go for a language agnostic conjunction but you cannot possibly fill in all possible languages India has like like like basically 30 to 35 different languages in which people interact with the app you cannot possibly feed in all possible data which means you have to somehow go via the opposite route and find what's imported or spot what's important and leave everything else around right food is spelling variation now for example rajma rice rajma chawal both mean the exact same thing because rice and chavel are synonyms so you need to handle synonyms as well rumali Roti rumali Roti r u m a l i r double o m a l i they are phonetically similar now this also needs to be handled now how do we solve all of these complicated situations in a simple way this is where what zomato did is they leveraged what to wake byte parent coding bi-directional lstm and CRF will not go into the machine learning side of it but still would still cover it from the surface level so that it becomes easier for you to understand in case you would want to dive deeper into this part right I'll just walk you through on few critical parts that I think are important for you to know first let's go through what to make now what is what work what to work is one of the most famous way through which uh like it's a most famous way to create word embeddings now I'll just walk you through on what word embedding is so what to make in general is a neural network model to learn word associations now here what it does is it is a very beautiful thing so machine understands numbers right so your computer understands number one zeros almost all binary right but it does not understand words so you have to somehow make a word re be like a word sorry a number represent a word but it's hard to just say a let's say Burger is one pizza is two that might be one but that might not be very useful so which is where what we are doing is what what to work basically does is it converts a word to a vector vector is simply a list of numbers so it converts word to a vector such that that Vector almost very accurately represents that word now how is this model coming up with this Vector this is coming up with this Vector depending on the Corpus that we are training the model on for example let's say we are training this model on zomato's data set it means that we are providing it restaurants entire food menu and all the location names that you have you are training your word to you are you are training your word to work model on this data set so what it would do is for every word in the vocabulary that it discovers it would create a vector so you may pass in the size of the vector that you would want to Output let's say typically it's 128 or 256 something but you may obviously pass it as a parameter and when you get this Vector now this set of numbers would vary accurately represent this word such that now this is where the fun part is such that the vector are very closely associated to the word for example a very famous example of word to back wherever you see any word to wake video or read any blog on word to make this is the most common example that you will see it converts the word to a vector such that if you operate some functions if you apply some operations on the vector The View may discover another word which is related I'll give an example let's say if you are training it on a normal English Corpus and if it's a decent Corpus and you fire a query let's say King has a vector man has a vector woman has a vector and queen has a vector so if you do vector algebra on King minus man plus woman it would give you a vector which would be very close to Queen's Vector right and it's a very common example that you will see almost at every single block about word to back now this is the core rangia that the way this neural network defines the weight depending on the Corpus is such that you can operate you can perform any operations on this vector and it would be like performing operations on the word right and now this is what makes it special because now you can use this to you can use this along with a bunch of other algorithms to do uh identification of synonyms because two vectors that are close to each other their words might have very similar meaning for example man and boy would be more closer to boy and girl right king and queen would be opposed like would be far away from each other like this would be literal representation of words in an n-dimensional space such that it holds its semantics it holds the meaning of it right and this is the beauty of word to work and in most cases you just do inputs or you just do inputs I Pi or let's say import gen Sim and then train the word to work model to to drive it but to know the internals of it it's not so difficult to understand but I would highly recommend you to go through it try try it out yourself and learn about whatever it's a very fascinating thing but you typically don't use it standalone you use it along with something else right okay that is first word to it now when you when we were talking about the problems the the overall challenges that came with this one of the challenges were multilingual queries we saw how there are filler words when we pass in the search DK Burgers K does not hold any info or any any information there so you need to have a language agnostic way to tokenize those strings such that you keep what matters while discard everything else so now this is where you would want a way so let me start from beginning there is the most common way to tokenize a text now what is tokenization let's say you have a text uh let's say it is called as none if let's say this is your uh string you would want to tokenize it such that the basic way is the let me wherever I find a space I would split it so Dal becomes one makhni becomes another K becomes another sat becomes another and none becomes another that is one way to look at it but is this the best way there is a very high chance that you what you are looking for might not be present as an independent word it might be present as like when speech to text is happening the way it would come out you don't know how uh the library that you are using for speech to text converts it to text so that is where what you need is you need a sub word tokenization let's say I have a dish name called fried rice with no space f-r-i-e-d-r-i-z-e but every other restaurant the Corpus uses fried space rice so you would you want to consider fried rice as one token or fried rice as two token right now this is exactly how where sub word tokenization comes in and what the algorithm that they use to create this vocabulary is called byte pair encoding for tokenization it's called basic bpe in short form it's a very simple but very beautiful very elegant implementation I would again very simple one I have linked a couple of resources for you to understand byte pair encoding in the in the description down below highly recommend you to check that out you would see how beautiful this algorithm is it is a supervised way to do it which means that it helps you define a tokenization scheme depending on the Corpus that you provided it's not a generic way that a splited space or splitted quotes or split at a special character it splits within the word itself like it it can also split within the word if that word is present in the Corpus so it operates on the frequency and it tries to reduce that it's very simple very fascinating algorithm that it powers like brilliant implementation I've linked a couple of uh videos and blogs that you can find it helpful it's in the description down below highly recommend you to check that out and this is byte pair encoding so they use these two to create or to train word to wake word to work outputs you this word embedding these vectors are called word embeddings these word embeddings are then used by a bi-directional lstm it's a neural network thing a long short term memory I won't go into the details of it plus CRF I won't go details into it either but just knowing that how to use it is good enough for you to get started otherwise this video would become an hour long video right but as an output of this when you train the entire neural network on all of this thing it becomes very elegantly used to do named entity recognition or something called as a sequence tagging both are similar so what sequence tagging does is what is it is exactly what we have to do so for example if someone types in mixed veg sub G or Roti so you have to tokenize it and then identify what is a dish what is a restaurant what is a location something around that right so for example mix with sub G this three words together is a dish is what we have to answer right this is what bi-directional lstm would do because you are training it to identify Dish Dish merge it into a dish right and then Roti is also a dish for example if I am searching for Jack's Aloo Tiki Burger so then Jax is the restaurant Aloo Tiki Burger is a dish right this is sequence tagging this is named entity recognition so the keywords for you to explore in case you are you would want to rebuild this is word to back uh byte pair encoding bi-directional lstm and CRF right CRF it's okay to not die beep into a bit of pie but in most cases if you are using if you are familiar with python you will find a bunch of examples where all of these things are put together and you just have to copy paste and run and train it on your data set uh Kegel has a bunch of data set on this thing you can feel free to train on that and experiment it's a very fascinating thing right so now assume that out of all of this what you've got is you got a way to tag a way to identify sequence of words as entities for example mixed with subj is a dish Roti is a dish Jax is a restaurant is a dish right now this is what would help us fire better queries on our search engine which is what we were discussing at the first now the overall architecture looks something like this of their search so user is interacting with the search service now search service so user passes what a search query to the search service now search service earlier used to simplify a search query and elasticsearch to get the response and send it back but we saw the problem the problem was the query was the query content multiple intent you had to identify what each entity means in the query so that you can retune your query for example if I am looking for Domino's Pizza what I would do if I identify that Domino's is the name of the restaurant I would search Dominos in the restore collection and Pizza in the food menu right so that I get better search results similarly if I'm searching for let's say Jax alotiki Burger I know I want restaurant having named Jack and then Aloo Tiki Burger is the name of a dish I can refine my search query so that elastics are just not spit out stupid answers right because it's not its fault but because we just cannot fire the query as is to the search engine and expect the best result out of it so here we just take a small detour and instead of search directly firing the query to the search engine what search does it search fires a query through this model and identifies the intent so what we do is we train the model on restaurant food menu and location this model is trained hosted on a Gateway you may use ec2 instance flash server to host it nameix Gateway I'm just using a generic name over here so search Service First fires an API which talks to the model given the search query tells you the named entities out of it it uses that and creates us very specialized queries depending on what it got out of this as an uh from this model as an output and fires a very relevant elastic search query looking for those corresponding things in those corresponding indexes and this way without changing much over here leveraging NLP over here you are trying to find or you are improving the relevance of the system this way now if you type Jax alutiki Burger in zomato you see Jack's restaurant top with Aloo Tiki Burger highlighted because it identified it really well right and otherwise it would have given some random answer like any restaurant having name Jacks might be on top and so it would be very hard to identify because query contained a lot of terms a query contained a lot of entities that it was looking for right and this is how zomato improves their experience like they make their search experience better by identifying query and almost all companies operating at scale have this have this intent identification something trained on their own data set they have this intent identification service and some of the other were built in very similar way right and yeah that is it this is how zomato improves the search query right and all of this all of this is taken from zomato's engineering block which I've Linked In the description down below highly recommend you to check that out so yeah that is it that is it for this one I will see you on the next one thanks [Music] thank you [Music]