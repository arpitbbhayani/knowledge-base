the best garbage collector is a myth. if you are trying to build your own garbage collector or trying to pick a garbage character for your specific use case, there are seven parameters that would objectively help you decide which one to go for. these parameters define a garbage collector and it determines its performance on your specific workload. in the previous video, we talked about why programming languages need an automatic garbage collection- primarily because engineers are unreliable- and in this one, we talk about the seven key metrics and characteristics of a garbage collector that can help us compare and judge which one is better than the other for a specific workload. this is not theoretical, but something that all senior engineers spend their time to get the best performance out of their systems. but before we move forward, i want to talk to you about a code based course, or system design, that i have been running since march 2021, and if you're looking to learn system design from the first principles, this course is for you. yeah, because this is a cohort based course. it will not just be me rambling a semi-optimized solution, thinking it's the most amazing solution out there. instead, it will be a collaborative environment where every single person who is part of the cohort will can pitch in his or her ideas and we will evolve our system around that right. every single problem statement comes with a brainstorming session where we all together brainstorm and evolve our system. that's why everyone understands the kind of trade-offs we made while making that decision. instead of just saying, hey, we'll use a particular queue, we'll have the justification why we use only that queue, why we use that particular database, why is equal, why not no sql? right? how are we leveraging throughput? how are we ensuring that our system scales? that's the highlight of this course. this course is taken by more than 500 engineers to date, spanning nine countries and seven cohorts. right, people from all top companies have taken this course and the outline is very intriguing. it's very exciting. so we start with week one around. we start with the core foundation of the course where we design online offline indicator. then we try to design our own medium. then we go into database, where we go in depth of database locking and take and see few very amazing examples of data log, database logging in in action and how do we ensure that our system scales through that? then the third week is all about going distributed, where we design our load balancer. i'll walk you through the actual code of a toilet balancer and understand how pcb connections are managed and how simple it is to build load balancer. then week four is about all about social networks. week five is all about building your own storage indents, like we'll build that intuition on. if you were to ever design your storage agent, how would you do that right? then week six is about building high throughput system. seven is about building uh ir systems, basically information retrieval systems and add-on designs where we design our own message brokers like sqs, where we design distributed task scheduler. and we conclude the course with week 8, where we talk about the super clever algorithms that has powered or that has made those systems possible. right, i have also attached a video, verbatim, as is from my first quote, where we designed and scaled instagram notifications. i will highly encourage you to check this video out. right and now back to the video. so the seven key metrics of a garbage collector are posting, safety, language, specific optimizations, completeness, throughput, space over it and scalability. there will not be one gc that is doing great at all of them. there would be some gcs who are great at throughput, great at pause time, great, uh, great- at safety, but they would be suffering from scalability, they would be very hap, they would have very high space overhead and they might not do a lot of language specific optimization, right. so when you like, when you're doing this comparative analysis between gc, try to plot this two dimensional web plot across all of the gcs on all the parameters that you can think of and see which one fits your needs. right, and you should be picking a gc that fits your needs, fits your workload, in order to get the best performance out of it right. again, best garbage collector is a myth, right, there is always one which is better than other in some particular use case. and if that particular characteristic or that particular use case is something you need, you have to go for that particular gc. and obviously, when something is good at something, it is also bad at a few. so you like, you get the best, but you also have to suffer the worst for those extra parameters. so there was a study done in early in 2000s around garbage collectors and what folks found out? that each one, each one of the garbage collector is superior than the others in at least one use case by 15 percent. this clearly indicates that, hey, there is no one calculator that is best across all, but every garbage collector will be better than all other in at least one use case. at least one use case by 15 percent. so, which means that if that is that one use case that you that you direly need, you would have to go for that garbage collector right and most garbage colors now to get the performance. how do you get performance out of your garbage collector? most garbage collectors, they give you a lot of knobs. when you see, knobs like these are all sort of tunable parameters which would help you tune the performance of your garbage collector for the load that you are handling. some examples like these are java specific examples, but any language you pick, every language or every garbage collector that you pick in every language. there are a lot of parameters that you can tune. go through the documentation to understand it. just a few things that i would want to point out is like: xx. uh, use serial gc, use parallel gc, max gc pause melees like this would define what's the maximum time your gc should be pausing. gc time ratio mean heap free ratio and all. so there are. there are 50 more parameters that you can tune depending on the gc that you have chosen. but it's when you are picking a gc, when you're tuning the gc to the best performance, you need to know: hey, these are all the parameters that i can do, this is my workload- run the test and see how it is, how it is behaving and, to be really honest, after a certain scale, you, after a certain scale and after a certain stage of your career, you will be spending more time tuning these parameters than coding. true story, and it average and it always happens to get that best performance out of it. because after a certain time the gc pauses will hurt. you will hurt the performance of your system and which is where you would be spending a lot of time tuning the performance out of your system to get that extra ounce of to, to get that extra ounce of throughput. right now, what we'll do is we'll go through the seven characteristics and understand each one of them and the kind of impact it has. first one: safety. what safety says is that a collector must never reclaim the storage of live objects. basically, it simply means that if what like, it should not be deleting an object which is already in use. so if i have two object pointers, object one and object two, and they both point to the same same object in memory. right and now, if this object is deleted, these two pointers become dangling pointers. so what we want is we want zero dangling pointers, right? so if two objects are referring to a particular place in memory, which means it's live, so your automatic garbage collection cannot delete this or cannot reclaim this space, right? so this is something that garbage collector should be doing. so this says that garbage collector. you say that the garbage caller is safe when it does not delete an object which is life, but, like i said, that on safety it might rank low or in safety it might rank high. what does this mean? this means that not all garbage collectors are 100 safe. there might be, like there are some garbage collectors to get to do better on other parameters. it might also reclaim the space which is always in use, not that frequently, but it can do right. so safety, if that is one of your most important criteria, you have to go for it, like it or it obviously has its own repercussions. but yeah, you have to bet, but you have to bear the load. the second one is throughput. obviously, everyone wants key. my time to spend on carpet collection should be as low as possible. like, like no one's like. no one wants to say my garbage collection can go for ours. obviously it does not, but no one says that. so everyone wants our program and garbage collection to execute in as little of a time as possible. ah, that's a very, very shrewd requirement, right? so what happens is you're like if i would want to plot a very simple box, plot on if this is the hundred percent of your time, how much time goes into program execution, how much time goes into garbage collection. you get a very nice, cute like 99 is to one or 90s to 10 ratio. 97 is massive, but 99 is 21 ratio, right? so during that one percent of the time, hypothetically, your gc is running. when your gc is running, like in most cases, it would be the stop the world gc, which means that when gc is running, your program cannot execute. so now, if your gc is slower, then your gc is taking longer time to execute, then your program is getting lesser time to execute, which affects the throughput of your business logic. for example, if you are running a payment service having a lot of transactions and if your gc kicks in, program execution is affected. your payment service is affected, right? so you don't want your gc time to be very high. you, because it would hog into your program execution time. you want to give the best performance to a user but you still want to run gc. so that's a kind of a dilemma. so what gc typically does is: gc does like most dc's. they have short bursts of like, they have short cycles, or sorry, they have cycles of short garbage collection and then a long one, right? so this short one, what gcs do is to ensure that your program gets enough cycles to execute. your program is is having a lot of throughput, or the main business logic is having a lot of cpu cycles to execute. your gc would try to run a quick garbage collection in a very short time, right? this would ensure that your program throughput is not affected. but then, once a while, gc would run an expensive defragmentation that would go for a longer time and then it would do it to. you know, because of all the shorting that it ran, it was not able to fully clean up the stuff. so that is where this long one comes in and it does this, this, this massive defragmentation or compaction, whatever it want to call, and it does it once a while. so you would always see short burst of gcs and then a long pause. a short burst of gcs, then a long pass, and that is how most diseases would operate: just to improve or just to make your overall throughput of your program, of your business logic, as high as possible. the third one is completeness. so completeness implies that, hey, all the garbage that is there in my heap should be reclaimed. the key word here is eventually right. so it implies that there should not be any object left in the memory that is a garbage, which is. no one is pointing to that object, but it is still lying there. a a repercussion or a side effect of this would be memory leaks. if you are not deleting all the objects that are not referenced ever in your system, then what it would lead to is it would lead to memory leak, because now, slowly and steadily, all of these objects are just lying there on your memory, never cleaned up. so it would increase your memory usage and slowly, and this is a classical case of memory leak. so which is where what completeness says? that, hey, a garbage collector is complete, where you want to eventually delete all the garbage that is there, or you would want to collect all the garbage that is there in the heap, right, so eventually. so it might again that one, instead of doing it in one cycle, you can do it eventually, but it has to be complete, right. so it may not happen in the first cycle, second cycle, fourth cycle, but maybe in the 10th cycle. that objects gets reclaimed, right, but that needs to happen. there should not be any object that is deleted or that is not reference, but it's still lying there, right, so eventually it needs to be cleaned up. the fourth one is pause time. this is the most important, most important parameter out there, most important characteristic out there. pause time is most, or more often than not, when a garbage collector runs it pauses the program execution. so this is called as stop the world gc. so this top double dc is when my gc is kicking in. it has to do a lot of computation, it has to do a lot of object movement here and there, so it would require your program execution to stop. so these, the threads that do that execution, are called mutator threads. these threads are stopped and only garbage collection threads run right, and when this happens, your business throughput or your program throughput is zero, which is why it's called stop the world. and this metric is one of the worst like: basically, this is high, it is directly impacting the throughput of your business logic and everything would go for a toss right. so that is where this is something that every senior engineer dreads: oh my god, we are having a stop. the world gc, like elastics, are big. any infra component, pick any, like specifically java service- you would see this more often- that there are so many stop-loss going high, your program execution stopped, your transaction needs to be restarted and so many things. so which is where? and it's like: why, why? why do we need stop double dc? why, why like? why such exclusivity to gc? it's not that just because gc needs to run fast, you are giving full cpu to it. the main reason is, once a while your gc would do defragmentation. it means that, let's say, i have this as my memory layout: these are all the objects that are allocated. the red ones are the one which are deleted, right? so once these objects are deleted, what needs to happen is that if i just delete these objects, the other objects would be lying there in memory, but they are not compacted, which means that if someone wants a very large object, it might not be able to fit in this available memory because memory allocation needs to be contagious. sorry, it needs to be continuous, right, memory allocation needs to be continuous. so if it needs to be continuous and if it does not have that big of a memory chuck, that big of a continuous memory chunk available, then it will not be able to allocate object right, which is where, once a while, your garbage collection does a defragmentation or a compaction in which, once these objects are deleted, it would reshuffle the objects such that it would leave a large chunk of continuous memory available for allocation. now, when the objects move here, object 1 and object 2 moved from this location to this location. basically these, these three objects were deleted. so these object wanted objects to moved over here so that all of the objects are closely packed and when this happens, you get a very nice large free chunk of space available over here. so now what happens is when this object movement is happening right, when these objects are being shuffled, the your program execute, because when objects are being shuffled, it's the actual memory address being changed from one to other, and when that happens, what your program like- if at the same time your program is also executing- what would happen is your program will point to some other location which does not exist, and all of those complications would kick in. that is where your gc says: hey, let's stop the world. let me quickly move all the objects, let me quickly do the defragmentation so that your your the way the objects are reference in the memory. they still are correct, right. so maintain the correctness of the references that your objects point to. it needs to stop the world. and once the object movement is done, then the program execution resumes. and this is what causes the stop the world, or it basically causes the pause type of gc, right? so what garbage collector does is it tries to, it tries its best to reduce the cost time to as low as possible. but when it tries to reduce the pause time now it has its own set of challenges because you know the side effect of this is you might not have a large chunk of continuous memory available, your gc might not be complete, and all that is where it's just a combination of short cycles and long pauses that happen. so once a while you'll have a long pause, otherwise you'll have a short burst of cycles. then you would run compaction once a while and you would not be completely eventually complete. so many things are affected by this right. but you would always try to optimize your workload like such that your program does not impact very high. so you'll tune a lot of parameters to ensure that your gc pauses are at minimum. the fifth point is space overhead. gc is obviously, when it needs to identify which objects to delete, which objects do not, it has to maintain a lot of auxiliary data structures to track which objects are being referenced, how are being referenced, which one to delete, why to delete, when to delete. so your gc itself has a space overhead right. so when it has a massive space overhead it would need memory for its allocation, and so it would put an extra pressure or extra load or extra consumption of your memory. so a good gc to like, again, space-time trade-off. if you have a large amount of space available to allocate, or if you're using a sophisticated data structure, you would find which objects to delete in a very short time. but if you have a very poor data structure you will take a long time to do it. but that poor data structure might be efficient on space. so that is where, again, a trade-off to make. hey, which like? which auxiliary data structures is my gc using to perform that need. so what is the overall space overhead of my garbage collector? and to do that again, there is no way but for you to test it on your dev environment, on your local environment, and see how much of a space overhead of the gc is there so that, if it fits your needs, go for it. otherwise, rethink your decision and go for another. like if you have a very memory intensive application where you cannot, where you have very strong constraint on memory, you cannot bear that extra space cost. you can bear on time, but you cannot bear on something. so some some weird use case, right? so then you would want to go for a gc that is lowered space over it, right? like few examples of garb, a few examples of data structures, that gc is used like bit tables- sorry, bitmap tables, so bitcoin tables. they would use to check which object is already picked for cleanup, which object is not, which, which object is moved to other generation and what not. something will look into future videos and then graphs to maintain, hey, this object depends on this object, this depends on this object. so if i clean this object, i would have to clean the other two and whatnot? right? so extra data structures. gcs need those data structures to be able to find out whom to delete, why to delete, quickly, able to find out and all of that. so space over it again a critical metric to consider. the sixth one is language specific optimizations. so every language is different, every language has a different set of features. so can a general gc algorithm take leverage or can leverage, uh, the language out there? no, like, if you go for a very basic gc algorithm- it is language agnostic, works across all languages- then it might not be best for a particular language because, let's say, there are some languages which are pure functional. there are some languages that only have heap allocation and does not allocate on stack. there are some objects that may have explicit di location, like where you have to call malloc and free and all. there are some languages that have only persistent data structures. now, which means that if you know, or if your garbage collector knows, that this is the language on which it is running, so it can run that extra optimizations where it can exploit the features of the language, where each of the languages, in how objects are allocated in memory, how are they mapped into memory, or what kind of access pattern do objects we have like if, if a language only has persistent data structures, then every time you make any modification it will create a new copy of the data. so you can very easily run a quick deletion of the past references of the objects which are not in use. then a way through which you know that if a particular languages store the allocated objects in a particular order in memory, you can leverage that. for example, there is there are a few gcs that run in constant time because of how objects are laid out in the memory manager. so the runtime of a memory: whenever the object is allocated, it's stored in a. they are allocated in a particular way in the memory of the language and if you know that this is how the objects will always be allocated, you can quickly find out okay how to do my gc in constant time, because that's the way the objects are allocated in the memory and depending on other ways of allocation, other ways how objects are created, objects are deleted, objects are referenced, you can make a lot of optimizations on a garbage collector. so which is where you will always find most garbage collectors out there? they are language specific garbage collectors because they exploit how that language is built. they exploit how that language does object allocation and other part of it. then the final point around this is scalability. the garbage collectors were being built from like last 20, 30, 30, 35 years. the first set of garbage collectors are still around. the garbage collectors that were built back then were built for few mbs of ram. now we have few hundred gbs of ram like, which is an insane amount of scale. so here, even with garbage collector, scalability is extremely important, because a gc or a garbage collector written 30 years back might not be performant enough, like might be good for few mbs of cleanup, but not for a few hundred gbs of cleanup, right. so gc needs to leverage the modern hardware capabilities, like modern hardwares are parallel. if a gc is not leveraging multiple cores, then then not a good choice there, right? so it needs to leverage the hardware better to get the best performance out of it, and that is where a gc needs to evolve. a classic example of that is because servers are growing. the ram of a server was initially few mbs, now at this few hundred gbs, if not terabyte. obviously terabyte slams are there, but still few hundreds of gbs at least, and hence when a gc would kick in, cleaning up few mps is very small task: clearing a few hundred gbs- your gc would be running for a very long duration. now let's say, if your gc was a stop the world gc, like every time it runs it stops the world. so going through that few hundred gb of heap every time, and if it is every time stopping the world, then your program execution is suffering so much, which is where your gc needs to know, or it needs to evolve itself such that if, even if the memory is high, it is still not doing, it is not always stopping the world for its garbage collection, and it is to do the memory management in the most efficient way possible, because there is a massive space to iterate and go through. like, just iterating few gbs of ram, of memory itself takes a long time to do so. right so, which is where your gc can be very like, an old dc might be very inefficient for the moon, for, basically, for the modern workload, which is something that you have to always keep in mind. right so, there are now to handle large amount of servers and to handle this large load, but there are some gc's, uh, that are pause free, because when they operate on few hundred gb of ram they cannot do always stop the world. so there are. so some gc's have evolved and new features have been added to it, which are pause free, which would never lead to any positive, but obviously it has impact on other part of it, because obviously you cannot get best of all the worlds, but again, evolution is extremely important. so, picking a gc, like if you are, if your workload is very heavy on ram and your servers are always in few hundred gbs, if not terabytes, then you would have to go for a gc that is pause free, which other r is very efficient in leveraging the hardware. again, going to the gc documentation might give you that answer, right? so, yeah, these are seven gc characteristics that are there that would help you pick the next best dc for your next use case right in the. in the coming videos we will all now will start going into the different gc algorithms and we'll start doing deep dive into one of, into each one of them, into understanding how they operate. what are the key, uh, key decisions that those algorithms made to get the performance out of it, like, and and how do they function? right? so, theory part. then i will start going to the algorithmic part of it. but, uh, these seven key characteristics, extremely important for you to know when you are picking your next gck. hey, what's the scalability, what's the pause time? and most people only think about pause time, but the other six are equally important. right, that's exactly where i wanted to create this video for you folks. nice, amazing. that's all for this one. uh, thanks again for watching the video. if you guys like this video, give this video a thumbs up. if you guys like the channel, give this channel a sub and i'll see you in the next one. thanks.