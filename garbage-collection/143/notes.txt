Why Caching cannot improve Mark and Sweep?

GC ? Why caching cannot improve Mark and sweep Mark and Sweep Garbage Collection Mark : start from root nodes and continue to mark the reachable objects whatever 's left is dead /garbage sweep : iterate to all objets in the heap and clean what's garbage collection needs to be extremely fast garbage we do not want the CPU cycles to be used to collect garbage . would it to be constructively used in we want running user program that Mark and given sweep is a simple DFS - - , how improve its ? can we performance smaller GC pauses - more Cpu cycles for - user program The first optimization technique we could think is of ? it work caching can

what is a cache ? Cpu core Ll that stores data that cache is anything . So ans the future requests are served faster . 1215ns) " The data be " me cache can 13 Cache 110ns) result from the previous computation - Main Memory 150ns) - copy of the data from a slower storage ? where cache improves performance Cache can improve performance when - temporal locality the application exhibits spatial locality - Temporal locality A recently accessed memory location to be accessed again is more likely . Spatial locality 4- a location is recently accessed , the locations adjacent to it will be accessed soon

Hardware / Cache Prefetching To leverage temporal and spatial locality , hardware can pre - fetch to be accessed into the cache some data likely and thus boosting the overall performance of the system . Main cache memory 50ns 1ns Data done in two pref etching is ways hardware Intel / AMD does this by analyzing the I. intelligent access - ' ' 2. explicit prefetch instruction - your program can request the hardware to cache underlying so , can we leverage caching to speedup The answer is No ? the Garbage collection process

Why garbage collector cannot leverage caching to improve performance ? To leverage caching , the use - case should exploit temporal locality or spatial locality Temporal locality of a Mark and - - Sweep GC is poor " bit its " An object is accessed once and the mark in is marked _ : 1 header is read and set . type : student name : - The object is never accessed again age : - school : < ref ? So , caching won't help . Spatial locality of a mark - and - Sueeep GC is poor " " Mark and sweep DFS the objects go through - - uses to INE which be means you will not accessing physically adjacent objects student Physically adjacent data is school not accessed immediately . Main memory

Minor speed up is possible though the static love we can cache cardinality objects referenced eg : a language supports multiple types and for it to understand the type of an object it would stare into about it Caehich could be another object ) and name : student ← Very common > hence be cached functions : = can type : id : 1729 name : Arpit name : COEP 31 age : > Pune School : city : this the type objects * is a very crude example , in reality like cached Integer String. , Float , list . set are . Type objects tell the runtime engine what is the type of the object .