GitHub Outage: On switching a Master Database

Dissecting GitHub Outage Master database Outage during switching maintenance !! GitHub had an outage . . - during planned What happened ? ↓ Users observed delays in data being → API visible the on interface or API writes ! 1. Read after it is being written on the database F -1 IT Master Replica Reads to Replicas go u writes go to Master Async Replication Given that I. data was written successfully for reads Et but was not available = Ll ↳ Place we stare is different from the Master Replica ✓ Place we read from A- SYNC Replication This is done through a Master Replica setup handle and is a popular way to large read load euithout affecting the write load .

What happens in planned maintenance ? During a planned database maintenance , we switch the database ↳ apply security patches By ↳ ↳ version upgrades parameter tuning ↳ hardware replacement ↳ periodic reboots we switch the primary database from one machine to another so , we keep another instance handy and with a config change wee route all traffic to new DB . Unavailable Hence , for a short duration the system might become . happened to So , what GitHub ? During planned maintenance , they switched muumuu ! the master and the mysqld process crashed the master On newly promoted server

How to ? mitigate The old database there Tyµgw server was . so , because the new server crashed we quickly route ✗ traffic to old server back so , this should the problem . . . . . wait . . . . Switching back to old server would definitely keep the system as it can continue to process writes but running . . . . . , served the WRITE For GitHub , the crashed MySQL server , traffic for 6 seconds ! ! Some writes went to old new new database and we switched back . ?? . so , we hat would happen > Writes me in ↓ old new CRASH ¥ × Failover

Now , the current state of old new GitHub is - new writes going to old . some data only on Writes - > me in the new database ↓ ~ old new Old CRASH × - old data intact Failover HOW do we remediate ? switch the database Anytime we , should note the BIN 104 ordinates we always co - does this ↑ * Every company Using 13114104 cue apply the changes that happened in new DB > Ñ after first failover on the old DB } new

So how reads ? , got affected > Replica when we failover databases , specifically create set during outages . we a new > Replica start and of replicas for a fresh - clean consistency Because dataset took 4 hours is HUKEEE ! ! creating replicas ~ and cluster took hour manually configuring 1 ~