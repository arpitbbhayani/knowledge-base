so micro services need to communicate with each other. the communication is always about getting or updating a data that is owned by the other service. whatever service gets access to all the data it ever wants. this is the simplest way for the micro services to communicate with each other, and the pattern is called sharing the database pattern. the core idea here is to let anyone who needs the data from a service or wants to operate something into the service can directly talk to his database, rather than going through a middleman api server, although most people think it is the wrong way of communication, instead of discarding it completely. in this video, we talk about how microservices can communicate using a shared database, the four challenges associated with it, see ways to mitigate them and understand where it could be actually beneficial for us to share the database rather than going through a middleman api server. but before we move forward, i'd want to talk to you about a code based course, or system design, that i have been running since march 2021. right, if we're looking to learn system design from the first principles, this course is for you. yeah, because this is a cohort based course. it will not just be me rambling a semi-optimized solution, thinking it's the most amazing solution out there. instead, it will be a collaborative environment where every single person who is part of the cohort will can pitch in his or her ideas and we will evolve our system around that right. every single problem statement comes with a brainstorming session where we all together brainstorm and evolve our system. that's where everyone understands the kind of trade-offs we made while making that decision, instead of just saying, hey, we'll use a particular queue, we'll have the justification why we use only that queue, why we use that particular database- y sql, why not no nosql? right, how are we leveraging throughput? how are we ensuring that our system skills? that's the highlight of this course. this course is taken by more than 500 engineers to date, spanning nine countries and seven cohorts. right, people from all top companies have taken this course and the outline is very intriguing. it's very exciting. so we start with week one around. we start with the core foundation of the course, where we design online offline indicator. then we try to design our own medium. then we go into database, where we go in depth of database logging and take and see few very amazing examples of data log or database logging in in action. and how do we ensure that our system scales through that. then the third week is all about going distributed, where we design our load balancer- i'll have oculus, the actual code of a toy load balancer- and understand how pcb connections are managed and how simple it is to build load balancer. then week four is about all about social networks. week five is all about building your own storage indents, like we'll build that intuition on. if you were to ever design your storage agent, how would you do that right? then week 6 is about building high throughput system. 7 is about building uh ir systems, basically information retrieval systems- and adobe designs where we design our own message brokers like sqs. where we design distributed tasks scheduler. and we conclude the course with week 8, where we talk about the super clever algorithms that has powered or that has made those systems possible. right, i have also attached a video, verbatim as is from my first quote, where we designed and scaled instagram notifications. i will highly encourage you to check this video out. right, and now back to the video. so say, we are building a multi-user blogging application in which we have the blog service and the analytics service. block service owns the block db, in which all the information about all the blocks ever published on the platform exist. analytic service is the one that understands likes views happening on the block and it wants to update it in the database. now there are two ways to do it: analytic service can talk to the block service and block service can update its database. second approach is that analytics service has the access to the blocksdb and it can directly update the database. the second approach that i just mentioned is the one that talks about the sharing the database pattern, where the database, which is the blocksdb, is shared between the block service and the analytics service. this is the simplest way to integrate microservices, to have microservices coordinate and communicate between them right, and is one of the most common approaches used across the industry. right, there are a few very solid advantages of using this pattern. first of all, it's the simplest way of integration. no complex things required, like directly two services talking to a database and you are done right. no middleman involved. so now there is no need for an analytic service to talk to block service and block service updating the database. if you have this middleman, it not only improves your, it not only affects your development time, but integration practices. http, grpc, so many complications and all what if one team understand grpc, other team doesn't, then that team needs to upgrade themselves to understand grpc and all of those complications happen. there is no latency overhead, like because there is no extra network. hop, your analytic service, as soon as it got data, can directly update it in the database. so no latency overhead, right. quick development times now. because analytics can directly write to the database, like they are working independently. they know the data, they know the schema. they would directly update the database. so there is no cross-team effort required over here. analytic service can choose to like quickly develop things and put things into production, like update the metadata into the blogsdb and whatnot. right, so quick development times. then simpler operations, like if your analytics service was talking to the block service and let's say the communication is happening, or persistent tcp connections, then someone had to manage the tcp connection pool. then see your servers are scaled up, see if everything works fine, see if there are no network doors, backlog, syncs and what not. instead your analytics service is directly talking to the database. so no problem there, no extra overhead. operations are pretty simple: both services talking to the same database and done right. so pretty, pretty simple on the operation side and, more importantly, better performance because there is no middleman, there is no extra network hop, that is happening. analytic service is directly updating the database, block services directly reading from the database, so overall performance looks super solid. so this as an approach has massive, massive advantages. keeping things simple, everyone is happy, teams are working very quickly, right, so it's a win-win for everyone. but apart from all of these advantages, there are few, rather four key disadvantages, not really, but four key challenges that you would have to always keep in mind when you are adopting this pattern. it may not be suitable across all use cases, but even for a minor use case, if you are adopting this pattern where two services will be sharing the same database, both of them having the read and write access to it, then what four things you should be thinking about. the first challenge is: external parties are getting internal details. so here what is happening is because, like, the database is owned by the blocks team, but analytics team wants to update a total likes into the database. so analytics team needs to understand the schema, needs to understand how the data is stored, needs to understand the intricate details of it, of this particular db, so that it can correctly place the information in the right table at the right spot. otherwise it would be a massive mismatch onto users and because block service is expecting it to bit some place but analytic service is putting it into a different place, so major complications might happen. so, by sharing a database with an external party, here analytics is an external party, like it needs to get the internal schema and other implementation details like, for example, implement details like: are they using soft deletes or heart deletes, is the database normalized or not, is the data redundant or not, right so those kind of details analytics team would be able to deduce out of this database, which might not be the best thing, because why should they be caring about this part, right? so it's always better to have as safe distance as possible from all the interfacing teams and not let them know the internal details of the things, right? second is where. what if the block service thinks of changing the schema? because analytics service or analytics team knew that the schema was in a certain way. now, if you, as a blog stream, want to change the schema now, analytics team needs to change their query, need to change their code base to adhere to the new schema, and to do that the biggest problem here would be that analytics team would need to change its logic, uh, and the block stream needs to ensure that the changes are always backward compatible so that the transition is smooth now, unnecessarily. what is happening is because a service like analytic service was dependent on the same database, the block service. who, the blocks team, who owns the database, is not able to quickly make those alterations into it that might give them better performance or better maintainability, and but they would have to wait on the analytics service to make those sentences, keep them in the loop and get those things done. so this sort of tight coupling might not be the best decision for the overall autonomy of the blocks team, because they are always dependent on the other team like hey, they need to be informed, they need to give a go at, even though blocks team own it, but they are dependent on that. so this reduces the development time. and just one key point before we move to the second challenge is what if your blocks team today, like we know that hey, relational database works well till the certain stage, but now that, let's say, we are getting millions of- hypothetically, let's say, we are getting millions of articles, one database is not able to support it. so you want to shard it or you want to move from sequel to nosql, because nosql gives you by default sharding right. so, given that blocks team independently cannot make the decision because analytics queries might get impacted, so there is no clear autonomy of how- uh, of how- block service can operate. they are always dependent on the analytic service to like, before making any changes, they would have to take a nod from them. so it it's not truly an autonomous system, like there is a very strong coupling between the blogs and the analytics, so not really a good design or not really a good high level pattern that we talk about. second challenge is sharing the database is equal to sharing the business logic. so now, for example, to render a particular dashboard or to render a particular data onto the interface, your services needs to fetch data from t1, from tables t1, t2, t3 and t4. right, and this information is needed by all the three services: blogs, analytics and, let's say, a recommendation service. right now, the logic of logic to fetch this information is implemented by all of them. it's not that only one service is implemented, because all of them are talking to the database and the services are not talking to each other directly. this the logic, the business logic to get that particular information has to be replicated across all the three services. now this- now, let's say, block service- made some change. now it says that, hey, now, in order to fetch this information, instead of using tables t1, t2, t3, t4, use tables t1, t2, t7 and t4. so when this happens, your analytics service and your recommendation service would need to change that business logic at their end and redeploy their services unnecessarily like. it should have been a very smoother transition where they should have been there. they should not even have known what's happening behind the scenes. but now, because they are all sharing the database, if anything changes or any business logic changes, these folks needs to update their logic and deploy their changes. so here what we are doing is what we are losing is we are losing on cohesion. what we wanted is all the services, or all the components that are very tightly coupled, or they were where, in order to scope your micro service, you should always be thinking, hey, are these components, uh, independent enough to be separated? if they are not, then you should keep them together. here these three components seem very separate, like three very different use cases, but still, because they are sharing the same database, there is very, there is very thing that the services needs to be: knowing the business logic and and changing the business logic according to change happening on one of the servers or the team that owns the service. so pretty messy situation over there, right? so, although we talked about two challenges, but the first two challenges that we talked about are directly impacting the core principle behind the microservice. so, in order to like in the previous video, we talked about how to scope a micro service, and the two things we talked about is loose coupling and high cohesion. the first challenge is actually breaking on loose coupling, because you are having very tight coupling because they are sharing the database, and the second one: you are losing high cohesion because three services that seem to be tightly coupled are not and business logic needs to be changed but you cannot keep them at the same place. so pretty messy situation over here. so we are losing both by sharing the db. the third challenge is risk of data corruption and deletion. so here what would happen is because every service blocks analytics and recommendation. all of them have read and write access onto the same database. what if, due to a buggy script or due to a wrong script, analytics ran a script and it deleted the data from the blocks tv permanently or it corrupted. it corrupted the data. now, when that happens, it affects not only the block service but end user directly. it may lead to cascading failures and basically cascading impact across other services. so here, when you, when you are sharing the database across multiple services, you have to unnecessarily additionally take care of database level access control list to ck hey, and because analytic service needs to update only rows in this particular table, analytic service should get access. the user through which analytics services talking to the blocksdb should have access only to that table. now recommendation service might not need to update something into the database. let recommendation service only have read user like. those sort of complications come in as soon as you start sharing the database, just so to prevent data corruption and data deletion right. the fourth and the final challenge by sharing the database is: your shared database can be abused very easily, say your analytics. your analytic service has written a, a query and this query is very expensive, very expensive, as in super heavy with respect to the number of tables it joins, the amount of data it computes and so on and so many things. so when that is there, when analytics team fire that particular query, your blog's db starts to choke up. because your blocksdb starts to choke up, what would happen is it would reduce or it would impact the performance on the main block service and the recommendation service. so analytic service is putting additional pressure into your blog's database, which is shared across three services. so, unnecessarily, the three, all the three services are getting affected by because of one, because of one service. and now you'll say, hey, can we not rate limit? but how will you rate limit a db query? where is the rate limiter? like you are directly connecting to the database, rate limiter would have come into the picture, or rationing would have come into the picture when all the things, all the requests, would have gone through a central service. let's say, if analytics talks to blogs and blogs talks to the database and recommendation talks to blogs and blog stocks to database, we can apply rate limiting over here, ensuring that no service is abusing the shared database. but when the three services are given privileges to talk to the database directly, any one service of you can like, because of a buggy script, because of a bug, because of what not, can actually abuse the entire system and can let the entire system get affected? right? given that these are the four challenges, does this mean that we should not be using shared database pattern? no, there is the problem. like most people look at every problem as black and white problem or right or wrong. no, it's never like that. in any design, in any system you ever design, you need to know what are the strengths of that approach and what are the weaknesses of that approach. so here, if the weaknesses is something that we can live by, the strengths are immense, like because it's give you quick development time, quick access, direct control and whatnot. right, so what are the possible places where you can actually use sharing a database pattern? first of all, it's a very quick solution. so, for example, if you're starting up, you have a very small team, why would you want to spend time building microservices, talking to that and then talking to db? don't add those over complications. so if you're having, if you're operating on a small and lean team, never think of optimizing it on the micro services part, inter service communication and whatnot. not worth the time and the effort, right? so doing this- analytics to blocks and blocks to db- takes time, team coordination and all of that. so very slow, so it would make things slow. so when you want speed and agility, share the database. don't think too much about it. add those necessary access controls, because you are a very lean team and you don't know if your business is going to survive. pick the one that suits your current needs rather than going for the best practices overall. second is when your schema doesn't change. often, like most of the situations that we talked about in the challenges, it was more about changing the schema, right? what if i want to change the schema, move the database? my blog stream cannot do it independently. what if there is no need? what if you know that for next three years we are not going to change the database? what if we know that the schema is not going to change to a massive extent? where things are pretty stable, then why not? why not share the database? it is so simple to share the database and get those things up and running in a very short time, rather than thinking about, hey, pure microservice communication and other sort of complications. no need of doing that, right. the third thing is read load can be moved to a replica. one of the challenges that we talked about there was one system abusing the other database when that is the use case or wherever. basically, that is a possibility. what you can actually do is, instead of not adopting a shared database pattern, what you can actually do is you can actually fork out a read replica out of your main blocks db and let the analytics query fire on the read replica, although there would be some lag. lag would be in a couple of seconds, but it would not affect other services. so what you can do is you can move all the read load to this read replica, while the main block db can take care of the critical rates by the block service and the rights happening by the block service. so this way, your block service can still operate in isolation, right, without getting this affected. an analytic service with some basic lag can continue querying on the read replica. this way, your analytics service is happy, your blog service is happy and you are getting very nice development time, quick turnaround time, no team coordination required and whatnot- like, obviously, given that your schema is not changing often- right. this way you reduce the dependency and you're still basically getting the benefits out of sharing the database rather than losing on most of the stuff. so, yeah, that is it: four challenges, uh of uh, sharing the database pattern and ways to mitigate them, and when can you and, more importantly, when can you actually use this pattern? and this is not something which is just theoretical, like most systems or most microservices evolve this way, where they first start with sharing the database. they even at scale. they do share the database in which they do not see massive changes happening or the system is stable enough and the system is not abusing. they put some basic checks in place and let uh multiple services access the common database. that is the best way to have those in like best and the quickest way to have that communication. so keep all of those things in mind next time when you are designing a system- that no pattern is black or white, no pattern is right or wrong. you should always think about where can i exploit this pattern and what is the best for my use case, right? so yeah, that's it for this one. i hope you, i hope i gave you- a different perspective to look at uh microservices communication pattern, especially sharing a database, where not to look at it as a wrong pattern per se, but just use it what floats your portal, right? so, yeah, that's it for this one. uh, if you guys like this video. give this video a thumbs up. if you guys like the channel, give this channel a sub. i post three in-depth engineering videos every week and i'll see you in the next one. thanks again.