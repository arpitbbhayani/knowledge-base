so micro sizes need to talk to each other to exchange information and get things done. for example, your core api server needs to talk to your notification service to send notifications to the followers when you post something right now. picking the right communication pattern is super important, as a good decision will ensure a great user experience and scalability, while a bad one will ruin your party. there are, overall, two categories of communication: synchronous and asynchronous. in this video, we in depth discuss what synchronous communication is and how it is done, what a synchronous communication is and how it is done, the advantages and disadvantages of both of them and, most importantly, understand how to decide which one to opt for with real world examples. but before we move forward, i'd want to talk to you about a code based course, or system design, that i have been running since march 2021, and if you're looking to learn system design from the first principles, this course is for you. yeah, because this is a cohort based course. it will not just be me rambling a semi-optimized solution, thinking it's the most amazing solution out there. instead, it will be a collaborative environment where every single person who is part of the cohort will can pitch in his or her ideas and we will evolve our system around that right. every single problem statement comes with a brainstorming session where we all together brainstorm and evolve our system. that's why everyone understands the kind of trade-offs we made while making that decision. instead of just saying, hey, we'll use a particular queue, we'll have the justification why we use only that queue, why we use that particular database, why sequel, why not no sql? right, how are we leveraging throughput? how are we ensuring that our system scales? that's the highlight of this course. this course is taken by more than 500 engineers to date, spanning nine countries and seven cohorts. right, people from all top companies have taken this course and the outline is very intriguing. it's very exciting. so we start with week one around. we start with the core foundation of the course where we design online offline indicator, then we try to design our own medium. then we go into database, where we go in depth of database logging and take and see few very amazing examples of data log or database logging in in action and how do we ensure that our system scales through that. then the third week is all about going distributed, where we design our load balancer. i'll have, obviously the actual code of a toy load balancer and understand how pcb connections are managed and how simple it is to build load balancer. then week four is about all about social networks. week five is all about building your own storage. indians, like we'll build that intuition on: if you were to ever design a storage agent, how would you do that right? then week six is about building high throughput system. seven is about building uh ir systems- basically information retrieval systems- and adopt designs where we design our own message brokers like sqs, where we design distributed task scheduler. and we conclude the course with week 8, where we talk about the super clever algorithms that has powered or that has made those systems possible. right, i have also attached a video, verbatim as is from my first code, where we designed and scaled instagram notifications. i will highly encourage you to check this video out, right? and now back to the video. so say, we are building a social network in which we have a reaction service and a notification service. whenever user b post something, user a is allowed to react on it- like, like, share and comment- and as soon as that reaction happens, the notification needs to be sent out to the user who created it post, which means user b, right? so how would the reaction service, talk to notification service to send out a notification to the target user. right, that's the agenda, or that's exactly what we'll be discussing today. so here the things would have been pretty simple if we would have monorail in place. so what's a monolith? monolith is just like: you don't have microservices architecture, but rather everything just fits into this one gigantic code base you have, which means that sending out a notification to a user is just a function call, nothing extra. it's just a function call, part of the same process or part of the same thread stack, and you just invoke that function call and that sends out the notification. right, so that is super fast. that is guaranteed to succeed. and that is one of the biggest advantages of monolith where, because there is no distributed systems involved, there is no network call involved, the sending out notification part using a function call will is always guaranteed to succeed. but the the things become extra challenging when we have a distributed system, because in distributed system whatever could go wrong would go wrong. so what might go wrong on a distributed system? there might be a network failure, your target service, which means the notification service, is down, or your notification service is overwhelmed by the number of requests that it is getting, so it is not able to respond as quickly as you would want it to. your target service is not at all reachable. not data reachable means the service is not down, but because of network partitioning, your one of the service is not able to reach the target service. so how, how would we like, in a distributed setup, how would we make these two services talk to each other? so, which is where the first category of the first category of communication pattern we talk about, is synchronous communication. so synchronous communication is one of the simplest way of establishing communication between two services and it's, and it's as simple as just making an api call or doing that synchronous uh or basically doing the synchronous transaction uh between the two servers. so, for example, whenever user, whenever some user, reacts on a particular post, that reaction service, when it registers it in its database, it will be synchronously talking to your notification service to send out, let's say, a notification service exposes a bunch of endpoints, the reaction service will trigger or will synchronously invoke the apis of your notification service to send out a notification. so here, this, the key highlight of synchronous communication, is that it is a blocking call, which means that when your user hits the like button, the api of the reaction service gets invoked. reaction service updates its database, then it triggers a notification on the notification service, right, and the notification service sends out the notification. then the notification ma says ok to the reaction service and then the reaction service sends ok to your user. so, which means that unless the notification is sent to your user, your a main api call from your, from your user, will never be completed. so this is a blocking call, right? so every like this is a classical case of synchronous communication and a blocking call, where your main api is blocked until all the synchronous communication is done. right, but what would this guarantee? this would guarantee completeness. this would guarantee that whenever a user hits the like button, the other user definitely gets notified. otherwise the like does not complete. like like all the user would be not, uh, like you would not get a successful response out of it, right? so how do this like? obviously, synchronous communication is there, but how do we actually implement it? like? most synchronous communication in today's day and age is all is. most of them are built on http, right, and obviously there are raw tcp based communication, not denying that. but most common that you will ever come across is http based, where three most famous ways to do it is rest based endpoints, where literally the your notification service itself has exposed a set of endpoints. reaction service invokes that end point, so maybe a get call or a post call or a put call and that would trigger that part. so rest based communication, graphql based communication and grpc based communication- all of this are built on top of http and http itself is built on top of a reliable communication, which is tcp. so what we'll do is in this one will not discuss a lot about rest, graphical and grpc, but we'll touch upon that in some other video. right? so now let's talk about advantages of synchronous communication. so synchronous communication, the biggest advantage that you get is that the communication happens in real time. because when your reaction service was talking to like you had to send a notification, reaction service made an api call which guarantees sending out a notification. so whenever there is this real-time communication happening, the call has to be synchronous. you cannot defer it, you have to do it synchronously, right? synchronous communication is one of the simplest and the most intuitive way of communication. like. it's a no brainer on how synchronous comment. like you want to talk to a service, you make an api call to this service and done. that's exactly what synchronous communication is all about. so it's very simple, it's very intuitive and it's very real-time, but obviously grass is not always green. what are the disadvantages of synchronous communication? the biggest disadvantage of synchronous communication is that the caller is blocked until the response is received, which means that, say, if reaction service is talking to a notification service and let's say, notification service does not respond in 5 millisecond, 50 millisecond, 100 millisecond, 200 millisecond, one second, two second, your reaction service is blocked and because your user made a synchronous api call to a reaction service, your user is blocked for that time. so the blocking time adds up across all the levels of communications that you have right because of. because the communication is synchronous and your user needs to be blocked, it may hit a timeout or to your network level. so there are lots of, lots of problems when you have a large chain of synchronous communication and most of them arise because the call is blocking. because the call is blocking, you are not getting a response or you cannot move forward unless you get the response from your apis, basically from the communication that you intended. the second disadvantage is that your servers need to be proactively provisioned for peaks, and not just for this thing, but for peaks. and that's the worst part, because now, let's say, you have a service a who wants to talk to a service b and this completing is your service b. so what you are doing is your reaction service is triggering api of your notification service in synchronous way. when that is happening, what you definitely need to do, because the communication is synchronous, your reaction service will make a call to your api of your notification service. and what? if there are not enough servers to handle it, then the request will get dropped. if the request gets dropped or you see higher latency, it would impact the overall latency of that your user experiences, which is where you need to always ensure in case of synchronous communication. you need to always ensure that there is that there are enough servers for you to handle the traffic. otherwise your latencies will spike up because your servers are like you have pure servers- large number of requests. they might not be able to handle it, so you'll see large network latencies coming at play. right, and the worst part here is you have to do it for peak, which means that, let's say, if you see a sudden surge of users and if you don't have enough notification servers to who are sending out synchronous, or beat any service, not just, i'm just taking that as an example- beat any service if it does not have enough capacity to handle it. there is a chance, or rather number one: the service will get, or the servers will get overwhelmed, the database will get overwhelming, can cash and, uh, your end user latencies will shoot up, which means your end user experience is going to suffer a lot. right so? which means that with synchronous communication, whenever you are doing it- not just notification service, any service- always think about it. have you proactively, or have you have, or do you have enough servers for you to handle the surge or the peak, or do you have the right set of scaling policies applied on that? third disadvantage of using a synchronous communication is risk of cascading failures. so what exactly is cascading failure? it means that when you have a chain of connected components which is communicating synchronously, if one of the component goes on- let's say here, service a is synchronously communicating with service b, b is communicating with service c, c is communicating with service d. all of this in one request call. what if service d goes down? as soon as service d goes down, the call that was made by service c to service d starts to fail and c does not immediately know that the d is down. it will wait for some time. let's say it waits for a for one second before it declares the dead, or or or rather before it gets to know that d is dead. so that would add a back pressure to c. c might start to choke up because of added latency. because c might choke up, it would have back pressure on b and b goes down with takes a with it because of the synchronous communication. a lot of services will start to experience degraded performance, will start to see higher latencies. it should put additional pressure on to the onto the system because the incoming load is not changing and that service would go down. this is a classic case of cascading failures where chained services, one of them goes down. it affects every single one in the chain. and how do you stop it? you need to have circuit breakers in place where you say that hey, if d is down, he would not even invoke these api because he knew the d is down, so that your circuit is broken and you do not have this cascading failures happening. the next disadvantage is that it creates very strong coupling between participating services. we talked about, uh the like- how do you scope a microservice- in the previous video in which we talked about that. one of the key- uh key- things to remember when we are scoping a microservice is that there should be loose coupling between them. but when you have synchronous communication in place, your service are tightly coupled, which means that if your a is synchronously communicating with b, if b changes something, a should be kept in the loop, right, like, for example, api contract changes, a needs to know about it. if, let's say, they are having a major deployment which requires a downtime, then a needs to know because the communication is synchronous, because the communication synchronous. if b is down for some time, even though it's a planned downtime, a needs to know about it. so this creates a strong coupling between them. and, like with synchronous communication- you always have to think about that- are my apis version. like, for example, if you push, if b pushes a, a a backward incompatible change, then it needs to ensure that it it is creating a new version for that so that a is not affected much. so your api needs to be versioned. you need to have strong contract established between a and b, which means this is exactly what the message or request is, is exactly what your response should be. and every time b pushes something, it needs to ensure that it is backward compatible. so it added. it adds a lot of complex, unnecessary complexity when you are having synchronous communication. but obviously there are major benefits of using synchronous communication, but you always have to keep in mind about all of these disadvantages of using them. but this does not mean that we don't use synchronous communication. we use it all the times, by the way. okay, so when should we actually use synchronous communication? the key reason for you to use synchronous complication is when you cannot move on. in simple terms, when you are making a request and you cannot move to the next line of code unless you get the response, which means that the request you made and the response you will get. that response is important for you to proceed, to proceed further. for example, you fire it. you fire a database query. unless you get a response, you will not move forward. this is a classic case of synchronous communication. so that is where you are firing of database queries. your api, like the api responses that your user makes, like ebay api request that your user makes to a service. let's say, i want to like, uh, like a post, so user will trigger an api to like that particular post and until it gets the response, it will not move forward, right? so this is a classic case where you should be using synchronous command and basically this is one of the most important reasons, or most important places where you would be using synchronous communication. the second is when you want real-time response, for example, chat and check out, like when you're. when you're chatting with something. when you're chatting with someone, you always expect a real-time response from that person and when this happens, this communication cannot be delayed. it needs to be in real time because otherwise the user experience will be bad. so that is where you would use synchronous communication. check out, which means that on an e-commerce website, you added something to the card and you hit the checkout. this needs to be synchronous. your payment needs to be signals if it is go. if it goes asynchronous, how will you even know, like, what that flow is going to be? or how will you like you as a user or as a end customer? your expected guy made the payment immediately. give me my order, right? so you need to send me uh or you need to notify me about my order, like my api request should complete. you cannot do this asynchronously, right? because this is where- because- and typically you will always see wherever money is involved- most of the transactions becomes incurred or most of the communication becomes synchronous. and one key pattern to look at when you are picking uh, when you go for synchronous communication, is when it will take relatively less time to compute and respond. so if your latencies of your api is typically few milliseconds and seeking relatively less compute to, to, to find that answer to, to basically uh, create a response, you would typically go for uh, a synchronous. so if it's a long running process- let's say it goes for 10 minutes- that cannot be done synchronously. that has to be done the sacrifice right. so now let's talk about the second category of communication, which is asynchronous communication. so this is a classic standard diagram for a synchronous communication in which what you typically have is, whenever two services need to talk to each other, instead of directly invoking each other's api, they send out a message in a broker. this is that buffer, that that holds all the messages together and then your notification service can slowly consume the message that happens over here. this is a classic idea behind notification or behind asynchronous communication, right? so here the interaction between the two services, or like the reaction service and the notification service, is via an exchange of a text message, for example your reaction service, or when your user reacted to something. this is going to be a synchronous call. user making an api, a rest api call to register a like on a particular post, then the reaction service would update its database and then would send a message to your message broker saying that this user reacted to this post made by this particular user. so user a reacted to post by b. this message is sent to the broker and is read by the notification service and notification service would say: hey, because a reacted to b, i need to send notification to b, so notification will send out. notification service will send out a notification to the user b. right, so here the message broker is acting as this gigantic buffer in which a lot of messages are pushed and from which a lot of messages are consumed. and because of the best part of going for an asynchronous communication is that there is no cascading failure, because this is above, in synchronous communication you always made a call right away, but here the messages are stored in message broker, which can eventually get consumed by the notification service. so here, because this is acting as that buffer, which means that this communication does not need to happen in real time, so there is no risk of cascading failures. there might be longer delays if there is a high surge in volume, but there is no. uh, there will not be any cascading failures. that's the biggest advantage of going for an asynchronous communication here, like in synchronous, where everything was blocking. in asynchronous the, the processing is or the communication is non-blocking. so what would happen is because, uh, your user making an api call to a reaction service is synchronous. so user registered a like reaction service, updated database, then it created an asynchronous task in a message broker. this is also synchronous. this is also synchronous. and once it made an, once it registered a message in your broker, your broker stored it and acknowledged it. this acknowledge: after your reaction service got that acknowledgement that the message is stored in the broker, it would send the okay response to your user. so now when your user makes a like, the, the, the reaction gets registered and asynchronous message is pushed in, the broker gets a response, gets a response, and only for this much of time the api is blocked or the or your user is blocked, right and now? once the message is registered, now your broker notification service can run at their own time and can trigger the notification. so here the notification service can pull the message out of the broker and send out the notification to the user. but that is independent of this main request cycle, this main request context that you have, right. so now your main request context is pretty lean, while your heavy lifting is done asynchronously, right. so what technologies can you use here as broker? few very famous examples: rabbit, mq, sqs, kafka, kinases. google pops up. there's so many out there that you can, out of the box, use as your message broker for this call. each one has a separate property, uh, but we will talk about that sometime in the future. but basically, when to use that exact tech? when and why? uh, we'll talk about it sometime in the future. but the idea is: adding that buffer removes your cascading failure, makes your things lean and efficient and, like to be really honest, this is one of the main reason why a lot of things have scaled right. okay, now let's talk about our advantages, of our securities communication. the biggest advantage of asynchronous communication is that your services don't need to wait for the response. so earlier your reaction service used to send communication to notification or synchronous connection notification and then you should get response. but what if notification service is with asynchronous communication? you don't worry about that. your reaction service simply puts a message in the message broker and done now. now a notification services job is to pull that message out from the message broker and send out the notification. you don't really have to worry about that. so now what would happen is the api response time that your user sees, your end user sees- is pretty low because it stores one reaction in the database, sends out a message and done. it does not have to do that heavy lifting that your notification system does, which makes a call to, let's say, your email client or your or your or your- basically whatsapp- provider to send those notifications to a user. this way, if you get a surge of request, your system is unaffected because what was happening is in synchronous communication. you had to ensure that the notification services is bulked up, but to handle the search in case of a synchronous communication, your reaction service, because when you're, when exactly are you getting search? when your end user is making a lot of reactions. that's why you are getting search over here. but for every request that you get over here, you are updating the database that you anyway have to ensure and it needs to send a message to the message broker, right, it is. when this is done, like here, no matter how many requests you get, your reaction service only has to store messages in the message broker. it has nothing to do with notification, it is just storing the messages in the message broker. this way, what would happen is, no matter how big the search is, your end user experience is pretty consistent because so long by, by the way, so long as the message broker is skilled enough, right? so here the key idea is, if there is one request per second or 1000 requests per second, the api response time, sees as experienced by your end user, remains unchanged, because your reaction service updates this database and sends a message broker, and that's exactly what it would always do: beat one user or one request per second or 1000 requests per second, right. so here that obviously like if there is a search, your notification service might be over. when consuming, there will be larger delays, but no failures, no bad user experience, which is more important. like you are not giving bad user experience to your customer, okay. the next uh advantage of asynchronous communication is that you don't need to proactively scale now because, as we just saw, because of the search, you don't need to proactively scale notification. you can see that, hey, if there are large number of messages in the broker, then scale up the notification system because the communication is not synchronous. the reaction is not. the reaction service is not directly dependent on notification service, which means your notification service. if, so long as the delay is acceptable, your notification service can slowly consume all the messages, right. so that's a big advantage where you don't need to proactively scale up your infrastructure just to handle that amount of request. you might want to. exactly, you might want to increase the number of consumers of the notification service just to ensure the minimal delay, but reaction service is unaffected by it and that is what gives you very strong decoupling between your services. the next advantage is that you require fewer infra components like load balancer when your reaction service is talking to a notification service via broker in this communication, you don't really need a load balancer sitting in front of notification service because what's happening? your reaction service is just pushing the message in the broker and the notification consumers are picking the message from the broker. so in our sequence communication you don't need extra components like load balancer. and why it is important? because adding a load balancer increases that hop by on an average from one. as soon as you add one network hop, it approximately adds three to five milliseconds of your latency. in case of coming like this load, like if your user was directly talking to this api server, let's say the time it took was 100 millisecond, but with this load balancer in place it might take 105 millisecond. right, because this is a network of your packet. your tcp packet has to go from user to load balance and then from load balancer to reaction servers, right? so adding this one extra component in your, in your infrastructure, that one extra network hop, will have impact on your overall latency. but with a synchronous communication there is no load balancer involved. reaction service simply puts the message in the broker and message broker and your notification service pulls the message out and then does the processing whatever it needs to. so your user experience is pretty consistent always. the next advantage is there are no request drops or data loss in synchronous communication. we see that if your target service is overwhelmed, let's say notification service is overwhelmed, then any incoming request that comes in will have to be dropped. right, it might see very high latency and once it hits that limit, once that pcb backlog hits its limit, the mo, the request, would start to drop. it would be 5038 service, temporary and available, unable to connect, connection timeout and whatnot. so there will be request drop. there will be data loss where user registered something to write and you are not even accepting it. so this is a classic problem in synchronous communication when typically you see traffic or when you see a, when you see a, an unexpected surge. but with asynchronous, there is no data loss because the reaction service simply has to put the message in the broker. that's it. so that's where your system like. what would happen is your notification service, because your reaction service just put the message in the broker, the notification service will eventually consume all the message and will catch up, right. so even if there is a very high surge of reactions coming in sitting in your message broker, notice, if you have just fewer servers, it will take, let's say, 10 minutes to consume the messages. if you want faster, add more servers to it. so it's purely horizontal, scalable consumers that you have over here, right, but in any case you'll not have any request drop whatsoever because your reaction service only has to put the message in the broker. that's it. the next one is you get better control over failures because in synchronous communication, if their request field you had no way to retry, you had to do like your user had to do: retry, which is a very poor experience because having retries on your client side is not a good solution. but with this asynchronous communication what do you get is you can retry like, let's say, you're while processing a particular message or notification server crashed. when another server comes back up, it would read the same message and do that processing. so you will have retry out of the box. let's say your email sending client is not working. let's say whatsapp is not working or, uh, your email client is not working. your notification service can hear retry and it is not affecting your end user experience. the notification service is retrying it, let's say thrice, to just try to send that email out. if it is not able to do that, it would just add it to a dead, later queue or something. but here you can have an independent retry in an asynchronous framework versus a synchronous framework right. so that's a big, big, big advantage that you get out of. you get better control over your failures and retries. the next one is your services are truly decoupled because, like your, notification service can scale independently, your reaction service can scale independently because these are synchronous communication so long as a message broker is good enough for it to handle the traffic. what would happen is these services are totally decoupled. now it's all about sending out a message and reading over here. so now reaction service can choose to implement tcp with this end user or udp with this end user, however it would want to do it. notification service remains unaffected- right, because it's pure text based messages which are sent here and which is consumed over here. so purely decoupled. like you with this, you have purely decoupled your services. right enough. our advantages: what are disadvantages of asynchronous communication disadvantages? the biggest disadvantage of our synchronous communication is eventual consistency. as soon as you add a message broker in your architecture, you are signing up for delays. you are. you are okay your system to be not strongly consistent, because what would happen is the message is sent synchronously but then it is consumed asynchronously. so you have lost your control and if there is enough load coming in enough message piled up, your system will eventually send out the notification to all the users, but not in real time, right? so this is where you have to be very of the fact that as soon as you add an asynchronous component into your architecture, you are signing up for eventual consistency, okay. the next one is: your broker becomes a single point of failure if you only have one instance of your broker running, let's say, your sqs or revit or something you need, because this broker is the backbone of your communication. what you need to ensure that this broker is always up and running, because if your broker goes down, you cannot do much about it. right? your? your reactions are in this: trying to push message into it will fail. you'll experience data loss and whatnot. so it's very important that whenever you have a synchronous communication in place- because this message broker is the backbone of your architecture- it needs to be horizontally scalable. it needs to give you fault tolerance. it needs to guarantee that there is no data loss if the message is stored there, right? the next disadvantage is it's harder to track the flow of the communication. for example, you have service a, b, c, d and e. service a and b talk to each other via broker. b and c talk to each other with synchronous communication. c talks, c talks to d and d via message broker. so now for the same request context. how would you know what is processed and what is not synchronous? coming here, it would be pretty straightforward: api request succeeded, done. if it is not succeeded, then it's paid. but with asynchronous, you don't know if b is down, you don't know if b has consumed and processed your message, if c has done that, if d has done it, if he has done it. so here, as soon as you add the message brokers into a system, your tracing takes a hit. if someone tells you in this request context where exactly did your message go, how it got consumed, what was the average latency in each part, it will be very hard for you to tell unless you have a good uh monitoring or good observability set up on your infrastructure, right? so as soon as you add asynchronous communication, you are also signing up for a tougher observability. you need to have very fine granular tracking of where each request is going and how much time it is taking. so that's a good deal of disadvantage of using a synchronous communication. okay. so when should we use a synchronous communication. the biggest reason or the biggest place to use our signals communication is when delay in processing is okay. sending out notification should not be in real time. it is okay if it takes five seconds for you to send out a notification. so that's what you do, is you add a message to a broker and let your notification service consume it, because it does not need to be real time. in case of otp, though, it needs to be real time. for example, when you are trying to log in onto a website and you are waiting for the otp. that needs to happen in real time, so your react or your otp service will be talking to the, the sms service, in real time to send out the notification, to send out the sms. it cannot happen with delay, right? so where delay is acceptable, when delaying processing is acceptable, you will go for a synchronous communication. otherwise, you'll go for a synchronous communication. other example is analytics and reporting. let's say you are having a monitoring system and what do you want to do? is you want to create, let's say, reporting on top of your infrastructure key like something is wrong? this is the average response time. every disposal- i'm short of this- alerting and reporting part- can be done asynchronous, because the delay will not be days, it will be few seconds and it's okay if you get alert in five, second or ten second late, right, that's not that big of a thing that would happen because you are only having proactive alerting, right. so whenever the delay in processing is okay, you would go for a synchronous communication. second is when the job at hand is long running. say you are provisioning an ec2 server. now is it hypothetical, hypothetically, let's say, provisioning an ec2 server takes 10 minutes. will our user wait for 10 minutes for your api response to come in? no, so that's what you do: user submits a request to create a server server or your api server immediately responds, acknowledged, and then your api server sends a message. then that message is picked up by a provisioning service and that provisions are actually easy to server. so this is a classic case where your job at hand is long running, you would do it asynchronously. for example, provisioning a server, for example tracking your orders, for example database backup, database, backing up a database typically takes one hour. two or three are depending on the amount of data that you have. your synchronous communication cannot wait for one hour, right? imagine your http request taking one hour to complete. that's a very poor way to do it. that's where you do that communication asynchronously. next, when you have multiple services who need to react to the same event: for example, when the blog is published, you want to index it in your search, you have to notify all the followers and you need to update the user analytics. now, because of the same thing that happened, like one event is triggering three things, three independent things. this is a classic case where you would want to do it asynchronously. so as soon as the blog is published, it would synchronously push a message in a message broker. this message will be consumed by three services: search service, notification service and analytics service. this way, what would happen is your all of these four services are decoupled. this services has a job of putting the message into the broker and the three services will consume the message. now, let's say tomorrow, the use case is extended. you want the fourth service to consume the same message. it is seamless. it is seamless. you just add the fourth machine and start consuming from the same queue. so whenever you need have multiple services who need to react to the same event, you'd go for an asynchronous communication. and the final place where you can go for a segments communication is when it is okay for you to allow for failures and retries in synchronous communication. it is very hard to where it is not acceptable for your request to fail, right. but when you want to gracefully handle the failures with asynchronous communication, what you can do is you can add retries, which does not really hamper the experience of your user, but it works seamlessly fine. so whenever you are allowing your users or whenever you are allowing your uh request to fail and you can retry gracefully- for example, your email client is down, your notification service read the message from the broker, wants to send out an email notification to one of your users and if your email service is done, notification service can gracefully do retry without hampering any performance to your end user, because it is doing retry and it would invoke and then eventually, when the email client or your emails are email provider comes back up, the request would succeed. so when it is okay for you to allow failures and retries, this is where you will go for an asynchronous communication rather than going for a synchronous one, right? so yeah, basically, that's it for synchronous and asynchronous communication in microservices, in a pure microservices architecture. i hope you now have a detailed and in-depth understanding of the communication advantages and disadvantages and, more importantly, when to use which where, by and how. right, so yeah, that's it. that's it for this one. uh i, if you guys like this video, give this video a thumbs up. if you guys like the channel, give this channel a sub. i post three in-depth engineering videos every week and i'll see you in the next one. thanks a ton.