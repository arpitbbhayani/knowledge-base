so the hash table needs to be resized in order to maintain a consistent performance.
in this ninth week of the hash table internal series, we go into the implementation details of resize operation and talk about when and where in the code should we trigger a resize, two ways to implement resize while using chain hashing and things to remember while resizing a hash table that uses open addressing.
but before we move forward, i'd like to talk to you about a course on system design that i have been running for over a year now.
engineers from companies like google, microsoft, github, slack, facebook, tesla, yelp, flipkart, dream 11 and many, many, many more have taken this course and have some wonderful things to say.
the first one is the live cohort discourse which you see on the left side, and the second one is the recorded course which you can see on the right side.
load factor: a simple ratio of the number of keys that are there in your hash table divided by the number of slots that you have, and we see that as the load factor increases, as it approaches 1, the performance of the performance or the lookup time of your hash table starts to degrade, and and it primarily happens because of two reasons.
but now let's talk about how to actually implement it with chain hashing and with open addressing.
okay, so let's talk about chain hashing first.
to decide when to resize, we definitely need to know the load factor and hence we need to keep a track of the number of keys that are there in the hash table and the number of slots in the hash table, right, we need to know this information.
so that is where any struct or class that we would use to implement this needs to have those two fields or those two attributes with it: that anytime you are inserting a new key, you might have a variable that says count underscore keys that becomes plus plus every time you insert, right, and then you would have the length of that array or the length of the hash table that you know, the total number of slots that you have.
so every time, upon insert, you would compute alpha, which is equal to count underscore keys divided by length underscore table.
so this is what your actually place, your resize function right.
second, in the chain hashing itself, we have to shrink the table.
also, because it is very much possible that you have deleted a bunch of keys and then what happened is you are having a large number of empty slots, so you're wasting a lot of contiguous memory in the uh.
so we saw that we would shrink when alpha or when a load factor becomes one by eight, and this would be triggered when you invoke delete key operation.
so you might have a delete key operation that takes a table and a key and in the code you would again similar to insert, you would compute your load factor every time you delete a key, right, so alpha is equal to count underscore key is divided by length underscore table, and if alpha is less than 0.125, which is 1 by 8, you would trigger a resize and resize to the length underscore table by two.
and so this is how you do a shrink and that is how you do a resize or a grow of a hash table right now it.
so resizing is all about three things: allocating a new array of desired size, let's say, if you are growing, allocating a new area of that big of a size, then you would have to insert all the keys in the new array and then delete the old array that you had.
right, this is what your overall resize function would look like right now, with chain dashing.
first is, let's say, you have a hash table, you created a new copy with, with 2x of the size, a new array with two exercises, with zero elements in it, and then what you would do is you would iterate through the old keys that are there in the hash table and reinsert them into the new one by triggering the insert key function, which means your nodes, your chains, the way they are in the old setup, they would continue to be there.
you are just iterating through the key and literally reinserting them in the new table, right.
so the advantage of this is very simple: you're literally iterating and then calling an insert key function on this new table, right, and it would automatically take care of everything that you want to, what that you want it to, but it is very expensive because you had the nodes allocated in this with the first hash table.
now, when you're doing an insert, you would be reallocating the node and then eventually you'd be freeing up the first one, but at least for some time you are triggering a malloc of that linked list node to place that key and then add it and what not.
basically, there is an efficient which is slightly more efficient when, instead of reallocating the linked list node, how about we simply adjust the pointers?
for example, if there is a node in the linked list of my first hash table but now i'm creating a second hash table of 2x of size, we know that this node needs to be there in this particular slot in the new hash table.
instead of reallocating the node and putting it into the new hash table and then deleting the old node, we just do the pointer adjustment of my linked list nodes.
this is slightly more efficient because it helps us not, or rather it enables us to not- reallocate the linked list node again, but just readjustment of pointer, slightly difficult to read, but you get the efficiency out of it right.
second, one is slightly efficient- obviously slightly efficient, but the code might not be as readable as you would want it to be right and this is how you would like.
these key factors that you would have to think about when you do resizing of a hash table that uses chain hashing.
now let's talk about resizing of a hash table that uses open addressing.
instead, it finds the empty slots from the hash table and tries to place the key there.
you literally have to iterate through all the keys and put it into the new table.
we know that we always soft delete, we always stop, delete the element so that we can reach the keys further in the collision chain.
simple example: let's say in my hash table i have keys in the order: k3, k6, k1, ky, k2, k4, k8, k7 and k4, k5, k2 and k4 have collided to index 2, right.
i have to do a soft delete, right, we talked about it in detail in in previous couple of videos, but just to recap, that's why we always do soft deletes in open addressing.
because now, because we are soft deleting the keys, even soft deleted keys are making our lookups inefficient, because because they are occupying the space in the table first of all, then we have to go through them in order to look for the keys beyond that right.
so that is where even a soft deleted key with open addressing, having a soft deleted key, is also as expensive as having a key inserted in the table right.
so your deleted keys would also slow down your key lookups because they are occupying the space and you have to go through them in order to hunt for, or in order to continue your search for, further elements.
so we had our keys counter, like we used to maintain a keys counter, whose job would be to keep track.
first is the keys counter, which keeps track of active keys of your hash table right.
so these are the keys which are actually active in your hash table, so you would be not counting soft deleted keys over here.
so, which means whenever you are inserting a key, you do this keys counter plus plus.
when you are deleting a key, you do keys counter minus, minus, right.
it would consider, or it would also consider, the keys that are deleted, so it would count them as well.
whenever you are inserting a key, you would do used counter plus plus, and when you are deleting a key, you would not do not do anything because your keys is still being used.
so this way, with keys counter, you would know the exact number of active keys in your hash table, while the used counter would say the exact number of slots that are occupied in your hash table with deleted keys or with the actual keys of your hash table.
so now your load factor alpha is equal to the number of keys used, or the number of slots used in your hash table, divided by the total number of slots.
this means that we are accounting for the soft deleted keys as well, right, this is a slight change in the implementation part.
so let's see what happens when we do trigger, and so your resize is triggered when you try to insert into it.
so insert key function: similar, but just your load factor function or your load.
the way your computing load factor changes.
instead of using keys count, you're using used count divided by length of table to find a load factor for open addressing and then, if it is greater than equal to 0.5, you trigger the resize right.
and remember, when you trigger a resize, you have to reset your used counter to be same as active counter, because what you would do is, when you are resizing the table, you would only rehash the active keys and skip the deleted ones, because you don't need to, though those are soft deleted keys.
so when you resize your table, you would be skipping your soft deleted keys and not needing it to be rehashed into the new new table, right?
so, given that after your insert keys are crafted, so after the resizes happen, you would have to reset your counter of used count to be same as active count right.
similarly, upon deletion, you would you might want to shrink your table.
so, while shrinking the table, we only rehash the active keys and skip the deleted ones.
same we do it with delete right.
so here also, whenever you delete a key, you would recompute your load factor to be equal to the used count divided by the length of the table and then, if it is less than 0.125, it is 1 by eight.
you would do a resize and shrink the table to half.
and when you do resize, you would rehash all the keys, rehash all the active keys into the new hash table and then reset the counter so that you start a fresh with used code is equal to active part because you have skipped the soft deleted keys.
and these are the pointers that you have to take care of while implementing resize.
when you are using open addressing as your probing scheme, whereas your collision resolution scheme- right, and that is it.
this is how you would think about, like when you are practically implementing your resize operation, you have to think about these factors.
with chain hashing, you can do two ways to do it with open addressing.
and that is it from me in this ninth video of the hash table internal series.
i really hope you try to build your own hash table.