so the hash table needs to be resized in order to maintain a consistent performance but how exactly in this ninth week of the hash table internal series we go into the implementation details of resize operation and talk about when and where in the code should we trigger a resize two ways to implement resize while using chain hashing and things to remember while resizing a hash table that uses open addressing but before we move forward i'd like to talk to you about a course on system design that i have been running for over a year now the course is a cohort based course which means i won't be rambling a solution and it will not be a monologue instead a small focused group of 50 60 engineers every cohort will be brainstorming systems and designing it together this way we build a solid system and learn from each other's experiences the course to date is enrolled by 600 plus engineers spanning nine cohorts and 10 countries engineers from companies like google microsoft github slack facebook tesla yelp flipkart dream 11 and many many many more have taken this course and have some wonderful things to say the coolest part about the course is the depth we go into and the breadth we cover we cover topics ranging from real-time text communication for slack to designing our own toy load balancer to qrik buses live text commentary to doing impressions counting at scale for any advertisement business in all we would cover roughly 28 questions and the detailed curriculum uh split week by week can be found on the course page which is linked in the description down below so if you're looking to learn system design from the first principles you will love this course i have two offerings for you the first one is the live cohort discourse which you see on the left side and the second one is the recorded course which you can see on the right side the live code base course happens every two months and it will go on for eight weeks while the recorded course contains the recordings from one of the past cohorts as is if you are in a hurry and want to binge learn system design i would highly recommend you going for the recorded one otherwise the live code is where you can participate and discuss things live with me and the entire cohort and amplify your learnings the decision is totally up to you the course details prerequisites testimonials can be found on the course page at pitt binary dot me slash master class and i would highly recommend you to check that out i put the link of uh the course in the description down below so if you are interested to learn system design go for it check out the link in the description down below and i hope to see you in my next cohort thanks so resizing is important to maintain a consistent performance we all know that and the performance degrades as the load factor increases load factor a simple ratio of the number of keys that are there in your hash table divided by the number of slots that you have and we see that as the load factor increases as it approaches 1 the performance of the performance or the lookup time of your hash table starts to degrade and and it primarily happens because of two reasons first is it takes longer time to do lookups because of heavy coalitions that you have right basically finding an empty slot takes much more time or going through that collisions to spot your particular key takes time but now let's talk about how to actually implement it with chain hashing and with open addressing where exactly in the code should we place it okay so let's talk about chain hashing first to decide when to resize we definitely need to know the load factor and hence we need to keep a track of the number of keys that are there in the hash table and the number of slots in the hash table right we need to know this information so that is where any struct or class that we would use to implement this needs to have those two fields or those two attributes with it that anytime you are inserting a new key you might have a variable that says count underscore keys that becomes plus plus every time you insert right and then you would have the length of that array or the length of the hash table that you know the total number of slots that you have you might have to store it at a particular in a particular variable so every time upon insert you would compute alpha which is equal to count underscore keys divided by length underscore table when this alpha hits or becomes greater than 0.5 we resize right we resize the table and make it twice its size to maintain a consistent performance right so this is what your actually place your resize function right you would every insert you would compute your load factor post insert and you would do that adjustment you do the resize if needed right this is i'm talking about chain hashing second in the chain hashing itself we have to shrink the table also because it is very much possible that you have deleted a bunch of keys and then what happened is you are having a large number of empty slots so you're wasting a lot of contiguous memory in the uh you are wasting your contiguous heap memory so you have to fix it that is where you shrink so we saw that we would shrink when alpha or when a load factor becomes one by eight and this would be triggered when you invoke delete key operation so you might have a delete key operation that takes a table and a key and in the code you would again similar to insert you would compute your load factor every time you delete a key right so alpha is equal to count underscore key is divided by length underscore table and if alpha is less than 0.125 which is 1 by 8 you would trigger a resize and resize to the length underscore table by two so you would be making it half right so that is how you would do a shrink and so this is how you do a shrink and that is how you do a resize or a grow of a hash table right now it now let's go into our implementation details of it so resizing is all about three things allocating a new array of desired size let's say if you are growing allocating a new area of that big of a size then you would have to insert all the keys in the new array and then delete the old array that you had right this is what your overall resize function would look like right now with chain dashing there are two ways to implement two ways to implement this sort of hashing uh this sort of resize first is let's say you have a hash table you created a new copy with with 2x of the size a new array with two exercises with zero elements in it and then what you would do is you would iterate through the old keys that are there in the hash table and reinsert them into the new one by triggering the insert key function which means your nodes your chains the way they are in the old setup they would continue to be there you are just iterating through the key and literally reinserting them in the new table right the disadvantage of this it's like so the advantage of this is very simple you're literally iterating and then calling an insert key function on this new table right and it would automatically take care of everything that you want to what that you want it to but it is very expensive because you had the nodes allocated in this with the first hash table now when you're doing an insert you would be reallocating the node and then eventually you'd be freeing up the first one but at least for some time you are triggering a malloc of that linked list node to place that key and then add it and what not that is expensive it's very simple to read but it's expensive to implement right so there is a better basically there is an efficient which is slightly more efficient when instead of reallocating the linked list node how about we simply adjust the pointers for example if there is a node in the linked list of my first hash table but now i'm creating a second hash table of 2x of size we know that this node needs to be there in this particular slot in the new hash table we just do quarter we just do pointer readjustment instead of reallocating the node and putting it into the new hash table and then deleting the old node we just do the pointer adjustment of my linked list nodes this is slightly more efficient because it helps us not or rather it enables us to not reallocate the linked list node again but just readjustment of pointer slightly difficult to read but you get the efficiency out of it right two ways to implement one is simple but expensive second one is slightly efficient obviously slightly efficient but the code might not be as readable as you would want it to be right and this is how you would like these key factors that you would have to think about when you do resizing of a hash table that uses chain hashing now let's talk about resizing of a hash table that uses open addressing this is where things become a little more interesting with open addressing we know that it does not do it does not use any auxiliary data auxiliary data structure to place the collided keys instead it finds the empty slots from the hash table and tries to place the key there so in open addressing we always we know that when we are deleting see insert would be straightforward you because there is no extra auxiliary space you cannot do any optimization you literally have to iterate through all the keys and put it into the new table there is no way out there is no way out you have to do that but let's talk about dilution did because basically deletion is where things become very interesting so not in open addressing we know that we always soft delete we always stop delete the element so that we can reach the keys further in the collision chain simple example let's say in my hash table i have keys in the order k3 k6 k1 ky k2 k4 k8 k7 and k4 k5 k2 and k4 have collided to index 2 right so first k1 is there then k5 then k2 then k4 then let's say deleted k5 now if i'm looking up for k4 i have to reach i have to go to index 2 and then move forward to the right then to the right then to the right to reach the k4 and which is where if i delete k5 i would not be able to proceed that is where i cannot make an empty slot out of it i have to do a soft delete right we talked about it in detail in in previous couple of videos but just to recap that's why we always do soft deletes in open addressing and this is where things become interesting because now because we are soft deleting the keys even soft deleted keys are making our lookups inefficient because because they are occupying the space in the table first of all then we have to go through them in order to look for the keys beyond that right so that is where even a soft deleted key with open addressing having a soft deleted key is also as expensive as having a key inserted in the table right so your deleted keys would also slow down your key lookups because they are occupying the space and you have to go through them in order to hunt for or in order to continue your search for further elements so how do we handle it a way to handle this is slight modification so we had our keys counter like we used to maintain a keys counter whose job would be to keep track so now instead of having one counter you have two counters so one length of array is already there but apart from that you would have two counters first is the keys counter which keeps track of active keys of your hash table right so these are the keys which are actually active in your hash table so you would be not counting soft deleted keys over here so which means whenever you are inserting a key you do this keys counter plus plus when you are deleting a key you do keys counter minus minus right and then you would have second counter called used counter whose job is to keep track of slots that are occupied it would consider or it would also consider the keys that are deleted so it would count them as well so which means that your used counter should be doing here you should like whenever you are inserting a key you would do used counter plus plus and when you are deleting a key you would not do not do anything because your keys is still being used right your key is still being used so that's why you would not do anything over here right so this way with keys counter you would know the exact number of active keys in your hash table while the used counter would say the exact number of slots that are occupied in your hash table with deleted keys or with the actual keys of your hash table so here what you'll do is instead of using your keys counter to main to measure the load factor you would use the used counter to find the load factor so now your load factor alpha is equal to the number of keys used or the number of slots used in your hash table divided by the total number of slots this means that we are accounting for the soft deleted keys as well right this is a slight change in the implementation part so let's see what happens when we do trigger and so your resize is triggered when you try to insert into it so insert key function similar but just your load factor function or your load the way your computing load factor changes instead of using keys count you're using used count divided by length of table to find a load factor for open addressing and then if it is greater than equal to 0.5 you trigger the resize right and remember when you trigger a resize you have to reset your used counter to be same as active counter because what you would do is when you are resizing the table you would only rehash the active keys and skip the deleted ones because you don't need to though those are soft deleted keys so when you resize your table you would be skipping your soft deleted keys and not needing it to be rehashed into the new new table right so given that after your insert keys are crafted so after the resizes happen you would have to reset your counter of used count to be same as active count right similarly upon deletion you would you might want to shrink your table so while shrinking the table we only rehash the active keys and skip the deleted ones exact same how we do it with insert same we do it with delete right so here also whenever you delete a key you would recompute your load factor to be equal to the used count divided by the length of the table and then if it is less than 0.125 it is 1 by eight you would do a resize and shrink the table to half and when you do resize you would rehash all the keys rehash all the active keys into the new hash table and then reset the counter so that you start a fresh with used code is equal to active part because you have skipped the soft deleted keys and these are the pointers that you have to take care of while implementing resize when you are using open addressing as your probing scheme whereas your collision resolution scheme right and that is it this is how you would think about like when you are practically implementing your resize operation you have to think about these factors with chain hashing you can do two ways to do it with open addressing these are pointers that you would have to keep track of to ensure that you are not introducing any bug in your code and that is it from me in this ninth video of the hash table internal series i hope you found it amusing i really hope you try to build your own hash table it's really easy but it's super fun to do it right so yeah that's it from me for this video if you guys like this video give this video a massive thumbs up if you guys like the channel give this channel a sub i post three in-depth engineering videos every week and i'll see in the next one thanks [Music] you