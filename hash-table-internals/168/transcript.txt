linear probing is one of the simplest and the most intuitive ways of handling hashtable collisions and it is based on a technique called open addressing in this video the fourth of this hash table internal series we take a detailed look into linear probing understand what it is how hash table operations happen with linear probing learn why it is so simple yet so efficient and conclude with looking at two challenges that come with adopting it but before we move forward i'd like to talk to you about a course on system design that i have been running for over a year now the course is a cohort based course which means i won't be rambling a solution and it will not be a monologue instead a small focused group of 50 60 engineers every cohort will be brainstorming systems and designing it together this way we build a solid system and learn from each other's experiences the course to date is enrolled by 600 plus engineers spanning 9 cohorts and 10 countries engineers from companies like google microsoft github slack facebook tesla yelp flipkart dream 11 and many many many more have taken this course and have some wonderful things to say the coolest part about the course is the depth we go into and the breadth we cover we cover topics ranging from real-time text communication for slack to designing our own toy load balancer to greek business live text commentary to doing impressions counting at scale for any advertisement business in all we would cover roughly 28 questions and the detailed curriculum split week by week can be found on the course page which is linked in the description down below so if you're looking to learn system design from the first principles you will love this course i have two offerings for you the first one is the live cohort business which you see on the left side and the second one is the recorded course which you can see on the right side the live cover based course happens every two months and it will go on for eight weeks while the recorded course contains the recordings from one of the past cohorts as is if you are in a hurry and want to binge learn system design i would highly recommend you going for the recorded one otherwise the live code is where you can participate and discuss things live with me and the entire cohort and amplify your learnings the decision is totally up to you the course details prerequisites testimonials can be found on the course page at pittsby dot me slash master class and i would highly recommend you to check that out i put the link of the course in the description down below so if you are interested to learn system design go for it check out the link in the description down below and i hope to see you in my next cohort thanks so conflicts are inevitable as we are trying to map a large range of application keys into a smaller hash table in the previous video we looked at what open addressing is and how it tries to resolve conflicts in hash table while accommodating all the keys that come in there are multiple ways of implementing the probing function and one of them is linear proofing which we will take a detailed look today right so just to reiterate what is a probing function first of all what is open addressing open addressing tries to solve this problem that whenever there is a collision in the hash table it tries to find an available slot from the hash table itself it does not use any auxiliary data structure like a linked list or a tree it is trying to utilize the space of the hash table as much as it can right without using an auxiliary data structure and probing function it is it tries to place the key it tries to basically find the next available slot it basically a good probing function generates a sequence of permutation of all the indexes of your hash table and we try each one of them one by one and then the first available slot we find we try to place it right so every single technique that falls under open addressing is just about defining this probing function right today when we look at linear probing we'll see what a probing function for linear probing exactly looks like so the idea of linear probing is extremely simple what it does is it says that if i face a collision let's say if i'm facing a collision at index 3 right and i'm trying to insert a particular key the hash function when i passed it it gave me the index 3 right so i'm going to the index 3 trying to check if it is occupied or not if it is not not occupied i'll insert it right so if let's say this index 3 is occupied by some key then what we would do is we would go to the image at right and see if index 4 is available if 4 is not available we'll go to 5 and then 6 and then eventually let's say we go to 7 which is available so our key gets inserted into index 7 right this is linear probing and mathematically it can be very simply written as my probing function is a function of key and an attempt i it is not an index it is an attempt so my probing function h of my probing function k comma i is equal to h of k as in hash of the key k plus i mod m right so every attempt it starts from 0 1 2 3 4 and so on and so forth it very beautifully fits one after another so whatever the hash index is it's not that everyone would start at 3 we like the keys would be hashed at random locations but if that is occupied we would move to the right to find the first available slot right now what happens when we go to the extreme right we circle back to index 0 and resume our lookup and like always open addressing has this problem where if you i have filled all the slots of your hash table then you cannot insert any more keys and obviously that limitation holds with open addressing in general but this is the idea of linear probing it's extremely simple to implement right now let's quickly take a look into how hash table operations work with linear probing so adding a key let's say i have key k1 k2 i have key k1 k2 and k3 all collided at index 2. so when i pass k1 k2 and k3 all of them the hash function spits out 2 right so all of them are trying to get inserted into my hash table at index2 k1 got inserted at index 2 because the index 2 was open was empty then i tried to insert k3 k2 was empty then it moved to 1 to the right so then k3 got placed at 3 then k2 came in k2 got placed at 4. now when i'm trying to insert k4 it will get indexed to 2 2 is filled it will go to 3 3 is filled it will go to 4 4 is filled it will go to 5. 5 is empty so k4 is slotted at five this is a linear lookup that you are making one after another to see the first available slot and put it there right now let's take a look at another operation key lookup how does key lookup look like so what we do is we invoke the probing function we pass the key through the hash function and when we pass the key through the hash function we get a slot right we get an index we go to that index and check if the key is there if the key is there we return if the key is not dead we start iterating from that one by one until we find the key if we find the key valin could be return right let's say during the traversal if we encounter an empty slot if i encounter an empty slot it means that there would not be any key that has collided on that address like the key that you are looking for has not collided on there is not yet present in the hash table otherwise that would not have been an empty slot right so if you discover or if you encounter an empty slot while traversing you have to stop the iteration right otherwise unless you find any key you would continue iterating through the array to find the key of your interest and eventually you will find it if it is there in the hash table right this is how key lookups work right and obviously you would have foreseen it the worst case of this is you are iterating the entire hash table the entire big range of array in case every single slot is filled you will be iterating through the entire hash table to look up for a key right and that is a problem that is the worst case of this implementation but in most cases your hash table is large enough and you would have far far empty slots in between and that would you don't need to iterate the entire table whatsoever you would encounter an empty slot much before you iterate the entire table right but that is the worst case that you should be aware of right now the final operation of my hashtable deleting a key deleting a key has to be a soft delete previous video we discussed why soft deletes are important for open addressing here also we have to do soft delete because if we are not doing soft delete if we do hard delete what would happen is it would create an empty slot so it never move forward for the collided key of that same for the same index so that is where you would always need to do hi uh you'd always need to do soft delete so whenever a key is there that you needs to be removed or that needs to be deleted from the hash table and you are using linear probing you would start from that index move forward until you locate the key and soft delete that key right so that you by looking up you can continue your iteration moving forward right this is how the three operations the three key operations of a hash table would look like with linear probability right now let's take a look at how why linear probing is so fast simple we all agree it's like going through the hash and then moving forward for forward it's really simple but why is it so fast right now it's fast would you think hey i am linearly traversing the array isn't it slow you think that it is slow but the best part here is because you are linear because you are linearly traversing through the array you are using locality of reference now what happens going into operating system details right but when you are accessing any memory location in your ram in your main memory when you are trying to locate whenever you are trying to access any location when a system call goes to fetch that particular location what would happen um your operating system works at a block level it might be a 4kb block like your disc typically has 4 kb book let's say it's 1 kb block for your ram it takes that 1 kb block and puts it into cpu cache right so because the value is accessed by what by accessed by your cpu so when the request goes to access a ram or a particular location in the ram a block is read from the ram and it is cached on the cpu right so now what happens when you are traversing through the array one after another you are you might already be hitting the cache the cpu cache you might not even have to go to the main memory to read it because you are constantly editing one after another now let's see i'll give a i'll give a very concrete example let's say you were iterating on the array a and your hash function splitted out 2 for a particular key so when you accessed a of 2 right a of 2 3 4 and 5 all four might be brought up in the cpu cache right now let's say you saw collision at 2 you are moving to 3 when it is trying to access a of 3 it is already there in the cpu cache it would not have to do a it would not have to do a memory lookup it could will already have the data in the cpu cache so it would be very fast in iterating that is where linear probing very beautifully exploits the locality of reference though your os your cpu hardware is anyway caching those things and it is very beautifully leveraging it which is where linear probing gives a very solid performance when it comes to handling collision keys right and looking up them and deleting them it's really fast right now you'll think and there is a one there is one very strong claim which says that linear probing gives a constant time performance for average cases it gives constant time performance it's a very solid like it's a big claim because you see that the worst case is always moving forward for forward eye training through the entire array why how can it even say that it would give a constant time performance because because in an average case there would be far fewer collisions you would use a hash function that is random enough that is distributed across your entire space right so in most cases the collisions would be far fewer which means that let's say on an average per slot there are five collisions right when you are accessing one of the key but anyway bringing all of them in a cpu cache so when you're hydrating it is literally doing a cpu lookup you don't even have to go to your ram to access it right which is why on an average it gives you constant time performance it's a big claim but that's how and that's how hash functions are supposed to work you cannot expect every every single one of them colliding to the same place right but the worst case is still painful when entire hash table is filled and you have to iterate all of them right that is there but average case you should not be even worrying about it gives you constant time performance and there is a paper that proves it's give you it gives you constant time performance wikipedia page reference section basically check that out if you wish how they have proven it right now we'll conclude the final part challenges with the university obviously grass is not always green challenges with linear problem challenge number one a bad hash function would make linear probing very inefficient right because it would have to do like let's say assume that a bad hash function for example every single key is hashing on to the same value so let's say if you have a hash table of size eight every single one of them is hashing to the same location too then eventually your hashtable fill out and because it's a poor hash function you would always have to do linear lookup across the table so a bad hash function would ruin your linear probing right that is where it is very important to use a good hash function which nearly uniformly distributes the hash space or the hash output across your entire range right that is really important which is why with linear probing murmur hash is very much preferred because it's really very random like it looks near uniform the way it distributes it it's beautiful right so that's where linear probing has its disadvantage that it relies heavily like a poor hash function will ruin the entire experience right so that is where picking a good hash function is very important second limitation is really important it's really fun linear probing suffers from clustered collisions what do i mean by that so for example what would happen over here is let's say i have key k1 k2 and k3 and k1 hashes to index 2 k2 hashes at index 2 k3 hashes to index 3 right so what would happen if i'm trying to insert k1 it would go to index 2 the slot is empty k1 sits there and k2 also hashes to index 2 k2 will go to index 2 will see the slot is occupied it would go to index 3 and sit k3 hashes to index 3 it would say array but index 3 is already occupied by k2 so it will go to k4 so here you see you are forming a clustered collision where because of one because of a prior key spilling over or having having large number having collisions it is affecting the key sitting nearby right so you had a collision on k2 so then k3 also got impacted because k1 and k2 occupied the slot of k3 right so this is where you see a lot of clusters being form of collided keys which are impacting each other somewhat the other way right plus a bad function if it tries or if it uh places or if it generates localized hashes for example if you're having a range from 0 to 100 but your hash function is creating or is basically producing values which is really clustered in the range of let's say 10 to 20 right so then all the keys are put into this same 10 to 20 slot and then they spell and they are actually spillover across the table then what would happen is you are unnecessarily seeing large number of collisions in a small space and then unnecessarily you have to do linear lookup so that is where again uniform hash function would make all the difference but it would you almost nearly uniformly distributes your key across the entire hash table right so just to reiterate on the clustered collision first is when in a smaller space of keys or a smaller range where a lot of keys get collided or they get hashed you would have to do spillover and it would be displacing the other keys now when i say displacing it does not mean it would move the other case but like in this example k3 would have been indexed at location 3 but because k2 already held index 3 it would the k3 had to move to 4 and this is what is catastrophic right so that is where if your hash function is creating a clustered is generating a clustered output somewhere in the range like it's occur although you have a big range but if your hash function is only creating values in in clusters and which is very common to see with poor hash functions then you are seeing a lot of clustered collisions and then eventually the problem transfers into a linear lookup problem rather than a hash table lookup problem right this is a big problem with linear hashing that is why again a good uniform hash function is very important right otherwise it would you are you are just converting your hash table into a linear lookup which is very poor right okay that's it that's it about uh linear lookups the idea was to go in depth of linear probing no not not about linear cup but i have a linear probing the idea was to go in depth about linear probing help you understand the challenges and the advantages and why it is so fast why as it leverages cpu cache and whatnot i hope you learned something new uh this was the fourth video in this hashtable internal series i'm planning to create much more so if you guys like this video give this video a thumbs up if you guys like the channel give this channel a sub i post three in-depth engineering videos every week and i'll see in the next one thanks [Music]