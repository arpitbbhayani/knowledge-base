it's so powerful, it spans so many use cases, the core idea being we want to store application level key value pairs in a data structure and all the accesses would be key based.
i can place any type of value against that particular key right.
in the hash table we earlier only used to store keys, but now we would also need to store the value as well.
and in an integer hash key, which is when i pass the key through the hash function, i get in the range of 0 to 2, raised to power 32, that hash key i would store so that i don't have to recompute the hash every time all over again, and i'll store a white star value so that i can hold any type of value against this particular key.
we would need to know that, hey, for a particular key, i get the hash value.
so that is where, even after we reached the location in the hash table, we would need to do a key comparison, which is where we would need to accept a custom key comparator while we are setting up a hash map and this key comparator would take two keys or two void pointers and then it would in its responsibility of the application developer to pass the key comparator function, not inter, not implementation of a hash map.
all the information possible- key competitor function- needs to be passed by the developer, right?
second implementation detail is when we delete a key from the hash table, it may be our responsibility to clean them up.
it might be the last reference of the key comma value in our hash map, which is where to have a very robust implementation, we would need to also accept the destructor function: the destructor function for key and destructive function for value.
for example, if you are building or using a language that supports manual memory management and if that is the final reference of it, so then if the destructor function is passed, we would be invoking it when we delete the key permanently, right?
all operations are key based and this is a very important insight because that is where the comparator function we never accept.
this is really interesting that when we are, if a key exists and if i'm trying to insert a new key, we cannot just discard in the hash set implementation, we discard it.
we cannot just discard a key that already exists in the hash map just because, like.
so overall properties of hashmap would be the array of linked lists that it is holding, that the size of the array, the number of keys that it has right.
this six things that it would need while setting up a hash map right, the overall array, the size of the array, the number of keys that it's there, the comparator function for the key, the destructor function for the key and the value.
if passed, we would be invoking it when we do a hard delete right, and given that it is chaining upon collision, every array, no, or every element of an array is just a pointer to the linked list.
so destructor functions of value and key: very important when you are doing manual memory management.
so lookup function would return the value for the provided key, or null if it does not exist.
are two keys, two exact same keys in my hash map, right?
so that is where we cannot just blindly insert whatever we get at the head of the linked list, because problem right, you cannot have two keys, uh, in your hash map.
so that is where approach number one: if the key is present, we do not insert at all, but we update.
so if you'd want to maintain that that most recently put keys are very likely to be accessed, it's better that we delete and we reinsert the key with the new value.
right approach number three is, if the key is present, we insert the key without deleting.
so the three approaches to implement a insertion in a hash map and it depends on what your application needs, right?
so, with open addressing, we are not using any auxiliary data structure like link list that we did with the chained approach, but we would be leveraging the free slots present in my hashtag, in my array already.
okay, so your hash map would, overall, have the array that is, holding the size of the array, the used slots of the array and active keys count.
we already have a key comparator function right now.
implementation detail: during insert, lookup and delete, when we find the matching hash key.
we need to explicitly compare the key to check its existence, because it might be possible that you inserted a key but you are deleting some other key, but that other key does not exist in your hash map.
which is where it's very important to, when you reach to the location in the hash table, you do an explicit key comparison to ensure that you are deleting the key that you are intended to right.
that's why key competitor function- really important for this implementation right.
so explicitly comparing the keys is very important and not just do a void, start a pointer: equality check, actual value comparison, actual key comparison needs to be there, right.
second, implementation detail: destructors should be invoked only when we are hard deleting the key, for both key and value.
if provided so here, what would happen is, given that with open addressing we are always triggering soft deletes, we would not invoke destructor when we are doing soft deletes, when we do hard delete, which means when we resize the hash people, be it growing or shrinking, that's where we would be not copying the soft deleted keys.
when we are doing hard delete of the key and the value, right and both.
the destructor function needs to be invoked if provided right.