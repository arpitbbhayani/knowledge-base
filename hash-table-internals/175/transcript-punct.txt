so maps and dictionaries are amazing, but how are they implemented? in this 11th video of this hashtable internal series, we take an in-depth look into the implementation of maps using hash tables, popularly called as hash maps. we will go into the implementation details and performance tunings of map and see how they are built on top of tables having chaining and on top of tables having open addressing. but before we move forward, i'd like to talk to you about a course on system design that i have been running for over a year now. the course is a cohort based course, which means i won't be rambling a solution and it will not be a monologue. instead, a small, focused group of 50- 60 engineers every cohort will be brainstorming systems and designing it together. this way, we build a solid system and learn from each other's experiences. the course to date is enrolled by 600 plus engineers, spanning nine cohorts and 10 countries. engineers from companies like google, microsoft, github, slack, facebook, tesla, yelp, flipkart, dream 11 and many, many, many more have taken this course and have some wonderful things to say. the coolest part about the course is the depth we go into and the breadth we cover. we cover topics ranging from real-time text communication for slack to designing our own toy load balancer to qrik buses. live text commentary to doing impressions counting at scale for any advertisement business. in all we would cover roughly 28 questions and the detailed curriculum, split week by week, can be found on the course page, which is linked in the description down below. so if you're looking to learn system design from the first principles, you will love this course. i have two offerings for you. the first one is the live cohort discourse which you see on the left side, and the second one is the recorded course which you can see on the right side. the live code base course happens every two months and it will go on for eight weeks, while the recorded course contains the recordings from one of the past cohorts, as is. if you are in a hurry and want to binge learn system design, i would highly recommend you going for the recorded one. otherwise, the live code is where you can participate and discuss things live with me and the entire cohort and amplify your learnings. the decision is totally up to you. the course details, prerequisites, testimonials can be found in the course page at binary dot me slash master class, and i would highly recommend you to check that out. i put the link of the course in the description down below. so if you are interested to learn system design, go for it. check out the link in the description down below and i hope to see you in my next cohort. thanks, so hash maps are amazing data structure. it's so powerful, it spans so many use cases, the core idea being we want to store application level key value pairs in a data structure and all the accesses would be key based. for example, if i am storing a as a key and value as apple, b as key, value as ball, c for cat, d for dog, i'd want to do lookups by key, right. so key and value both has application context that i can place any type of key. i can place any type of value against that particular key right. here all operations are key based. value is just there. so when you are retrieving, you would retrieve the value. but overall all operations would be: keep. so, given a key, get me the value, put a key comma value, look up a particular key right and, we're sorry, basically delete a key as well. right, so all the operations are key based, but we are. we would also want to place values in that. so here, going into the implementation detail. so what do we need to store in the hash table? in the hash table we earlier only used to store keys, but now we would also need to store the value as well. so what we would store is we would store something called as a pair, and the pair would be a void star key so that we can support any type of key. and in an integer hash key, which is when i pass the key through the hash function, i get in the range of 0 to 2, raised to power 32, that hash key i would store so that i don't have to recompute the hash every time all over again, and i'll store a white star value so that i can hold any type of value against this particular key. this is what we would be storing in our hash table implementation detail. so, given that we are supporting a generic key type which is white star, how would we compare two keys? we would need to know that, hey, for a particular key, i get the hash value. i go to that location. it might be possible that there might be some other key. some other key which is not yet inserted in my hash table got hashed into that same location. then how would i know that that is the exact key. so that is where, even after we reached the location in the hash table, we would need to do a key comparison, which is where we would need to accept a custom key comparator while we are setting up a hash map and this key comparator would take two keys or two void pointers and then it would in its responsibility of the application developer to pass the key comparator function, not inter, not implementation of a hash map. so hashmap will be very agnostic, would be very generic. all the information possible- key competitor function- needs to be passed by the developer, right? okay, point number one. second implementation detail is when we delete a key from the hash table, it may be our responsibility to clean them up. it might be the last reference of the key comma value in our hash map, which is where to have a very robust implementation, we would need to also accept the destructor function: the destructor function for key and destructive function for value. for example, if you are building or using a language that supports manual memory management and if that is the final reference of it, so then if the destructor function is passed, we would be invoking it when we delete the key permanently, right? so that is where this micro implementation data is really important to build a robust implementation of a hash map. otherwise you would have a memory leak all over again. okay, so here a key thing: hash map. we never care about the value, we are just storing the value against the key. all operations are key based and this is a very important insight because that is where the comparator function we never accept. we never, we, we never wanted a value comparator function. we only wanted key comparator function. right, value is they're just there, white star. we are just placing the pointer there. that's it right. implementation detail. so, putting some key, like with hash map, with hashtags. this is really interesting that when we are, if a key exists and if i'm trying to insert a new key, we cannot just discard in the hash set implementation, we discard it. but here, if we are trying to put the same key value or same key again with a different value, the value should be replaced. this is really important. we cannot just discard a key that already exists in the hash map just because, like. so that is where the updation needs to kick in, right, and this goes into the implementation details of it, right, okay, now let's take a look at how do we implement hashmap with chaining right, with the hashtables having chaining. so overall properties of hashmap would be the array of linked lists that it is holding, that the size of the array, the number of keys that it has right. the comparator function, the destructor function for the key, the distorter function for the value. this six things that it would need while setting up a hash map right, the overall array, the size of the array, the number of keys that it's there, the comparator function for the key, the destructor function for the key and the value. destructor functions are optional. if passed, we would be invoking it when we do a hard delete right, and given that it is chaining upon collision, every array, no, or every element of an array is just a pointer to the linked list. we would have the collision linked list over here where every node of this linked list would have four elements now. first is. then integer 32 hash key, so that we avoid recomputation again and again. white star key: that would help us hold any type of key. void star value: that would help us hold any type of value and struct node star next, which is pointer to the next node in the linked list. a classic linked list implementation, just changes from the hashtag side. we are also storing value pointer over here, not the actual value but the pointer to the value, so that we only require four bytes of memory to hold it right. so destructor functions of value and key: very important when you are doing manual memory management. if provided by the developer, if provided by the user, we would be invoking it when we do a heart delete. right implementation detail for hashtable training. so lookup function would return the value for the provided key, or null if it does not exist. so instead of having a separate function that checks the existence of the key and doing something around that, we can just have a function called lookup whose job is to, given a key, give me the value. if the key exists, the value is written. if the key does not exist, it returns a null. it's a very standard implementation but it helps us avoid redundant implementation of like having a contains function and having a lookup function, right. second implementation detail. now this is where it goes a little deeper. to avoid duplicates, we always have to check and insert, right, so we don't want to have two elements. are two keys, two exact same keys in my hash map, right? that should not be possible. so that is where we cannot just blindly insert whatever we get at the head of the linked list, because problem right, you cannot have two keys, uh, in your hash map. so that is where approach number one: if the key is present, we do not insert at all, but we update. right, we do not insert at all. that is approach number one. so that's where you would do a lookup. you'd get a value pointer, you'd get the node pointer and then you'll do an update. second, if the key is present. now this is an interesting approach. if the key is present, you delete the old key and reinsert. you would say, but why, if the key is already there, i can simply go and update the value. right, why would someone delete and reinsert? very interesting advantage of that: what this would do is we know that we are always inserting at the head of the list, which means that, upon iterating, the recent keys would be much quicker to find. so imagine if this is more like a uh, i'm reading my own rights kind of use case where i'm very, i'm very likely to read the recently written keys. i would not have to. i treat the entire list. i can just go to the head. i'll find this key in the first, in the first couple of places. so if you'd want to maintain that that most recently put keys are very likely to be accessed, it's better that we delete and we reinsert the key with the new value. think of it like caching, like like quicker access of key value pair. right approach number three is, if the key is present, we insert the key without deleting. without deleting, which means there would be multiple keys with the same, with the same name, right? so if i'm inserting k1 with v1 and then i'm inserting k1 with v2, both of them would exist in the linked list, like k1, v1 and another node that would be 1, v, 2, both of them would exist. we are trying to optimize for fast writes. right, because we do not have to check and compare and what not. we're directly inserting. whatever we get into the part, we're directly inserting it. as is. this is very space inefficient because multiple nodes having the same key inefficient, but we get super fast insert. so if your workload is right, heavy when you need very fast inserts, then you might want to go for this option. but with this what happens? the delete becomes expensive because now when you're deleting a particular key, you would not just have to delete the first instance of the key that you find. you'll have to go through the entire linked list and find all the instances of the key and then trigger a delete of all of them. delete to become expensive. and similarly, with lookup you, it doesn't become expensive, but you have to ensure that in lookup you would always return the first match that you got right and that's by default what you do, but just being explicit about it, right? so the three approaches to implement a insertion in a hash map and it depends on what your application needs, right? okay, now let's talk about implementing hashmap with hash tables and, uh, implementing hashmap with hashtables having open addressing. so, with open addressing, we are not using any auxiliary data structure like link list that we did with the chained approach, but we would be leveraging the free slots present in my hashtag, in my array already. so your hashmap will, overall, have these attributes: the array that is holding array. second, the number of keys that are there in the array. third are the number of used slots and fourth are the number of keys. a, just a small mistake. the second one is the size. okay, so your hash map would, overall, have the array that is, holding the size of the array, the used slots of the array and active keys count. so use slots like with uh, open addressing. we are doing so, we are always doing. soft deletes and even deleted elements add up to the performance problem right. so that is where our load factor would not be computed on the number of active keys but on the number of used slots. in previous couple of videos i've discussed this in detail. when we're discussing about performance of a hash table, if you're not sure, go check that out right, we'll go into real depth of it on how it is implemented right. and apart from active number of active keys would have the comparator function, the key comparator function, destructor function for the key and the destructor function for the value. right, each slot or each element of the array would be a slot and slot. very standard implementation with open addressing is it would have a boolean is empty, a boolean is deleted if the which tells if the slot is empty or the slot is soft deleted. then an n32 hash key so that we avoid recomputation of hash key. then avoid star key to hold the actual key of generic type void star value to hold value of generic type right to compare the key. we already have a key comparator function right now. implementation detail: during insert, lookup and delete, when we find the matching hash key. we need to explicitly compare the key to check its existence, because it might be possible that you inserted a key but you are deleting some other key, but that other key does not exist in your hash map. you are still reaching the same index and then on without doing key competition. if you delete it, you would be accidentally deleting some other key, so that's bad. which is where it's very important to, when you reach to the location in the hash table, you do an explicit key comparison to ensure that you are deleting the key that you are intended to right. so very important to do that. that's why key competitor function- really important for this implementation right. so explicitly comparing the keys is very important and not just do a void, start a pointer: equality check, actual value comparison, actual key comparison needs to be there, right. second, implementation detail: destructors should be invoked only when we are hard deleting the key, for both key and value. if provided so here, what would happen is, given that with open addressing we are always triggering soft deletes, we would not invoke destructor when we are doing soft deletes, when we do hard delete, which means when we resize the hash people, be it growing or shrinking, that's where we would be not copying the soft deleted keys. that is where we would be invoking the destructor operation, because the reference should not be dangling and pointed here and where right. so that is where we would only trigger the destructor function. when we are doing hard delete of the key and the value, right and both. the destructor function needs to be invoked if provided right. and these are some micro implementation details of hash map using hash tables, like really other implementations, pretty straightforward. but these are some things that we would definitely need to keep in mind when we are implementing our hashmap using hashtable having open addressing. so, yeah, that's it. that's it about those implementation details that you might need to take care of everything else, but i would highly recommend you to implement your own hash table and eventually implement your own hashmap. it's really fascinating to implement them. i hope this series was good. i hope you learned something new in depth about the most common data structure that we use day in and day out- hash tables. and this was the 11th video in this hash table internal series where we talked about implementation of hashmap using hash table. and yeah, that's it. that's it for this video. if you guys like this video, give this video a massive thumbs up. if you guys like the channel, give this channel a sub. i post three in-depth engineering videos every week and i'll see in the next one. thanks again. [Music] you.