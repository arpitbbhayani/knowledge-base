[
  {
    "id": 188,
    "topic": {
      "id": 0,
      "uid": "distributed-systems",
      "name": "Distributed Systems",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT1wfRQo2xrrst2SGremT_qd",
      "bgcolor": "#DDF0FF",
      "themecolor": "#1798FF",
      "course_url": null
    },
    "yt_video_id": "tV3EQNgpZKI",
    "title": "Distributed Shortest-Path Bellman Ford Algorithm in Distributed Systems",
    "description": "To keep our distributed system efficient and performant, we have to ensure that the messages that are sent within the network take up the most efficient path. We may think ... network ... graph ... efficient path ... shortest path ... so can we not use our graph algorithms?\n\nWe cannot use them directly because this is distributed system and there is no single node that holds the information about the entire topology. Every node simply knows about the incident edges, and hence we have to take baby steps while devising a solution.\n\nIn this video, we take a look into a variant of the famous Bellman-Ford shortest path algorithm and see how it operates in a distributed setting.\n\nOutline:\n\n00:00 Agenda\n03:07 Need for Shortest Path in Distributed Systems\n06:59 Bellman-Ford Shortest Path in Distributed Systems\n14:35 Complexity Analysis",
    "img": "https://i.ytimg.com/vi/tV3EQNgpZKI/mqdefault.jpg",
    "gif": "https://media.giphy.com/media/1k5k3J5K3BywQOrpNA/giphy.gif",
    "duration": "17:5",
    "view_count": 326,
    "like_count": 17,
    "comment_count": 4,
    "released_at": "2022-09-02",
    "gist": "Determining the shortest path in a distributed system is an important problem to address and it finds its application across multiple use cases like\n\n- delivering messages to a node efficiently\n- efficient routing of messages\n\nA key point to consider here is the fact that \"shortest\" is not only about the distance, but it can also be about the congestion, time, cost of communication lines, cable infra, and much more.\n\n## Problem statement\n\nIn a distributed network, where nodes are connected via paths/edges having some weight assigned, find the shortest path from a specific source to all the nodes\n\n## Bellman-Ford Algorithm in Distributed System\n\nIn this gist, we discuss a synchronous approach which means every node moves forward in the algorithm in sync. There are ways to achieve this, but the implementation of synchronous behavior is out of the scope of this gist.\n\nBecause it is a distributed network no node knows the entire topology and weights. They just know\n\n- total number of nodes\n- their immediate neighbors, and\n- the weights of the edges incident on it.\n\nEvery node keeps track of `dist` which holds the shortest distance to it from the source `i0`. Initially, `dist` at `i0` will be `0` and `dist` at all other nodes will be `inf`.\n\nAt every round, all the nodes will send their `dist` across all of their outgoing edges to their neighboring nodes. Every node `i` upon receiving an incoming `dist` from its immediate neighbor `j` compares\n\n- its own `dist`\n- incoming `dist` + `weight(i, j)`\n\nafter comparing, if the incoming distance plus the weight of the connecting edge is smaller than its own `dist` it means that the distance from `i0` to the current node could be shorter and hence, the node updates the `parent` suggesting that the shortest path from `i0` to `i` goes through `j`.\n\nAfter `n - 1` rounds, the `dist` at every node will contain the shortest distance to it from source `i0`, and the `parent` will contain one of its immediate neighbors that lies in the shortest path.\n\n## Complexity Analysis\n\nWe require `n - 1` rounds to complete the algorithm, the time complexity of Bellman-Ford Shortest Path in Distributed System is `O(n)`. At every round, every node sends `dist` message across all of its edges to its immediate neighbors, the communication complexity becomes `O(n x |E|)`.",
    "notes_gd": "https://drive.google.com/file/d/1IG1MdH-DALxcbx3rtZ25KHxUwSbrwTfo/view?usp=sharing",
    "slug": "distributed-shortest-path-bellman-ford-algorithm-in-distributed-systems"
  },
  {
    "id": 187,
    "topic": {
      "id": 0,
      "uid": "distributed-systems",
      "name": "Distributed Systems",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT1wfRQo2xrrst2SGremT_qd",
      "bgcolor": "#DDF0FF",
      "themecolor": "#1798FF",
      "course_url": null
    },
    "yt_video_id": "PTlYBBqAYXA",
    "title": "Synchronous Breadth First Search Algorithm to power broadcast in Distributed Systems",
    "description": "In a distributed system, what if one of the nodes wants to efficiently broadcast a message in the network?\n\nThe situation is not as simple as it sounds, because there is no single node that holds the information about the entire topology; they just know about their immediate neighbors.\n\nIn this video, we take a look into an algorithm that powers synchronous Breadth-First Search traversal in a distributed setup, understand its time and communication complexity, and talk about its applications.\n\nOutline:\n\n00:00 Agenda\n02:36 Breadth-First Search and Distributed Systems\n06:26 BFS Distributed Algorithm\n13:58 Termination of the Algorithm\n18:57 Applications of BFS in Distributed Systems",
    "img": "https://i.ytimg.com/vi/PTlYBBqAYXA/mqdefault.jpg",
    "gif": "https://media.giphy.com/media/26n6WywJyh39n1pBu/giphy.gif",
    "duration": "21:46",
    "view_count": 428,
    "like_count": 22,
    "comment_count": 2,
    "released_at": "2022-08-31",
    "gist": "Breadth First Search is a critical algorithm in Distributed systems as it powers key features like\n\n- Broadcast in minimum time\n- Building topological understanding\n- Topological stat like Diameter\n\nIn this gist, we discuss a synchronous approach which means every node moves forward in the algorithm in sync. There are ways to achieve this, but the implementation of synchronous behavior is out of the scope of this gist.\n\n## Output of BFS\n\nThe output of this traversal is a Breadth-First Directed Spanning tree that covers all the nodes but a subset of edges. This output is important because we can use this spanning tree as a foundation for other applications and algorithms.\n\n## The algorithm\n\nThe node `i0` initiates the BFS and it sends the `search` message to its neighbors. The nodes can either be marked or unmarked. If marked, they are part of the spanning tree already.\n\nWhen an unmarked node receives the `search` message,\n\n- it marks itself\n- updates its parent to the node it received the `search` message from\n\nIn the next round, the nodes that received the message in the previous round participate, and send `search` messages to their neighbors, and the nodes receiving the messages do the needful.\n\nEventually, every node will be receiving the `search` message from some or the other node and will be part of the spanning tree.\n\n## Complexity Analysis\n\nTime taken to complete the BFS is proportional to the diameter of the network and the number of messages exchanged will be equal to the number of outgoing edges in the network.\n\n## Conveying the children\n\nWith the current algorithm, every node knows its parent in the spanning tree but every node also needs to know which of its neighbors are its children in the spanning tree.\n\nTo achieve this, each node has to respond to the `search` message with a `parent/non-parent` message that tells the node if it was chosen to be the parent or not. This way, every node will know its parent and children in the spanning tree.\n\n## Termination of BFS\n\nThe most important part of any distributed algorithm is its termination. How would the node know that BFS is done?\n\nThe approach we use is called Convergecast.\n\nThe idea is to respond to the search message only when it received responses from all its children. This ensures that the node initiating the BFS would receive the messages from its children only after all the nodes respond to their corresponding parents.\n\n## Applications\n\nAfter constructing the BFS Spanning Tree, we can use this constructed path to\n\n- do an efficient broadcast on the network\n- do distributed computation in the network",
    "notes_gd": "https://drive.google.com/file/d/1s39L6dNbDCN0xk_ZpyVKRf2a2OgZsCdr/view?usp=sharing",
    "slug": "synchronous-breadth-first-search-algorithm-to-power-broadcast-in-distributed-systems"
  },
  {
    "id": 186,
    "topic": {
      "id": 0,
      "uid": "distributed-systems",
      "name": "Distributed Systems",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT1wfRQo2xrrst2SGremT_qd",
      "bgcolor": "#DDF0FF",
      "themecolor": "#1798FF",
      "course_url": null
    },
    "yt_video_id": "4aeFQpuww4E",
    "title": "FloodMax algorithm for Leader Election in Distributed Systems",
    "description": "Leader Election is necessary to make Distributed Systems auto recover and remain autonomous.\n\nIn this video, we take a detailed look into a Leader Election algorithm called FloodMax that works on any network with any topology. We understand the runtime complexity of it and look at a couple of optimizations that make it efficient.\n\nOutline:\n\n00:00 Agenda\n02:25 FloodMax Algorithm\n08:45 Complexity analysis of FloodMax Algorithm\n09:31 Optimizations in FloodMax Algorithm",
    "img": "https://i.ytimg.com/vi/4aeFQpuww4E/mqdefault.jpg",
    "gif": "https://media.giphy.com/media/3o6nV90vn3oe6bUuIM/giphy.gif",
    "duration": "12:41",
    "view_count": 869,
    "like_count": 17,
    "comment_count": 0,
    "released_at": "2022-08-28",
    "gist": "Leader Election is a critical component in any distributed system. It enables the system to auto-recover from leader failures. When a leader node goes down, the Leader Election algorithm is triggered to elect the new leader.\n\nLeader Election should work with any topology and hence we take a look into an algorithm called FloodMax.\n\n## FloodMax Algorithm\n\nThe Flood Max Algorithm Flood Max works with a network that is arbitrarily connected. It assumes that every node is given a comparable UID that may be randomly allotted and every node knows the network's diameter.\n\n### The algorithm\n\nThe Flood Max algorithm is designed to elect the node with the maximum UID as the new leader and the core idea is to flood the network with the Max UID until the value converges.\n\nThe election process happens synchronously, which means every node moves forward in the algorithm in sync. There are ways to achieve this, but the implementation of synchronous behavior is out of the scope of this gist.\n\nThe algorithm stops after completing rounds equal to the diameter of the network. In each round, every node\n\n- sends the max UID it has seen to the connected nodes\n- updates the max UID it has seen so far after receiving messages from its neighbors\n\nAfter completing the `diameter` number of rounds, each node will have the max UID it has seen so far which will also be the global maximum; thus every node will know who is the leader of the network.\n\n### Complexity Analysis\n\nIt takes O(diameter) number of rounds to elect the leader and in each round the number of messages exchanged is equal to the number of edges, hence O(|E|); hence communication complexity is O(diameter x |E|).\n\n## Reducing Communication Complexity\n\nTo decrease the number of messages exchanged during the election, nodes can send the Max UID only when it changes. This would significantly reduce the messages exchanged across the network during leader elections.\n\nAnother optimization to reduce the communication is to NOT send the Max UID in the direction of the neighbor from which it was received.",
    "notes_gd": "https://drive.google.com/file/d/1yUZjPZoVKiKls7iof9Y-HF-9YsAoQpNN/view?usp=sharing",
    "slug": "floodmax-algorithm-for-leader-election-in-distributed-systems"
  },
  {
    "id": 185,
    "topic": {
      "id": 0,
      "uid": "distributed-systems",
      "name": "Distributed Systems",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT1wfRQo2xrrst2SGremT_qd",
      "bgcolor": "#DDF0FF",
      "themecolor": "#1798FF",
      "course_url": null
    },
    "yt_video_id": "mcKLQVmCsG4",
    "title": "TimeSlice algorithm for Leader Election in Distributed Systems",
    "description": "Leader Election helps our Distributed Systems auto recover without any human intervention and makes the system autonomous.\n\nIn this video, we take a detailed look into a Leader Election algorithm called TimeSlice that is extremely impractical but it still provides us great insight into a seemingly weird implementation.\n\nOutline:\n\n00:00 Agenda\n02:27 Introduction to the TimeSlice Algorithm\n05:21 The TimeSlice Algorithm\n11:03 Complexity Analysis of TimeSlice Algorithm",
    "img": "https://i.ytimg.com/vi/mcKLQVmCsG4/mqdefault.jpg",
    "gif": "https://media.giphy.com/media/26tnqkPaDXV7EzPAQ/giphy.gif",
    "duration": "14:3",
    "view_count": 262,
    "like_count": 15,
    "comment_count": 1,
    "released_at": "2022-08-26",
    "gist": "Leader Election is a critical component in any distributed system. It enables the system to auto-recover from leader failures. When a leader node goes down, the Leader Election algorithm is triggered to elect the new leader.\n\n## TimeSlice Algorithm\n\nTimeSlice algorithm for leader election is highly impractical, unbounded, yet an interesting algorithm to understand.\n\nThe algorithm assumes\n\n- each node has a UID that is a positive integer\n- the nodes are arranged in a virtual ring\n- each node knows its immediate neighbor to the right\n- each node knows the total number of nodes `n` in the network\n\n### The flow\n\nThe election proceeds in phases 1, 2, 3, and so on. Each phase consists of `n` rounds. Because the algorithm is synchronous, each node knows when the algorithm is proceeding with rounds and phases.\n\nIn phase `i`, nodes can only forward the message having the candidature of UID `i`. Hence, in phase `3`, a node will forward the message to the next node, only when it is having the candidature of UID `3`.\n\n## The flow\n\nIn phase 1, the node with UID 1 will send the message with its candidature across to the next node in the ring. If no such node exists, then no message is sent.\n\nThus, for `n` rounds within phase 1 there is void silence in the network. Then beings the phase 2.\n\nHence, we see that the messages will be sent across the ring only when the phase `i` beings where `i` is the smallest UID in the network. For all `(i - i) * n` rounds, there will be void silence in the network.\n\nWhen phase `i` begins the node with UID `i` will know that it is the new leader and it initiates the message and sends it to the next neighbor. For `n` successive rounds, the message is sent across the network and thus all `n` nodes know about the new leader `i`.\n\n## Complexity Analysis\n\nThe algorithm thus elects the node with the minimum UID as the new leader in just `O(n)` messages but takes time proportional to the `O(n*i)`.\n\nIf the minimum UID is a large integer, then the algorithm will take a longer time to elect the leader, and hence it is unbounded on the number of nodes in the network.",
    "notes_gd": "https://drive.google.com/file/d/1eZ2xCcikcZJ4krKj6pWuQtVvkFhCGAhL/view?usp=sharing",
    "slug": "timeslice-algorithm-for-leader-election-in-distributed-systems"
  },
  {
    "id": 184,
    "topic": {
      "id": 0,
      "uid": "distributed-systems",
      "name": "Distributed Systems",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT1wfRQo2xrrst2SGremT_qd",
      "bgcolor": "#DDF0FF",
      "themecolor": "#1798FF",
      "course_url": null
    },
    "yt_video_id": "inzQQm-kXCo",
    "title": "HS algorithm for Leader Election in Distributed Systems",
    "description": "Leader Election is important in every single distributed system out there as it enables us to auto recover from the failures.\n\nIn this video, we take a detailed look at a synchronous ring-based algorithm called the HS algorithm and see how it works on a bidirectional network in O(N logN) complexity.\n\nOutline:\n\n00:00 Agenda\n02:22 Introduction to HS Algorithm\n05:07 The HS Algorithm\n14:37 Halting the HS algorithm\n16:18 Key implementation detail of HS algorithm",
    "img": "https://i.ytimg.com/vi/inzQQm-kXCo/mqdefault.jpg",
    "gif": "https://media.giphy.com/media/fveKCnZRN7aOrtWNfj/giphy.gif",
    "duration": "18:55",
    "view_count": 432,
    "like_count": 24,
    "comment_count": 7,
    "released_at": "2022-08-24",
    "gist": "Leader Election is a critical component in any distributed system. It enables the system to auto-recover from leader failures. When a leader node goes down, the Leader Election algorithm is triggered to elect the new leader.\n\n## HS Algorithm\n\nHS algorithm is synchronous which means every node proceeds with the algorithm in sync. A key highlight of this algorithm is that it has communication complexity i.e. number of messages exchanged, of O(n long).\n\nThe algorithm works with the following assumptions\n\n- every node has a comparable unique ID\n- the communication between nodes is bidirectional\n- the nodes are virtually arranged in a circular ring\n- the nodes know their immediate neighbors\n\n### The flow\n\nEvery node participates in the election. To pitch itself, it creates a message with its UID and sends it to its immediate neighbors in both directions.\n\nTo reduce the number of messages required to elect the new leader, the nodes who knows their UID is smaller, they quickly drop out of the election.\n\nThe election proceeds in phases. In each phase `i`, the nodes participating in the election send their candidature to a hop distance of 2^i and wait for it to come back.\n\nEvery node along the path, upon receiving the message,\n\n- if the incoming is greater than its own, it forwards it\n- if the incoming is lesser than its own, it discards\n\nIf the node, receives its UID as an incoming message from both directions then it knows that it has the maximum UID in the 2^i neighborhood. With each phase, the hop distance increases exponentially.\n\nWith each phase, the nodes with smaller UIDs start to drop off from the election while still acting as the transmitter of the messages. After certain phases, there will be only one node remaining and that becomes the new leader.\n\n### Halting\n\nThe leader election in the HS algorithm halts when the node receives its probe message and thus it knows that it is the only one left and hence declares itself as the new leader.\n\nThe new leader creates the announcement message and relays it across the ring announcing itself as the new leader all the nodes locally update it and the election is concluded.\n\n### Key Implementation Detail\n\nThe message sent across during the election contains `<uid, hops, direction>`. It helps the node know\n\n- the number of hops the message has taken\n- stop forwarding when the hop count becomes 0\n- in which direction to reply",
    "notes_gd": "https://drive.google.com/file/d/1CHtYoRO_-LFEkX_R0xtTLPVsWfCO9jQd/view?usp=sharing",
    "slug": "hs-algorithm-for-leader-election-in-distributed-systems"
  },
  {
    "id": 183,
    "topic": {
      "id": 0,
      "uid": "distributed-systems",
      "name": "Distributed Systems",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT1wfRQo2xrrst2SGremT_qd",
      "bgcolor": "#DDF0FF",
      "themecolor": "#1798FF",
      "course_url": null
    },
    "yt_video_id": "NDBJr37dBzc",
    "title": "LCR algorithm for Leader Election in Distributed Systems",
    "description": "Leader Election is important for our distributed systems to auto recover from the failures.\n\nIn this video, we take a detailed look into a simple, naive, and intuitive distributed Leader Election algorithm called LCR, and understand how simple yet effective this algorithm can be.\n\nOutline:\n\n00:00 Agenda\n02:19 Introduction to LCR Algorithm\n05:07 The LCR Algorithm\n09:54 Halting the LCR Algorithm\n11:44 Complexity Analysis of LCR Algorithm",
    "img": "https://i.ytimg.com/vi/NDBJr37dBzc/mqdefault.jpg",
    "gif": "https://media.giphy.com/media/3orieZaGxNP4493CVy/giphy.gif",
    "duration": "14:20",
    "view_count": 744,
    "like_count": 58,
    "comment_count": 25,
    "released_at": "2022-08-22",
    "gist": "Leader Election is a critical component in any distributed system. It enables the system to auto-recover from leader failures. When a leader node goes down, the Leader Election algorithm is triggered to elect the new leader.\n\n## LCR Algorithm\n\nLCR Algorithm for leader election is the simplest and the easiest to understand and implement, and its variant can be seen in action in a bunch of distributed systems.\n\nThe LCR algorithm expects the network to have the following properties\n\n### Unique ID\n\nEvery node in the network has a unique identification - UID - that can be compared with other UIDs.\n\n### Virtual Circular Ring\n\nLCR also assumes that the nodes in the network are virtually arranged in a circular ring, and each node knows the node to its right in the ring.\n\nAlthough we want a circular ring, the nodes may be physically connected to other nodes through any topology. The ring mandate is purely virtual and can be maintained only for powering elections.\n\n### The Algorithm\n\nIn the election, every node participates to be the new leader. To participate, it creates a message having its UID and sends it to its neighbor.\n\nWhen a node receives a UID, it compares the incoming UID with its own, and\n\n- if the incoming is greater than its own, it forwards it\n- if the incoming is lesser than its own, it discards\n- if the incoming UID == its own, it declares itself as the new leader\n\nWhen a node receives its UID as an incoming message, it implies that the message survived the entire iteration leading to the assertion that the node has the highest UID in the network; and hence can become the new leader.\n\nThe new leader is then announced through another message passed across the ring.\n\n### Halting the algorithm\n\nHalting is one of the most important aspects of any distributed algorithm, as it can get tricky to know when to stop.\n\nLCR algorithm stops when the new leader initiates the message and announces itself. To announce, it initiates the `HALT` message and sends it across.\n\nThe node receiving the `HALT` message understands that the new leader has been elected and needs to stop participating in the election. The node updates its local state with this information and forwards the message to the next node.\n\n## Complexity\n\nEach node participates in the election and sends messages across the entire ring. Every node could potentially receive the message from every other node; the communication complexity, the number of messages shared, is thus O(n^2).",
    "notes_gd": "https://drive.google.com/file/d/1W-9SA2qEo6jKvxcM4iMi326R63lK7XVm/view?usp=sharing",
    "slug": "lcr-algorithm-for-leader-election-in-distributed-systems"
  },
  {
    "id": 116,
    "topic": {
      "id": 0,
      "uid": "distributed-systems",
      "name": "Distributed Systems",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT1wfRQo2xrrst2SGremT_qd",
      "bgcolor": "#DDF0FF",
      "themecolor": "#1798FF",
      "course_url": null
    },
    "yt_video_id": "oMhESvU87jM",
    "title": "Implementing Distributed Transactions using Two Phase Commit Protocol",
    "description": "Previously, we built a theoretical foundation of Distributed Transaction using the Two-Phase Commit protocol. In this video, we implement the Distributed Transaction locally and mimic the food delivery system locally. While implementing we understand how to make the individual operations atomic and the entire distributed transaction atomic. We address resource contention while guaranteeing a consistent user experience.\n\nOutline:\n\n00:00 Revising the Two-Phase Commit\n07:35 Designing Database Schema\n11:40 Defining API Endpoints\n12:24 High-Level Architecture and Request Flow\n19:55 No inconsistent data - Atomicity\n24:14 Code walkthrough",
    "img": "https://i.ytimg.com/vi/oMhESvU87jM/mqdefault.jpg",
    "gif": "https://media.giphy.com/media/RbDKaczqWovIugyJmW/giphy.gif",
    "duration": "39:24",
    "view_count": 2858,
    "like_count": 120,
    "comment_count": 23,
    "released_at": "2022-03-30",
    "gist": "Distributed Transactions are not theoretical; they are very well used in many systems. An example of it is 10-min food/grocery delivery.\n\nPreviously we went through the theoretical foundation for the Two-phase commit protocol; in this one let's spend some time going through the implementation detail and a few things to remember while implementing a distributed transaction.\n\n> The UX we want is: Users should see orders placed only when we have one food item and a delivery agent available to deliver.\n\nA key feature we want from our databases (storage layer) is atomicity. Our storage layer can choose to provide it through atomic operations or full-fledged transactions.\n\nWe will have 3 microservices: Order, Store, and Delivery.\n\nAn important design decision: The store services have food, and every food has packets that can be purchased and assigned. Hence, instead of just playing with the count, we will play with the granular food packets while ordering.\n\n## Phase 1: Reservation\n\nOrder service calls the reservation API exposed on the store and the delivery services. The individual services reserve the food packet (of the ordered food) and a delivery agent atomically (exclusive lock or atomic operation).\n\nUpon reservation, the food packet and the agent become unavailable for any other transaction.\n\n## Phase 2: Assignment\n\nOrder service then calls the store and delivery services to atomically assign the reserved food packet and the delivery agent to the order. Upon success assigning both to the order, the order is marked as successful, and the order service returns a 200 OK to the user.\n\nThe end-user will only see \"Order Placed\" when the food packet is assigned, and the delivery agent is assigned to the order. So, all 4 API calls should succeed for the order to be successfully placed.\n\nNegative cases:\n\n- If any reservation fails, the user will see \"Order Not Placed\"\n- If the reservation is made but assigning fails, the user will see \"Order Not Placed\"\n- If there is any transient issue in any service during the assignment phase, APIs will be retried by the order service to complete the order.\n- To not have a perpetual reservation, every reserved packet and delivery agent will have an expiration timer that will be large enough to cover transient outages.\n\nThus, in any case, an end-user will never experience a moment where we say that the order is placed, but it cannot be fulfilled in the backend.",
    "notes_gd": "https://drive.google.com/file/d/18q2ELr9n6GCemKbJ0aS7q7NyF7wX1kL9/view?usp=sharing",
    "slug": "implementing-distributed-transactions-using-two-phase-commit-protocol"
  },
  {
    "id": 117,
    "topic": {
      "id": 0,
      "uid": "distributed-systems",
      "name": "Distributed Systems",
      "one_liner": null,
      "youtube_playlist_id": "PLsdq-3Z1EPT1wfRQo2xrrst2SGremT_qd",
      "bgcolor": "#DDF0FF",
      "themecolor": "#1798FF",
      "course_url": null
    },
    "yt_video_id": "7FgU1D4EnpQ",
    "title": "Distributed Transactions: Two-Phase Commit Protocol",
    "description": "Distributed Transactions are tough and intimidating. It is hard to guarantee atomicity across microservices given the network delays, resource contention, and unreliable services.\n\nIn this video, we discuss and take a detailed look into Distributed Transactions, understand why they are needed with a real-world example of Zomato's 10-minute food delivery, and build our understanding of the workings of the Two-Phase Commit protocol.\n\nOutline:\n\n00:00 Why Distributed Transactions\n03:44 Atomicity in Distributed Transactions\n06:47 Two-Phase Commit Protocol for Distributed Transactions\n18:29 Advantages and Disadvantages of Two-Phase Commit",
    "img": "https://i.ytimg.com/vi/7FgU1D4EnpQ/mqdefault.jpg",
    "gif": "https://media.giphy.com/media/3o6wO5b4A4Mx965tWE/giphy.gif",
    "duration": "21:21",
    "view_count": 5619,
    "like_count": 235,
    "comment_count": 32,
    "released_at": "2022-03-28",
    "gist": "Distributed Transactions are essential to have strong consistency in a distributed setup.\n\nAn example could be as simple as a 10-min food/grocery delivery- where to guarantee a 10-min delivery, you can only accept orders when there are goods available in the dark store, and a delivery agent is available to deliver the goods.\n\nThis is a classic case of Distributed Transaction where you need a guarantee of atomicity and consistency across two different services. In a distributed setup, we can achieve it using an algorithm called Two-phase Commit.\n\nThe core idea of 2PC is: Split the transaction into two phases: Reservation and Assignment.\n\n## Phase 1: Reservation\n\nThe Order service will first talk to store service to reserve food items and delivery service to reserve a delivery partner. When the food or delivery partner is reserved, they are not notified. By reserving them, we are just making them unavailable for everyone else.\n\nIf the order service fails to reserve any of these, we roll back the reservation and abort the transaction informing the user that the order is not placed. Reservation comes with a timer, which means if we cannot assign a reserved food item to order in \"n\" minutes, we will be releasing the reservation, making them available for other transactions.\n\nWe move forward to the Commit phase only when the order service reserves both- a food item and a delivery agent.\n\n## Phase 2: Commit\n\nIn the Commit phase, the order services reach out to the store service and the delivery service to assign the food and agent to the order. Because the food and the agent were reserved, no other transaction could see it, and hence with a simple assignment, we can get the reserved food and agent assigned to an order.\n\nUpon this assignment, the store and the delivery agent are notified about the order and proceed with their respective duties.\n\nWe retry a few times if any of the assignments fail (which could happen only if the service goes down). If we still cannot get the assignment done, we inform the user that the order cannot be placed.\n\nThe order is placed only after the food item, and the delivery agent is assigned to the order.",
    "notes_gd": "https://drive.google.com/file/d/18WDFAstffIe_vGbtTz_CS117XhvDcBx3/view?usp=sharing",
    "slug": "distributed-transactions-two-phase-commit-protocol"
  }
]