so exponential algorithms have to be the worst possible way to solve distributed consensus, but are they really that bad? in this video, we talk about an exponential, expensive yet important algorithm to achieve distributed consensus, named eig algorithm that gathers an exponential amount of information and then reaches a consensus. although a little expensive, but this algorithm is critical in laying the foundation for blockchain to make them resilient to malicious users. but before we move forward, i'd like to talk to you about a course on system design that i have been running for over a year now. the course is a cohort based course, which means i won't be rambling a solution and it will not be a monologue. instead, a small, focused group of 50- 60 engineers every cohort will be brainstorming systems and designing it together. this way, we build a solid system and learn from each other's experiences. the course to date is enrolled by 600 plus engineers, spanning nine cohorts and 10 countries. engineers from companies like google, microsoft, github, slack, facebook, tesla, yelp, flipkart, dream 11 and many, many, many more have taken this course and have some wonderful things to say. the coolest part about the course is the depth we go into and the breath we cover. we cover topics ranging from real-time text communication for slack, to designing our own toy load balancer, to quick buzz live text commentary, to doing impressions counting at scale for any advertisement business. in all we would cover roughly 28 questions and the detailed curriculum- uh split week by week, can be found on the course page, which is linked in the description down below. so if you're looking to learn system design from the first principles, you will love this course. i have two offerings for you. the first one is the live cohort discourse which you see on the left side, and the second one is the recorded course which you can see on the right side. the live cover based course happens every two months and it will go on for eight weeks, while the recorded course contains the recordings from one of the past cohorts, as is. if you are in a hurry and want to binge learn system design, i would highly recommend you going for the recorded one. otherwise, the live quote is where you can participate and discuss things live with me and the entire cohort and amplify your learnings. the decision is totally up to you. the course details, prerequisites, testimonials can be found on the course page at pitbi dot me slash master class and i would highly recommend you to check that out. i put the link of uh the course in the description down below. so if you're interested to learn system design, go for it. check out the link in the description down below and i hope to see you in my next cohort. thanks, so reaching consensus is extremely important in any distributed network. say, we have a database cluster in which one node thinks the value of price is one thousand dollars while the other node thinks the value of price is two thousand dollars. now, depending on where the request goes, you would get either 1000 or 2000 right. this gives an inconsistent view to our clients. that is where we need the nodes to talk to each other and reach a consensus and agree that if the value is 1000 or 2000, achieving distributed consensus is extremely simple when it comes to the case that your network wouldn't fail and your processes wouldn't crash. it becomes impossible to achieve distributed consensus when your network is unreliable, which means that there is no guarantee when a process a sends a message to process b, and if there is no guarantee that the message would be delivered, achieving distributed consensus is impossible. very strong what? but it is third that it becomes tricky to achieve distributed consensus when you assume a fair degree of reliability on your network. but the problem comes that the processes might crash or the nodes might crash. right, and this is where we would talk about an algorithm called an exponential information gathering- eig algorithm to reach a distributed consensus. the core idea of this is: every node sends data to every other node. every node records the path from which it received the data until a certain degree of level or under a certain degree, and then decide that, hey, this is going to be the final value. before we talk about eig, we have to talk about a data structure, the eig data structure. eig stands for exponential information gathering, so this data structure is a tree. eig data structure is a tree that grows exponentially and is constructed level by level. right? the idea is that the path in the tree- like from node 8, because it is growing level by level, if a message was received from node a to node b, to node c, we would have on the path a, children b is children c and that's where the value would be stored. so, along the path from which i received the message, i would be storing it along the same path in the tree, right? and this tree is basically what it does is it basically stores all possible permutations and just reiterating, it stores all possible permutations of parts from which you could receive messages right. this way we would be very sure from all possible places that we received a message. now we can easily reach the consensus because we have gathered all the information that we need to reach to a distributed consensus right. so to put this information formally, we can say that at each level we would have at each level k, rather each level k, every node would have n minus k children. so if n are the total number of nodes in my tree, then at each level we would have n minus k children, right? so this way what we would have is we would guarantee the uniqueness of the path so that we would eventually have all possible permutations of the nodes sitting at the leaf. a quick example of that is: let's say i draw a three level deep eig right and i have three nodes in my network right. so a, b and c. i have three nodes right. so my root node would be labeled as an empty string, right. the root node would have three children: a, b and c. if i go level deep, then a, because it is at level 1, it would have n minus 1, which is 3 minus 1, which is two children. so a will have two children, which a, b and a, c. similarly, b will have two children, b, a and b, c, c will have two children, c a and c b, which denotes that i received a message from a to b and then i received the message right, and then b, two, then a to c, that i received the message. right now, if i construct one more level, if i go a level deep on the third level, which means that my a, b, which is at level 2, would have n minus 2, which is 3 minus 2, which is 1, 1 children or 1 child. so a, b would have the children a, b, c, a, c will have the children a, c, b, b, a will have the will have a child b, a, c, b, c will have child b, c, a. so which means that we are not forming a cycle of nodes and we are covering all possible permutations. so this gives a very interesting way of visualizing permutation as a tree. we were anyway doing that, but this is a very nice way of how permutation fits into the distributed systems world through this very nice data structure. right now this is where we would be storing the information about the values which we would come, because in a distributed consensus, what we would have to do is every node would have some opinion, right, that the value is 1000, 2000, 1500, something, right? we would want all the nodes to send values to all other nodes and then reach, and then we, every node, would independently form its own eig tree and then they would all or independently, agree on a particular value, right? so the algorithm. so here, what we do is we assume that at max, f nodes would fail, which means we are assuming the reliability of the communication channel, but we are assuming that at max, f nodes would fail. so, given that we are making our distributed consensus tolerant to process slash nodes failure, the algorithm runs for total f plus 1 rounds and because we are giving enough chances for the nodes to fail- if it didn't fail, well enough, but at max we would be- we'd be tolerating failures of f nodes right at the end of f plus one round. every node would have the same eig with them the same eig and they would then be making the decision or basically reaching the consensus, right? okay, in each round. so we are doing this for f plus one down. so in. in each round, a new level of eig will be created. so each process. now the flow would be simple: each process maintains its own eig tree. the process, upon receiving the values from other nodes and processes, updates its own copy of the tree right in distributed consensus. every node has to be independent. they can exchange messages, but eventually the consensus has to be taken independently. that's why we need to send this information to every other node, so that every other node at the end of a plus one round has the exact same information, so that they all make the exact same decision, right? okay, so after f plus one rounds, what would happen is every node would have the same copy of eig tree and they would be able to make the decision. so nodes independently take the decision, and building this tree is a way to gather the entire information. now this algorithm can be split into two half. first is about gathering the information using this eig tree and second is about making the decision right. so the key highlight of this algorithm is how you gather the information to take that decision right. so we'll start with the first order, the easiest one, right? so what would happen? first round: every node sends the value that it holds to the entire network, including it's- well, including to its own. basically, it's saying that i'll be making, i'll be updating my own eig tree, right, but a formal way to say that is, every node would send a value to an entire network, including its own, so that every node would also update its own eig along the way, right, okay, so a sends data to b and c. let's say i have three nodes: a sensor to b and c. b sets it up to c and a. c sends eta to a and b and every node sends data to every other node, including itself. upon receiving a value v, the node- let's say i- as a node. let's say, uh, i received a value from other node, j- right, so me as a. i received a value from b, so in a b- like i'll be updating because i'm creating the first level, i'll update. tree of b is equal to v, so i'll be creating the first level of my eig tree that i was at empty, like my root was empty. i'm the. this is the first message that i received and i received the message b, right, sorry, i received a message from b, some value v, so i'll be creating the first level, like that, right? so the end of first round, every, at the end of first round, every single node in my network, let's say abc, at the node, they have values that they received from other nodes and itself and updated in its own eig tree, right? so at the end of this, every node would have the same eig and we would be constructing an eig tree of depth one. so a, b and c, all populated right now. what about the next set of rounds? so for around 2 to round, k plus 1, right? so this is the general. so for all other rounds, the process would remain the same. we have constructed the first level. now the process is pretty simple. every process, i, which means every node, i- sends all pairs x, comma, b from k minus 1 level. so we have the first level created. right now. to construct the next level, we use the existing k minus 1 level. so just the level about the last level that we created. we use that level and we send these values, right? we send these values to every other node, including ourselves, right? we send this values to every other node in the network, right? but what do we not send? so we send pairs x, comma, y from k minus 1 level in the network where i is not in the x, which means if i am sending the value, right. so let's say: up until now, what do we have? we have root node and we have abc constructed. now let's see if i am process b. right, if i am process b, i would be sending a and c to a and c, right. so i would not be sending any other because i would not be sending the path that i am in. this would ensure that we are basically creating or we are basically covering all possible permutations. that's the idea behind it, right? so process b would send tree of a and tree of c, two in round two, and process c would send tree of a entry of b in round two. right now. what would happen? node a can thus form the next level of eig tree with path, because process b and process c are sending data to a, which means that a now received the message from a itself, from b and from c from b. it received message for a, the value for a, like the node labeled a and the node labeled c. so this way, node a can form the eig tree with path a. b because it would have received a message from b, a, b, because b sends tree of a to a, tree of c to a. right. so a can form this path. a, b, c, b, because it received message from b, which message of b and c. so it would form a, b, c, b, a, c and b, c. right. so this four nodes, a, b, c, b, ac and bc, right, these four it formed. so node a will send x comma b to itself as well, and thus it would receive the value of tree of b and t of c from a to a. this way it would form b, a and c. a, because it received the value of b from a and c from a. so b, a and c, a it would form. similarly, in the above case, it received the value of, like b and c, it received the value from a, b, c, b, a, c and b, c. right, this way the node a would be forming the second level of this eig tree, right. so we have very beautifully created, if you look at this, up until this level, you are still covering all possible permutations of a and c of length 2, because a, b, a, c, b, a, b, c, c, a, c, b, with no repetitions, and this is the beauty of this particular eig algorithm on how we are exponentially gathering the information and forming this entire gigantic exponential permutation tree to eventually take the decision right. and this is the key highlight of this algorithm, where the first part is to gather the information, while the second half is all about deciding what the consensus is all about, right? so, in case this is a little confusing, i would highly recommend you to go back and listen to it once again. right, the idea is pretty simple. if i received, if a received, a message from b, so i would update, i would construct the path because i received i. i am a, i received a message from b, so b a, c, a, i'll be updating that, right. similarly, you would be updating the other part as well. right, okay, now this process is repeated at each node, so each node would have the exact same eig tree, because we are thinking that, uh, our communication lines are pretty reliable. in case they are not, you can always retry, but our processes cannot. uh, but our processes can crash, right? so even if, if, let's say, some of the process crash, they would not be sending information, but we would still have dense enough information to take that distributed consensus right. okay. so thus we see how every node has all the values from all the nodes across all the paths, and the algorithm stops after f plus one round. so if i'm having, let's say, i have- three nodes and i can allow at max one nodes to f? uh, one node to fail, i would do one plus one, two, i'll do it for only for two rounds, right, and then i'll be in a position- because i gave enough chances for processes to fail and now i'm in a position to make that decision. now the decision process is pretty simple. you can go with the very basic approach to take the distributed like to decide on a particular value. the idea is pretty simple. you have the entire eig tree constructed within this tree. now what you can do is you can go through, you can traverse the entire tree and find all possible values that you receive from all possible paths across all possible nodes, and then you construct a set out of this. if this set is a singleton set, which means it has only one value, what does this mean? if it has only one value, you choose that value because every node has the exact same eig tree. they would see this exact same singleton value and they would all be deciding on v, the singleton value that it has. if the set has multiple values, then you may choose the default, which is v0, maybe the previous state. it's like triggering a rollback, right? but eventually every node is making the exact same decision. you may choose an alternative decision strategy as well. the alternative decision strategy could depend on the use case. for example, if you have total ordering of the values, which means somehow you know that this is the smallest, 12 and this is the largest value and you would always need to pick the latest value or the largest value, then you apply the word, then you apply that rule. no one stopping you from doing that. it is very subjective to the use case. some databases might want to pick the latest value, some database might want to say: i am doing a rollback, or some distribute system might want to sell: pick this particular. so so long as you have total ordering in which you can very well say this value is smaller or this cell is younger or older or something like that, it's your decision rule. you would be making that particular decision and picking that particular value over there, right? so this is where, depending on your use case, using the total ordering of your system may be the latest value, smallest, greatest, whatever you can make that alternative decision strategy, no need to always trigger a rollback right. and this is how you would achieve a distributed consensus using an exponential information gathering algorithm. now, the reason why we picked that exponential information gathering- because it is used in solving- is it basically used to lay the foundation for uh byzantine's algorithm, for basic byzantines agreement where a node is malicious, which means node is corrupt, trying to disrupt the sanity of that, this exponential gathering. because we are gathering information across all possible paths over here. we are ensuring that we are making a same decision after getting all possible information that we would need then reaching a consensus right. and that's it for this video. if you guys like this video, give this video a thumbs up. if you guys like the channel, give this channel sub. i post three in-depth engineering videos every week and i'll see in the next one. thanks [Music] you.